[
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Task info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Task info", 
        "name": "Pct 'task_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_name' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_name\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Task info", 
        "name": "Pct 'task_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_summary' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_summary\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Task info", 
        "name": "Pct 'task_description' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_description' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_description\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'task_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'commit_sha' should be defined\n  Task id: dge_perturbation_prediction\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'method_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: method_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'method_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_name' should be defined\n  Task id: dge_perturbation_prediction\n  Field: method_name\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'method_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_summary' should be defined\n  Task id: dge_perturbation_prediction\n  Field: method_summary\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 0.4166666666666667, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'paper_reference' should be defined\n  Task id: dge_perturbation_prediction\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'is_baseline' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'is_baseline' should be defined\n  Task id: dge_perturbation_prediction\n  Field: is_baseline\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'task_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'commit_sha' should be defined\n  Task id: dge_perturbation_prediction\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'metric_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: metric_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'metric_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_name' should be defined\n  Task id: dge_perturbation_prediction\n  Field: metric_name\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'metric_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_summary' should be defined\n  Task id: dge_perturbation_prediction\n  Field: metric_summary\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 1.0, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'paper_reference' should be defined\n  Task id: dge_perturbation_prediction\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'maximize' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'maximize' should be defined\n  Task id: dge_perturbation_prediction\n  Field: maximize\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'task_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: dataset_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_name' should be defined\n  Task id: dge_perturbation_prediction\n  Field: dataset_name\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_summary' should be defined\n  Task id: dge_perturbation_prediction\n  Field: dataset_summary\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'data_reference' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_reference' should be defined\n  Task id: dge_perturbation_prediction\n  Field: data_reference\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'data_url' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_url' should be defined\n  Task id: dge_perturbation_prediction\n  Field: data_url\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw data", 
        "name": "Number of results", 
        "value": 24, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "len(results) == len(method_info) * len(metric_info) * len(dataset_info)", 
        "message": "Number of results should be equal to #methods × #metrics × #datasets.\n  Task id: dge_perturbation_prediction\n  Number of results: 24\n  Number of methods: 12\n  Number of metrics: 8\n  Number of datasets: 2\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_rmse' %missing", 
        "value": 0.04166666666666663, 
        "severity": 0, 
        "severity_value": 0.4166666666666663, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_rmse\n  Percentage missing: 4%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_rmse_clipped_0001' %missing", 
        "value": 0.04166666666666663, 
        "severity": 0, 
        "severity_value": 0.4166666666666663, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Percentage missing: 4%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_mae' %missing", 
        "value": 0.04166666666666663, 
        "severity": 0, 
        "severity_value": 0.4166666666666663, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_mae\n  Percentage missing: 4%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_mae_clipped_0001' %missing", 
        "value": 0.04166666666666663, 
        "severity": 0, 
        "severity_value": 0.4166666666666663, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_mae_clipped_0001\n  Percentage missing: 4%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_cosine_sim' %missing", 
        "value": 0.125, 
        "severity": 1, 
        "severity_value": 1.25, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_cosine_sim\n  Percentage missing: 12%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_cosine_sim_clipped_0001' %missing", 
        "value": 0.125, 
        "severity": 1, 
        "severity_value": 1.25, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_cosine_sim_clipped_0001\n  Percentage missing: 12%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_pearson' %missing", 
        "value": 0.125, 
        "severity": 1, 
        "severity_value": 1.25, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_pearson\n  Percentage missing: 12%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_spearman' %missing", 
        "value": 0.04166666666666663, 
        "severity": 0, 
        "severity_value": 0.4166666666666663, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_spearman\n  Percentage missing: 4%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'ground_truth' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: ground_truth\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'mean_outcome' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: mean_outcome\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'mean_across_celltypes' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: mean_across_celltypes\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'mean_across_compounds' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: mean_across_compounds\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'sample' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: sample\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'zeros' %missing", 
        "value": 0.375, 
        "severity": 3, 
        "severity_value": 3.75, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: zeros\n  Percentage missing: 38%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'lstm_gru_cnn_ensemble' %missing", 
        "value": 0.5, 
        "severity": 3, 
        "severity_value": 5.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: lstm_gru_cnn_ensemble\n  Percentage missing: 50%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'nn_retraining_with_pseudolabels' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: nn_retraining_with_pseudolabels\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'jn_ap_op2' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: jn_ap_op2\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'scape' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: scape\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'transformer_ensemble' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: transformer_ensemble\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'pyboost' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: pyboost\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Dataset 'neurips-2023-data' %missing", 
        "value": 0.03125, 
        "severity": 0, 
        "severity_value": 0.3125, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  dataset id: neurips-2023-data\n  Percentage missing: 3%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Dataset 'neurips-2023-kaggle' %missing", 
        "value": 0.11458333333333337, 
        "severity": 1, 
        "severity_value": 1.1458333333333337, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  dataset id: neurips-2023-kaggle\n  Percentage missing: 11%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_rmse", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_rmse", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_rmse", 
        "value": 0.4781, 
        "severity": 0, 
        "severity_value": -0.4781, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.4781%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_rmse", 
        "value": 0.5734, 
        "severity": 0, 
        "severity_value": 0.2867, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse\n  Best score: 0.5734%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_rmse", 
        "value": 0.1723, 
        "severity": 0, 
        "severity_value": -0.1723, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.1723%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_rmse", 
        "value": 0.544, 
        "severity": 0, 
        "severity_value": 0.272, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse\n  Best score: 0.544%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_rmse", 
        "value": 0.5137, 
        "severity": 0, 
        "severity_value": -0.5137, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.5137%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_rmse", 
        "value": 0.5877, 
        "severity": 0, 
        "severity_value": 0.29385, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse\n  Best score: 0.5877%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_rmse", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_rmse", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_rmse", 
        "value": 0.4799, 
        "severity": 0, 
        "severity_value": -0.4799, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.4799%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_rmse", 
        "value": 0.58, 
        "severity": 0, 
        "severity_value": 0.29, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse\n  Best score: 0.58%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lstm_gru_cnn_ensemble mean_rowwise_rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lstm_gru_cnn_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lstm_gru_cnn_ensemble mean_rowwise_rmse", 
        "value": 0.658, 
        "severity": 0, 
        "severity_value": 0.329, 
        "code": "best_score <= 2", 
        "message": "Method lstm_gru_cnn_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_rowwise_rmse\n  Best score: 0.658%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_rmse", 
        "value": 0.5727, 
        "severity": 0, 
        "severity_value": -0.5727, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.5727%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_rmse", 
        "value": 0.6588, 
        "severity": 0, 
        "severity_value": 0.3294, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse\n  Best score: 0.6588%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_rmse", 
        "value": 0.5564, 
        "severity": 0, 
        "severity_value": -0.5564, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.5564%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_rmse", 
        "value": 0.6094, 
        "severity": 0, 
        "severity_value": 0.3047, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse\n  Best score: 0.6094%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_rmse", 
        "value": 0.5664, 
        "severity": 0, 
        "severity_value": -0.5664, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.5664%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_rmse", 
        "value": 0.6583, 
        "severity": 0, 
        "severity_value": 0.32915, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse\n  Best score: 0.6583%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_rmse", 
        "value": 0.4875, 
        "severity": 0, 
        "severity_value": -0.4875, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.4875%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_rmse", 
        "value": 0.5856, 
        "severity": 0, 
        "severity_value": 0.2928, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse\n  Best score: 0.5856%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_rmse", 
        "value": 0.562, 
        "severity": 0, 
        "severity_value": -0.562, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.562%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_rmse", 
        "value": 0.6426, 
        "severity": 0, 
        "severity_value": 0.3213, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse\n  Best score: 0.6426%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_rmse_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_rmse_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_rmse_clipped_0001", 
        "value": 0.306, 
        "severity": 0, 
        "severity_value": -0.306, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.306%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_rmse_clipped_0001", 
        "value": 0.4353, 
        "severity": 0, 
        "severity_value": 0.21765, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.4353%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_rmse_clipped_0001", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_rmse_clipped_0001", 
        "value": 0.2286, 
        "severity": 0, 
        "severity_value": 0.1143, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.2286%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_rmse_clipped_0001", 
        "value": 0.2994, 
        "severity": 0, 
        "severity_value": -0.2994, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.2994%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_rmse_clipped_0001", 
        "value": 0.4607, 
        "severity": 0, 
        "severity_value": 0.23035, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.4607%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_rmse_clipped_0001", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_rmse_clipped_0001", 
        "value": 0.1956, 
        "severity": 0, 
        "severity_value": 0.0978, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.1956%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_rmse_clipped_0001", 
        "value": 0.3278, 
        "severity": 0, 
        "severity_value": -0.3278, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.3278%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_rmse_clipped_0001", 
        "value": 0.44, 
        "severity": 0, 
        "severity_value": 0.22, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.44%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lstm_gru_cnn_ensemble mean_rowwise_rmse_clipped_0001", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lstm_gru_cnn_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lstm_gru_cnn_ensemble mean_rowwise_rmse_clipped_0001", 
        "value": 0.4263, 
        "severity": 0, 
        "severity_value": 0.21315, 
        "code": "best_score <= 2", 
        "message": "Method lstm_gru_cnn_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.4263%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_rmse_clipped_0001", 
        "value": 0.4277, 
        "severity": 0, 
        "severity_value": -0.4277, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.4277%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_rmse_clipped_0001", 
        "value": 0.5299, 
        "severity": 0, 
        "severity_value": 0.26495, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.5299%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_rmse_clipped_0001", 
        "value": 0.3289, 
        "severity": 0, 
        "severity_value": -0.3289, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.3289%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_rmse_clipped_0001", 
        "value": 0.5055, 
        "severity": 0, 
        "severity_value": 0.25275, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.5055%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_rmse_clipped_0001", 
        "value": 0.414, 
        "severity": 0, 
        "severity_value": -0.414, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.414%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_rmse_clipped_0001", 
        "value": 0.5147, 
        "severity": 0, 
        "severity_value": 0.25735, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.5147%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_rmse_clipped_0001", 
        "value": 0.3429, 
        "severity": 0, 
        "severity_value": -0.3429, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.3429%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_rmse_clipped_0001", 
        "value": 0.4535, 
        "severity": 0, 
        "severity_value": 0.22675, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.4535%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_rmse_clipped_0001", 
        "value": 0.4265, 
        "severity": 0, 
        "severity_value": -0.4265, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.4265%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_rmse_clipped_0001", 
        "value": 0.5269, 
        "severity": 0, 
        "severity_value": 0.26345, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.5269%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_mae", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_mae", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_mae", 
        "value": 0.3717, 
        "severity": 0, 
        "severity_value": -0.3717, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae\n  Worst score: 0.3717%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_mae", 
        "value": 0.4199, 
        "severity": 0, 
        "severity_value": 0.20995, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae\n  Best score: 0.4199%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_mae", 
        "value": 0.3105, 
        "severity": 0, 
        "severity_value": 0.15525, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae\n  Best score: 0.3105%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_mae", 
        "value": 0.3406, 
        "severity": 0, 
        "severity_value": -0.3406, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae\n  Worst score: 0.3406%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_mae", 
        "value": 0.4537, 
        "severity": 0, 
        "severity_value": 0.22685, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae\n  Best score: 0.4537%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_mae", 
        "value": 0.1607, 
        "severity": 0, 
        "severity_value": 0.08035, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae\n  Best score: 0.1607%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_mae", 
        "value": 0.408, 
        "severity": 0, 
        "severity_value": -0.408, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae\n  Worst score: 0.408%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_mae", 
        "value": 0.4434, 
        "severity": 0, 
        "severity_value": 0.2217, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae\n  Best score: 0.4434%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lstm_gru_cnn_ensemble mean_rowwise_mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lstm_gru_cnn_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_rowwise_mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lstm_gru_cnn_ensemble mean_rowwise_mae", 
        "value": 0.4786, 
        "severity": 0, 
        "severity_value": 0.2393, 
        "code": "best_score <= 2", 
        "message": "Method lstm_gru_cnn_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_rowwise_mae\n  Best score: 0.4786%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_mae", 
        "value": 0.4737, 
        "severity": 0, 
        "severity_value": -0.4737, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae\n  Worst score: 0.4737%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_mae", 
        "value": 0.5269, 
        "severity": 0, 
        "severity_value": 0.26345, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae\n  Best score: 0.5269%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_mae", 
        "value": 0.3804, 
        "severity": 0, 
        "severity_value": -0.3804, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae\n  Worst score: 0.3804%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_mae", 
        "value": 0.5046, 
        "severity": 0, 
        "severity_value": 0.2523, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae\n  Best score: 0.5046%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_mae", 
        "value": 0.463, 
        "severity": 0, 
        "severity_value": -0.463, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae\n  Worst score: 0.463%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_mae", 
        "value": 0.5134, 
        "severity": 0, 
        "severity_value": 0.2567, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae\n  Best score: 0.5134%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_mae", 
        "value": 0.4123, 
        "severity": 0, 
        "severity_value": -0.4123, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae\n  Worst score: 0.4123%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_mae", 
        "value": 0.4517, 
        "severity": 0, 
        "severity_value": 0.22585, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae\n  Best score: 0.4517%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_mae", 
        "value": 0.479, 
        "severity": 0, 
        "severity_value": -0.479, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae\n  Worst score: 0.479%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_mae", 
        "value": 0.5239, 
        "severity": 0, 
        "severity_value": 0.26195, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae\n  Best score: 0.5239%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_mae_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_mae_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_mae_clipped_0001", 
        "value": 0.2956, 
        "severity": 0, 
        "severity_value": -0.2956, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.2956%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_mae_clipped_0001", 
        "value": 0.4464, 
        "severity": 0, 
        "severity_value": 0.2232, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.4464%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_mae_clipped_0001", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_mae_clipped_0001", 
        "value": 0.2212, 
        "severity": 0, 
        "severity_value": 0.1106, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.2212%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_mae_clipped_0001", 
        "value": 0.2696, 
        "severity": 0, 
        "severity_value": -0.2696, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.2696%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_mae_clipped_0001", 
        "value": 0.4837, 
        "severity": 0, 
        "severity_value": 0.24185, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.4837%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_mae_clipped_0001", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_mae_clipped_0001", 
        "value": 0.2482, 
        "severity": 0, 
        "severity_value": 0.1241, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.2482%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_mae_clipped_0001", 
        "value": 0.3415, 
        "severity": 0, 
        "severity_value": -0.3415, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.3415%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_mae_clipped_0001", 
        "value": 0.4754, 
        "severity": 0, 
        "severity_value": 0.2377, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.4754%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lstm_gru_cnn_ensemble mean_rowwise_mae_clipped_0001", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lstm_gru_cnn_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lstm_gru_cnn_ensemble mean_rowwise_mae_clipped_0001", 
        "value": 0.422, 
        "severity": 0, 
        "severity_value": 0.211, 
        "code": "best_score <= 2", 
        "message": "Method lstm_gru_cnn_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.422%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_mae_clipped_0001", 
        "value": 0.4207, 
        "severity": 0, 
        "severity_value": -0.4207, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.4207%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_mae_clipped_0001", 
        "value": 0.5574, 
        "severity": 0, 
        "severity_value": 0.2787, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.5574%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_mae_clipped_0001", 
        "value": 0.3134, 
        "severity": 0, 
        "severity_value": -0.3134, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.3134%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_mae_clipped_0001", 
        "value": 0.5315, 
        "severity": 0, 
        "severity_value": 0.26575, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.5315%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_mae_clipped_0001", 
        "value": 0.4041, 
        "severity": 0, 
        "severity_value": -0.4041, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.4041%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_mae_clipped_0001", 
        "value": 0.5393, 
        "severity": 0, 
        "severity_value": 0.26965, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.5393%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_mae_clipped_0001", 
        "value": 0.347, 
        "severity": 0, 
        "severity_value": -0.347, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.347%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_mae_clipped_0001", 
        "value": 0.4856, 
        "severity": 0, 
        "severity_value": 0.2428, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.4856%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_mae_clipped_0001", 
        "value": 0.4255, 
        "severity": 0, 
        "severity_value": -0.4255, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.4255%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_mae_clipped_0001", 
        "value": 0.5576, 
        "severity": 0, 
        "severity_value": 0.2788, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.5576%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_cosine_sim", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_cosine_sim", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_cosine_sim", 
        "value": 0.1625, 
        "severity": 0, 
        "severity_value": -0.1625, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim\n  Worst score: 0.1625%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_cosine_sim", 
        "value": 0.2079, 
        "severity": 0, 
        "severity_value": 0.10395, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim\n  Best score: 0.2079%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_cosine_sim", 
        "value": 0.2183, 
        "severity": 0, 
        "severity_value": -0.2183, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim\n  Worst score: 0.2183%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_cosine_sim", 
        "value": 0.2744, 
        "severity": 0, 
        "severity_value": 0.1372, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim\n  Best score: 0.2744%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_cosine_sim", 
        "value": 0.2209, 
        "severity": 0, 
        "severity_value": -0.2209, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim\n  Worst score: 0.2209%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_cosine_sim", 
        "value": 0.2721, 
        "severity": 0, 
        "severity_value": 0.13605, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim\n  Best score: 0.2721%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_cosine_sim", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_cosine_sim", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_cosine_sim", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_cosine_sim", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lstm_gru_cnn_ensemble mean_cosine_sim", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lstm_gru_cnn_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_cosine_sim\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lstm_gru_cnn_ensemble mean_cosine_sim", 
        "value": 0.447, 
        "severity": 0, 
        "severity_value": 0.2235, 
        "code": "best_score <= 2", 
        "message": "Method lstm_gru_cnn_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_cosine_sim\n  Best score: 0.447%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_cosine_sim", 
        "value": 0.3835, 
        "severity": 0, 
        "severity_value": -0.3835, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim\n  Worst score: 0.3835%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_cosine_sim", 
        "value": 0.4717, 
        "severity": 0, 
        "severity_value": 0.23585, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim\n  Best score: 0.4717%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_cosine_sim", 
        "value": 0.3299, 
        "severity": 0, 
        "severity_value": -0.3299, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim\n  Worst score: 0.3299%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_cosine_sim", 
        "value": 0.3362, 
        "severity": 0, 
        "severity_value": 0.1681, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim\n  Best score: 0.3362%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_cosine_sim", 
        "value": 0.3569, 
        "severity": 0, 
        "severity_value": -0.3569, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim\n  Worst score: 0.3569%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_cosine_sim", 
        "value": 0.4427, 
        "severity": 0, 
        "severity_value": 0.22135, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim\n  Best score: 0.4427%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_cosine_sim", 
        "value": 0.1816, 
        "severity": 0, 
        "severity_value": -0.1816, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim\n  Worst score: 0.1816%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_cosine_sim", 
        "value": 0.1835, 
        "severity": 0, 
        "severity_value": 0.09175, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim\n  Best score: 0.1835%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_cosine_sim", 
        "value": 0.3617, 
        "severity": 0, 
        "severity_value": -0.3617, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim\n  Worst score: 0.3617%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_cosine_sim", 
        "value": 0.4523, 
        "severity": 0, 
        "severity_value": 0.22615, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim\n  Best score: 0.4523%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_cosine_sim_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_cosine_sim_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_cosine_sim_clipped_0001", 
        "value": 0.1454, 
        "severity": 0, 
        "severity_value": -0.1454, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.1454%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_cosine_sim_clipped_0001", 
        "value": 0.206, 
        "severity": 0, 
        "severity_value": 0.103, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.206%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_cosine_sim_clipped_0001", 
        "value": 0.2038, 
        "severity": 0, 
        "severity_value": -0.2038, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.2038%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_cosine_sim_clipped_0001", 
        "value": 0.2677, 
        "severity": 0, 
        "severity_value": 0.13385, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.2677%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_cosine_sim_clipped_0001", 
        "value": 0.2009, 
        "severity": 0, 
        "severity_value": -0.2009, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.2009%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_cosine_sim_clipped_0001", 
        "value": 0.2224, 
        "severity": 0, 
        "severity_value": 0.1112, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.2224%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_cosine_sim_clipped_0001", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_cosine_sim_clipped_0001", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_cosine_sim_clipped_0001", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_cosine_sim_clipped_0001", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lstm_gru_cnn_ensemble mean_cosine_sim_clipped_0001", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lstm_gru_cnn_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lstm_gru_cnn_ensemble mean_cosine_sim_clipped_0001", 
        "value": 0.4114, 
        "severity": 0, 
        "severity_value": 0.2057, 
        "code": "best_score <= 2", 
        "message": "Method lstm_gru_cnn_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.4114%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_cosine_sim_clipped_0001", 
        "value": 0.3695, 
        "severity": 0, 
        "severity_value": -0.3695, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.3695%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_cosine_sim_clipped_0001", 
        "value": 0.438, 
        "severity": 0, 
        "severity_value": 0.219, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.438%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_cosine_sim_clipped_0001", 
        "value": 0.2785, 
        "severity": 0, 
        "severity_value": -0.2785, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.2785%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_cosine_sim_clipped_0001", 
        "value": 0.3161, 
        "severity": 0, 
        "severity_value": 0.15805, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.3161%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_cosine_sim_clipped_0001", 
        "value": 0.342, 
        "severity": 0, 
        "severity_value": -0.342, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.342%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_cosine_sim_clipped_0001", 
        "value": 0.4037, 
        "severity": 0, 
        "severity_value": 0.20185, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.4037%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_cosine_sim_clipped_0001", 
        "value": 0.184, 
        "severity": 0, 
        "severity_value": -0.184, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.184%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_cosine_sim_clipped_0001", 
        "value": 0.1859, 
        "severity": 0, 
        "severity_value": 0.09295, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.1859%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_cosine_sim_clipped_0001", 
        "value": 0.3524, 
        "severity": 0, 
        "severity_value": -0.3524, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.3524%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_cosine_sim_clipped_0001", 
        "value": 0.4315, 
        "severity": 0, 
        "severity_value": 0.21575, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.4315%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_pearson", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_pearson\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_pearson", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_pearson\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_pearson", 
        "value": 0.1555, 
        "severity": 0, 
        "severity_value": -0.1555, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_pearson\n  Worst score: 0.1555%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_pearson", 
        "value": 0.1886, 
        "severity": 0, 
        "severity_value": 0.0943, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_pearson\n  Best score: 0.1886%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_pearson", 
        "value": 0.214, 
        "severity": 0, 
        "severity_value": -0.214, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_pearson\n  Worst score: 0.214%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_pearson", 
        "value": 0.2687, 
        "severity": 0, 
        "severity_value": 0.13435, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_pearson\n  Best score: 0.2687%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_pearson", 
        "value": 0.2114, 
        "severity": 0, 
        "severity_value": -0.2114, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_pearson\n  Worst score: 0.2114%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_pearson", 
        "value": 0.2699, 
        "severity": 0, 
        "severity_value": 0.13495, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_pearson\n  Best score: 0.2699%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_pearson\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_pearson\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_pearson\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_pearson\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lstm_gru_cnn_ensemble mean_pearson", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lstm_gru_cnn_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_pearson\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lstm_gru_cnn_ensemble mean_pearson", 
        "value": 0.444, 
        "severity": 0, 
        "severity_value": 0.222, 
        "code": "best_score <= 2", 
        "message": "Method lstm_gru_cnn_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_pearson\n  Best score: 0.444%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_pearson", 
        "value": 0.3775, 
        "severity": 0, 
        "severity_value": -0.3775, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_pearson\n  Worst score: 0.3775%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_pearson", 
        "value": 0.4693, 
        "severity": 0, 
        "severity_value": 0.23465, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_pearson\n  Best score: 0.4693%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_pearson", 
        "value": 0.3286, 
        "severity": 0, 
        "severity_value": -0.3286, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_pearson\n  Worst score: 0.3286%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_pearson", 
        "value": 0.3347, 
        "severity": 0, 
        "severity_value": 0.16735, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_pearson\n  Best score: 0.3347%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_pearson", 
        "value": 0.353, 
        "severity": 0, 
        "severity_value": -0.353, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_pearson\n  Worst score: 0.353%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_pearson", 
        "value": 0.4402, 
        "severity": 0, 
        "severity_value": 0.2201, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_pearson\n  Best score: 0.4402%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_pearson", 
        "value": 0.1528, 
        "severity": 0, 
        "severity_value": -0.1528, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_pearson\n  Worst score: 0.1528%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_pearson", 
        "value": 0.1785, 
        "severity": 0, 
        "severity_value": 0.08925, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_pearson\n  Best score: 0.1785%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_pearson", 
        "value": 0.3572, 
        "severity": 0, 
        "severity_value": -0.3572, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_pearson\n  Worst score: 0.3572%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_pearson", 
        "value": 0.45, 
        "severity": 0, 
        "severity_value": 0.225, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_pearson\n  Best score: 0.45%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_spearman", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_spearman\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_spearman", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_spearman\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_spearman", 
        "value": 0.1903, 
        "severity": 0, 
        "severity_value": -0.1903, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_spearman\n  Worst score: 0.1903%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_spearman", 
        "value": 0.2222, 
        "severity": 0, 
        "severity_value": 0.1111, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_spearman\n  Best score: 0.2222%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_spearman", 
        "value": 0.2487, 
        "severity": 0, 
        "severity_value": -0.2487, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_spearman\n  Worst score: 0.2487%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_spearman", 
        "value": 0.2908, 
        "severity": 0, 
        "severity_value": 0.1454, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_spearman\n  Best score: 0.2908%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_spearman", 
        "value": 0.2126, 
        "severity": 0, 
        "severity_value": -0.2126, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_spearman\n  Worst score: 0.2126%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_spearman", 
        "value": 0.2489, 
        "severity": 0, 
        "severity_value": 0.12445, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_spearman\n  Best score: 0.2489%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_spearman", 
        "value": 0.0306, 
        "severity": 0, 
        "severity_value": -0.0306, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_spearman\n  Worst score: 0.0306%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_spearman", 
        "value": 0.0615, 
        "severity": 0, 
        "severity_value": 0.03075, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_spearman\n  Best score: 0.0615%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_spearman\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_spearman\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lstm_gru_cnn_ensemble mean_spearman", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lstm_gru_cnn_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_spearman\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lstm_gru_cnn_ensemble mean_spearman", 
        "value": 0.4211, 
        "severity": 0, 
        "severity_value": 0.21055, 
        "code": "best_score <= 2", 
        "message": "Method lstm_gru_cnn_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_spearman\n  Best score: 0.4211%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_spearman", 
        "value": 0.3719, 
        "severity": 0, 
        "severity_value": -0.3719, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_spearman\n  Worst score: 0.3719%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_spearman", 
        "value": 0.4434, 
        "severity": 0, 
        "severity_value": 0.2217, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_spearman\n  Best score: 0.4434%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_spearman", 
        "value": 0.2965, 
        "severity": 0, 
        "severity_value": -0.2965, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_spearman\n  Worst score: 0.2965%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_spearman", 
        "value": 0.3276, 
        "severity": 0, 
        "severity_value": 0.1638, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_spearman\n  Best score: 0.3276%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_spearman", 
        "value": 0.3528, 
        "severity": 0, 
        "severity_value": -0.3528, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_spearman\n  Worst score: 0.3528%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_spearman", 
        "value": 0.4163, 
        "severity": 0, 
        "severity_value": 0.20815, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_spearman\n  Best score: 0.4163%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_spearman", 
        "value": 0.1992, 
        "severity": 0, 
        "severity_value": -0.1992, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_spearman\n  Worst score: 0.1992%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_spearman", 
        "value": 0.2232, 
        "severity": 0, 
        "severity_value": 0.1116, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_spearman\n  Best score: 0.2232%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_spearman", 
        "value": 0.3645, 
        "severity": 0, 
        "severity_value": -0.3645, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_spearman\n  Worst score: 0.3645%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_spearman", 
        "value": 0.4428, 
        "severity": 0, 
        "severity_value": 0.2214, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_spearman\n  Best score: 0.4428%\n"
    }
]