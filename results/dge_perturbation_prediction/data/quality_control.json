[
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Task info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Task info", 
        "name": "Pct 'task_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_name' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_name\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Task info", 
        "name": "Pct 'task_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_summary' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_summary\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Task info", 
        "name": "Pct 'task_description' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_description' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_description\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'task_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'commit_sha' should be defined\n  Task id: dge_perturbation_prediction\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'method_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: method_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'method_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_name' should be defined\n  Task id: dge_perturbation_prediction\n  Field: method_name\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'method_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_summary' should be defined\n  Task id: dge_perturbation_prediction\n  Field: method_summary\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 0.4166666666666667, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'paper_reference' should be defined\n  Task id: dge_perturbation_prediction\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'is_baseline' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'is_baseline' should be defined\n  Task id: dge_perturbation_prediction\n  Field: is_baseline\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'task_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'commit_sha' should be defined\n  Task id: dge_perturbation_prediction\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'metric_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: metric_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'metric_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_name' should be defined\n  Task id: dge_perturbation_prediction\n  Field: metric_name\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'metric_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_summary' should be defined\n  Task id: dge_perturbation_prediction\n  Field: metric_summary\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 1.0, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'paper_reference' should be defined\n  Task id: dge_perturbation_prediction\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'maximize' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'maximize' should be defined\n  Task id: dge_perturbation_prediction\n  Field: maximize\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'task_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: dataset_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_name' should be defined\n  Task id: dge_perturbation_prediction\n  Field: dataset_name\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_summary' should be defined\n  Task id: dge_perturbation_prediction\n  Field: dataset_summary\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'data_reference' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_reference' should be defined\n  Task id: dge_perturbation_prediction\n  Field: data_reference\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'data_url' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_url' should be defined\n  Task id: dge_perturbation_prediction\n  Field: data_url\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw data", 
        "name": "Number of results", 
        "value": 24, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "len(results) == len(method_info) * len(metric_info) * len(dataset_info)", 
        "message": "Number of results should be equal to #methods × #metrics × #datasets.\n  Task id: dge_perturbation_prediction\n  Number of results: 24\n  Number of methods: 12\n  Number of metrics: 3\n  Number of datasets: 2\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_rmse' %missing", 
        "value": 0.04166666666666663, 
        "severity": 0, 
        "severity_value": 0.4166666666666663, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_rmse\n  Percentage missing: 4%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_mae' %missing", 
        "value": 0.04166666666666663, 
        "severity": 0, 
        "severity_value": 0.4166666666666663, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_mae\n  Percentage missing: 4%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_cosine_sim' %missing", 
        "value": 0.125, 
        "severity": 1, 
        "severity_value": 1.25, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_cosine_sim\n  Percentage missing: 12%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'ground_truth' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: ground_truth\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'mean_outcome' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: mean_outcome\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'mean_across_celltypes' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: mean_across_celltypes\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'mean_across_compounds' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: mean_across_compounds\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'sample' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: sample\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'zeros' %missing", 
        "value": 0.33333333333333337, 
        "severity": 3, 
        "severity_value": 3.3333333333333335, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: zeros\n  Percentage missing: 33%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'lstm_gru_cnn_ensemble' %missing", 
        "value": 0.5, 
        "severity": 3, 
        "severity_value": 5.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: lstm_gru_cnn_ensemble\n  Percentage missing: 50%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'nn_retraining_with_pseudolabels' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: nn_retraining_with_pseudolabels\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'jn_ap_op2' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: jn_ap_op2\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'scape' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: scape\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'transformer_ensemble' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: transformer_ensemble\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'pyboost' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: pyboost\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Dataset 'neurips-2023-kaggle' %missing", 
        "value": 0.11111111111111116, 
        "severity": 1, 
        "severity_value": 1.1111111111111116, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  dataset id: neurips-2023-kaggle\n  Percentage missing: 11%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Dataset 'neurips-2023-data' %missing", 
        "value": 0.02777777777777779, 
        "severity": 0, 
        "severity_value": 0.2777777777777779, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  dataset id: neurips-2023-data\n  Percentage missing: 3%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_rmse", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_rmse", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_rmse", 
        "value": 0.4778, 
        "severity": 0, 
        "severity_value": -0.4778, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.4778%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_rmse", 
        "value": 0.664, 
        "severity": 0, 
        "severity_value": 0.332, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse\n  Best score: 0.664%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_rmse", 
        "value": 0.1719, 
        "severity": 0, 
        "severity_value": -0.1719, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.1719%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_rmse", 
        "value": 0.6144, 
        "severity": 0, 
        "severity_value": 0.3072, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse\n  Best score: 0.6144%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_rmse", 
        "value": 0.5135, 
        "severity": 0, 
        "severity_value": -0.5135, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.5135%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_rmse", 
        "value": 0.6997, 
        "severity": 0, 
        "severity_value": 0.34985, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse\n  Best score: 0.6997%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_rmse", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_rmse", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_rmse", 
        "value": 0.4796, 
        "severity": 0, 
        "severity_value": -0.4796, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.4796%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_rmse", 
        "value": 0.6901, 
        "severity": 0, 
        "severity_value": 0.34505, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse\n  Best score: 0.6901%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lstm_gru_cnn_ensemble mean_rowwise_rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lstm_gru_cnn_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lstm_gru_cnn_ensemble mean_rowwise_rmse", 
        "value": 0.7397, 
        "severity": 0, 
        "severity_value": 0.36985, 
        "code": "best_score <= 2", 
        "message": "Method lstm_gru_cnn_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_rowwise_rmse\n  Best score: 0.7397%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_rmse", 
        "value": 0.573, 
        "severity": 0, 
        "severity_value": -0.573, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.573%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_rmse", 
        "value": 0.7461, 
        "severity": 0, 
        "severity_value": 0.37305, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse\n  Best score: 0.7461%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_rmse", 
        "value": 0.5562, 
        "severity": 0, 
        "severity_value": -0.5562, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.5562%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_rmse", 
        "value": 0.7209, 
        "severity": 0, 
        "severity_value": 0.36045, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse\n  Best score: 0.7209%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_rmse", 
        "value": 0.5663, 
        "severity": 0, 
        "severity_value": -0.5663, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.5663%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_rmse", 
        "value": 0.7443, 
        "severity": 0, 
        "severity_value": 0.37215, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse\n  Best score: 0.7443%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_rmse", 
        "value": 0.4874, 
        "severity": 0, 
        "severity_value": -0.4874, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.4874%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_rmse", 
        "value": 0.6902, 
        "severity": 0, 
        "severity_value": 0.3451, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse\n  Best score: 0.6902%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_rmse", 
        "value": 0.5625, 
        "severity": 0, 
        "severity_value": -0.5625, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.5625%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_rmse", 
        "value": 0.7365, 
        "severity": 0, 
        "severity_value": 0.36825, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse\n  Best score: 0.7365%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_mae", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_mae", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_mae", 
        "value": 0.3628, 
        "severity": 0, 
        "severity_value": -0.3628, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae\n  Worst score: 0.3628%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_mae", 
        "value": 0.4199, 
        "severity": 0, 
        "severity_value": 0.20995, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae\n  Best score: 0.4199%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_mae", 
        "value": 0.2089, 
        "severity": 0, 
        "severity_value": 0.10445, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae\n  Best score: 0.2089%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_mae", 
        "value": 0.4178, 
        "severity": 0, 
        "severity_value": -0.4178, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae\n  Worst score: 0.4178%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_mae", 
        "value": 0.4537, 
        "severity": 0, 
        "severity_value": 0.22685, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae\n  Best score: 0.4537%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_mae", 
        "value": 0.1606, 
        "severity": 0, 
        "severity_value": 0.0803, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae\n  Best score: 0.1606%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_mae", 
        "value": 0.4434, 
        "severity": 0, 
        "severity_value": -0.4434, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae\n  Worst score: 0.4434%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_mae", 
        "value": 0.5132, 
        "severity": 0, 
        "severity_value": 0.2566, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae\n  Best score: 0.5132%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lstm_gru_cnn_ensemble mean_rowwise_mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lstm_gru_cnn_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_rowwise_mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lstm_gru_cnn_ensemble mean_rowwise_mae", 
        "value": 0.5288, 
        "severity": 0, 
        "severity_value": 0.2644, 
        "code": "best_score <= 2", 
        "message": "Method lstm_gru_cnn_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_rowwise_mae\n  Best score: 0.5288%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_mae", 
        "value": 0.5167, 
        "severity": 0, 
        "severity_value": -0.5167, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae\n  Worst score: 0.5167%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_mae", 
        "value": 0.527, 
        "severity": 0, 
        "severity_value": 0.2635, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae\n  Best score: 0.527%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_mae", 
        "value": 0.4797, 
        "severity": 0, 
        "severity_value": -0.4797, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae\n  Worst score: 0.4797%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_mae", 
        "value": 0.5046, 
        "severity": 0, 
        "severity_value": 0.2523, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae\n  Best score: 0.5046%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_mae", 
        "value": 0.5134, 
        "severity": 0, 
        "severity_value": -0.5134, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae\n  Worst score: 0.5134%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_mae", 
        "value": 0.5139, 
        "severity": 0, 
        "severity_value": 0.25695, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae\n  Best score: 0.5139%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_mae", 
        "value": 0.4493, 
        "severity": 0, 
        "severity_value": -0.4493, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae\n  Worst score: 0.4493%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_mae", 
        "value": 0.4802, 
        "severity": 0, 
        "severity_value": 0.2401, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae\n  Best score: 0.4802%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_mae", 
        "value": 0.5248, 
        "severity": 0, 
        "severity_value": -0.5248, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae\n  Worst score: 0.5248%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_mae", 
        "value": 0.5481, 
        "severity": 0, 
        "severity_value": 0.27405, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae\n  Best score: 0.5481%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_cosine_sim", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_cosine_sim", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_cosine_sim", 
        "value": 0.1234, 
        "severity": 0, 
        "severity_value": -0.1234, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim\n  Worst score: 0.1234%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_cosine_sim", 
        "value": 0.2078, 
        "severity": 0, 
        "severity_value": 0.1039, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim\n  Best score: 0.2078%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_cosine_sim", 
        "value": 0.1716, 
        "severity": 0, 
        "severity_value": -0.1716, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim\n  Worst score: 0.1716%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_cosine_sim", 
        "value": 0.2743, 
        "severity": 0, 
        "severity_value": 0.13715, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim\n  Best score: 0.2743%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_cosine_sim", 
        "value": 0.2208, 
        "severity": 0, 
        "severity_value": -0.2208, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim\n  Worst score: 0.2208%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_cosine_sim", 
        "value": 0.2609, 
        "severity": 0, 
        "severity_value": 0.13045, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim\n  Best score: 0.2609%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_cosine_sim", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_cosine_sim", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_cosine_sim", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_cosine_sim", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lstm_gru_cnn_ensemble mean_cosine_sim", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lstm_gru_cnn_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_cosine_sim\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lstm_gru_cnn_ensemble mean_cosine_sim", 
        "value": 0.3318, 
        "severity": 0, 
        "severity_value": 0.1659, 
        "code": "best_score <= 2", 
        "message": "Method lstm_gru_cnn_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lstm_gru_cnn_ensemble\n  Metric id: mean_cosine_sim\n  Best score: 0.3318%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_cosine_sim", 
        "value": 0.3821, 
        "severity": 0, 
        "severity_value": -0.3821, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim\n  Worst score: 0.3821%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_cosine_sim", 
        "value": 0.3822, 
        "severity": 0, 
        "severity_value": 0.1911, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim\n  Best score: 0.3822%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_cosine_sim", 
        "value": 0.3029, 
        "severity": 0, 
        "severity_value": -0.3029, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim\n  Worst score: 0.3029%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_cosine_sim", 
        "value": 0.3361, 
        "severity": 0, 
        "severity_value": 0.16805, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim\n  Best score: 0.3361%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_cosine_sim", 
        "value": 0.3484, 
        "severity": 0, 
        "severity_value": -0.3484, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim\n  Worst score: 0.3484%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_cosine_sim", 
        "value": 0.357, 
        "severity": 0, 
        "severity_value": 0.1785, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim\n  Best score: 0.357%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_cosine_sim", 
        "value": 0.1613, 
        "severity": 0, 
        "severity_value": -0.1613, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim\n  Worst score: 0.1613%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_cosine_sim", 
        "value": 0.1796, 
        "severity": 0, 
        "severity_value": 0.0898, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim\n  Best score: 0.1796%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_cosine_sim", 
        "value": 0.362, 
        "severity": 0, 
        "severity_value": -0.362, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim\n  Worst score: 0.362%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_cosine_sim", 
        "value": 0.4066, 
        "severity": 0, 
        "severity_value": 0.2033, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim\n  Best score: 0.4066%\n"
    }
]