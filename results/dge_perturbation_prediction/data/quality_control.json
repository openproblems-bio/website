[
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Task info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Task info", 
        "name": "Pct 'task_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_name' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_name\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Task info", 
        "name": "Pct 'task_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_summary' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_summary\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Task info", 
        "name": "Pct 'task_description' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_description' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_description\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'task_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'commit_sha' should be defined\n  Task id: dge_perturbation_prediction\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'method_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: method_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'method_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_name' should be defined\n  Task id: dge_perturbation_prediction\n  Field: method_name\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'method_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_summary' should be defined\n  Task id: dge_perturbation_prediction\n  Field: method_summary\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 0.4166666666666667, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'paper_reference' should be defined\n  Task id: dge_perturbation_prediction\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'is_baseline' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'is_baseline' should be defined\n  Task id: dge_perturbation_prediction\n  Field: is_baseline\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'task_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'commit_sha' should be defined\n  Task id: dge_perturbation_prediction\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'metric_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: metric_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'metric_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_name' should be defined\n  Task id: dge_perturbation_prediction\n  Field: metric_name\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'metric_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_summary' should be defined\n  Task id: dge_perturbation_prediction\n  Field: metric_summary\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 1.0, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'paper_reference' should be defined\n  Task id: dge_perturbation_prediction\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'maximize' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'maximize' should be defined\n  Task id: dge_perturbation_prediction\n  Field: maximize\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'task_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: dataset_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_name' should be defined\n  Task id: dge_perturbation_prediction\n  Field: dataset_name\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_summary' should be defined\n  Task id: dge_perturbation_prediction\n  Field: dataset_summary\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'data_reference' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_reference' should be defined\n  Task id: dge_perturbation_prediction\n  Field: data_reference\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'data_url' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_url' should be defined\n  Task id: dge_perturbation_prediction\n  Field: data_url\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw data", 
        "name": "Number of results", 
        "value": 12, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "len(results) == len(method_info) * len(metric_info) * len(dataset_info)", 
        "message": "Number of results should be equal to #methods × #metrics × #datasets.\n  Task id: dge_perturbation_prediction\n  Number of results: 12\n  Number of methods: 12\n  Number of metrics: 16\n  Number of datasets: 1\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_rmse' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_rmse\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_rmse_clipped_0001' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_mae' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_mae\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_mae_clipped_0001' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_mae_clipped_0001\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_rmse_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_rmse_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_rmse_clipped_0001_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_mae_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_mae_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_mae_clipped_0001_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_cosine_sim' %missing", 
        "value": 0.08333333333333337, 
        "severity": 0, 
        "severity_value": 0.8333333333333337, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_cosine_sim\n  Percentage missing: 8%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_cosine_sim_clipped_0001' %missing", 
        "value": 0.08333333333333337, 
        "severity": 0, 
        "severity_value": 0.8333333333333337, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_cosine_sim_clipped_0001\n  Percentage missing: 8%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_cosine_sim_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_cosine_sim_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_cosine_sim_clipped_0001_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_pearson' %missing", 
        "value": 0.08333333333333337, 
        "severity": 0, 
        "severity_value": 0.8333333333333337, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_pearson\n  Percentage missing: 8%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_spearman' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_spearman\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_pearson_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_pearson_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_spearman_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_spearman_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'ground_truth' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: ground_truth\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'mean_outcome' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: mean_outcome\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'mean_across_celltypes' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: mean_across_celltypes\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'mean_across_compounds' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: mean_across_compounds\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'sample' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: sample\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'zeros' %missing", 
        "value": 0.1875, 
        "severity": 1, 
        "severity_value": 1.875, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: zeros\n  Percentage missing: 19%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'lgc_ensemble' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: lgc_ensemble\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'nn_retraining_with_pseudolabels' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: nn_retraining_with_pseudolabels\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'jn_ap_op2' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: jn_ap_op2\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'scape' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: scape\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'transformer_ensemble' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: transformer_ensemble\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'pyboost' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: pyboost\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Dataset 'neurips-2023-data' %missing", 
        "value": 0.015625, 
        "severity": 0, 
        "severity_value": 0.15625, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  dataset id: neurips-2023-data\n  Percentage missing: 2%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_rmse", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_rmse", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_rmse", 
        "value": 0.3777, 
        "severity": 0, 
        "severity_value": -0.3777, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.3777%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_rmse", 
        "value": 0.3777, 
        "severity": 0, 
        "severity_value": 0.18885, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse\n  Best score: 0.3777%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_rmse", 
        "value": 0.3846, 
        "severity": 0, 
        "severity_value": -0.3846, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.3846%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_rmse", 
        "value": 0.3846, 
        "severity": 0, 
        "severity_value": 0.1923, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse\n  Best score: 0.3846%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_rmse", 
        "value": 0.3683, 
        "severity": 0, 
        "severity_value": -0.3683, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.3683%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_rmse", 
        "value": 0.3683, 
        "severity": 0, 
        "severity_value": 0.18415, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse\n  Best score: 0.3683%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_rmse", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_rmse", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_rmse", 
        "value": 0.3625, 
        "severity": 0, 
        "severity_value": -0.3625, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.3625%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_rmse", 
        "value": 0.3625, 
        "severity": 0, 
        "severity_value": 0.18125, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse\n  Best score: 0.3625%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_rowwise_rmse", 
        "value": 0.4993, 
        "severity": 0, 
        "severity_value": -0.4993, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.4993%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_rowwise_rmse", 
        "value": 0.4993, 
        "severity": 0, 
        "severity_value": 0.24965, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_rmse\n  Best score: 0.4993%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_rmse", 
        "value": 0.5112, 
        "severity": 0, 
        "severity_value": -0.5112, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.5112%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_rmse", 
        "value": 0.5112, 
        "severity": 0, 
        "severity_value": 0.2556, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse\n  Best score: 0.5112%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_rmse", 
        "value": 0.4138, 
        "severity": 0, 
        "severity_value": -0.4138, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.4138%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_rmse", 
        "value": 0.4138, 
        "severity": 0, 
        "severity_value": 0.2069, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse\n  Best score: 0.4138%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_rmse", 
        "value": 0.5084, 
        "severity": 0, 
        "severity_value": -0.5084, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.5084%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_rmse", 
        "value": 0.5084, 
        "severity": 0, 
        "severity_value": 0.2542, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse\n  Best score: 0.5084%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_rmse", 
        "value": 0.3789, 
        "severity": 0, 
        "severity_value": -0.3789, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.3789%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_rmse", 
        "value": 0.3789, 
        "severity": 0, 
        "severity_value": 0.18945, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse\n  Best score: 0.3789%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_rmse", 
        "value": 0.466, 
        "severity": 0, 
        "severity_value": -0.466, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.466%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_rmse", 
        "value": 0.466, 
        "severity": 0, 
        "severity_value": 0.233, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse\n  Best score: 0.466%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_rmse_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_rmse_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_rmse_clipped_0001", 
        "value": 0.3421, 
        "severity": 0, 
        "severity_value": -0.3421, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.3421%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_rmse_clipped_0001", 
        "value": 0.3421, 
        "severity": 0, 
        "severity_value": 0.17105, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.3421%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_rmse_clipped_0001", 
        "value": 0.347, 
        "severity": 0, 
        "severity_value": -0.347, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.347%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_rmse_clipped_0001", 
        "value": 0.347, 
        "severity": 0, 
        "severity_value": 0.1735, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.347%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_rmse_clipped_0001", 
        "value": 0.3102, 
        "severity": 0, 
        "severity_value": -0.3102, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.3102%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_rmse_clipped_0001", 
        "value": 0.3102, 
        "severity": 0, 
        "severity_value": 0.1551, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.3102%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_rmse_clipped_0001", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_rmse_clipped_0001", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_rmse_clipped_0001", 
        "value": 0.3284, 
        "severity": 0, 
        "severity_value": -0.3284, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.3284%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_rmse_clipped_0001", 
        "value": 0.3284, 
        "severity": 0, 
        "severity_value": 0.1642, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.3284%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_rowwise_rmse_clipped_0001", 
        "value": 0.424, 
        "severity": 0, 
        "severity_value": -0.424, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.424%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_rowwise_rmse_clipped_0001", 
        "value": 0.424, 
        "severity": 0, 
        "severity_value": 0.212, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.424%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_rmse_clipped_0001", 
        "value": 0.4466, 
        "severity": 0, 
        "severity_value": -0.4466, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.4466%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_rmse_clipped_0001", 
        "value": 0.4466, 
        "severity": 0, 
        "severity_value": 0.2233, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.4466%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_rmse_clipped_0001", 
        "value": 0.3468, 
        "severity": 0, 
        "severity_value": -0.3468, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.3468%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_rmse_clipped_0001", 
        "value": 0.3468, 
        "severity": 0, 
        "severity_value": 0.1734, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.3468%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_rmse_clipped_0001", 
        "value": 0.4339, 
        "severity": 0, 
        "severity_value": -0.4339, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.4339%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_rmse_clipped_0001", 
        "value": 0.4339, 
        "severity": 0, 
        "severity_value": 0.21695, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.4339%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_rmse_clipped_0001", 
        "value": 0.3436, 
        "severity": 0, 
        "severity_value": -0.3436, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.3436%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_rmse_clipped_0001", 
        "value": 0.3436, 
        "severity": 0, 
        "severity_value": 0.1718, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.3436%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_rmse_clipped_0001", 
        "value": 0.4185, 
        "severity": 0, 
        "severity_value": -0.4185, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.4185%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_rmse_clipped_0001", 
        "value": 0.4185, 
        "severity": 0, 
        "severity_value": 0.20925, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.4185%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_mae", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_mae", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_mae", 
        "value": 0.3415, 
        "severity": 0, 
        "severity_value": -0.3415, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae\n  Worst score: 0.3415%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_mae", 
        "value": 0.3415, 
        "severity": 0, 
        "severity_value": 0.17075, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae\n  Best score: 0.3415%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_mae", 
        "value": 0.3331, 
        "severity": 0, 
        "severity_value": -0.3331, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae\n  Worst score: 0.3331%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_mae", 
        "value": 0.3331, 
        "severity": 0, 
        "severity_value": 0.16655, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae\n  Best score: 0.3331%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_mae", 
        "value": 0.277, 
        "severity": 0, 
        "severity_value": -0.277, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae\n  Worst score: 0.277%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_mae", 
        "value": 0.277, 
        "severity": 0, 
        "severity_value": 0.1385, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae\n  Best score: 0.277%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_mae", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_mae", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_mae", 
        "value": 0.342, 
        "severity": 0, 
        "severity_value": -0.342, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae\n  Worst score: 0.342%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_mae", 
        "value": 0.342, 
        "severity": 0, 
        "severity_value": 0.171, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae\n  Best score: 0.342%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_rowwise_mae", 
        "value": 0.4097, 
        "severity": 0, 
        "severity_value": -0.4097, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_mae\n  Worst score: 0.4097%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_rowwise_mae", 
        "value": 0.4097, 
        "severity": 0, 
        "severity_value": 0.20485, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_mae\n  Best score: 0.4097%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_mae", 
        "value": 0.4334, 
        "severity": 0, 
        "severity_value": -0.4334, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae\n  Worst score: 0.4334%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_mae", 
        "value": 0.4334, 
        "severity": 0, 
        "severity_value": 0.2167, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae\n  Best score: 0.4334%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_mae", 
        "value": 0.3286, 
        "severity": 0, 
        "severity_value": -0.3286, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae\n  Worst score: 0.3286%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_mae", 
        "value": 0.3286, 
        "severity": 0, 
        "severity_value": 0.1643, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae\n  Best score: 0.3286%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_mae", 
        "value": 0.4089, 
        "severity": 0, 
        "severity_value": -0.4089, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae\n  Worst score: 0.4089%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_mae", 
        "value": 0.4089, 
        "severity": 0, 
        "severity_value": 0.20445, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae\n  Best score: 0.4089%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_mae", 
        "value": 0.3491, 
        "severity": 0, 
        "severity_value": -0.3491, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae\n  Worst score: 0.3491%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_mae", 
        "value": 0.3491, 
        "severity": 0, 
        "severity_value": 0.17455, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae\n  Best score: 0.3491%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_mae", 
        "value": 0.4196, 
        "severity": 0, 
        "severity_value": -0.4196, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae\n  Worst score: 0.4196%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_mae", 
        "value": 0.4196, 
        "severity": 0, 
        "severity_value": 0.2098, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae\n  Best score: 0.4196%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_mae_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_mae_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_mae_clipped_0001", 
        "value": 0.3415, 
        "severity": 0, 
        "severity_value": -0.3415, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.3415%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_mae_clipped_0001", 
        "value": 0.3415, 
        "severity": 0, 
        "severity_value": 0.17075, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.3415%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_mae_clipped_0001", 
        "value": 0.3331, 
        "severity": 0, 
        "severity_value": -0.3331, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.3331%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_mae_clipped_0001", 
        "value": 0.3331, 
        "severity": 0, 
        "severity_value": 0.16655, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.3331%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_mae_clipped_0001", 
        "value": 0.277, 
        "severity": 0, 
        "severity_value": -0.277, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.277%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_mae_clipped_0001", 
        "value": 0.277, 
        "severity": 0, 
        "severity_value": 0.1385, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.277%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_mae_clipped_0001", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_mae_clipped_0001", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_mae_clipped_0001", 
        "value": 0.342, 
        "severity": 0, 
        "severity_value": -0.342, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.342%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_mae_clipped_0001", 
        "value": 0.342, 
        "severity": 0, 
        "severity_value": 0.171, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.342%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_rowwise_mae_clipped_0001", 
        "value": 0.4093, 
        "severity": 0, 
        "severity_value": -0.4093, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.4093%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_rowwise_mae_clipped_0001", 
        "value": 0.4093, 
        "severity": 0, 
        "severity_value": 0.20465, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.4093%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_mae_clipped_0001", 
        "value": 0.4334, 
        "severity": 0, 
        "severity_value": -0.4334, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.4334%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_mae_clipped_0001", 
        "value": 0.4334, 
        "severity": 0, 
        "severity_value": 0.2167, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.4334%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_mae_clipped_0001", 
        "value": 0.3284, 
        "severity": 0, 
        "severity_value": -0.3284, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.3284%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_mae_clipped_0001", 
        "value": 0.3284, 
        "severity": 0, 
        "severity_value": 0.1642, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.3284%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_mae_clipped_0001", 
        "value": 0.4086, 
        "severity": 0, 
        "severity_value": -0.4086, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.4086%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_mae_clipped_0001", 
        "value": 0.4086, 
        "severity": 0, 
        "severity_value": 0.2043, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.4086%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_mae_clipped_0001", 
        "value": 0.3491, 
        "severity": 0, 
        "severity_value": -0.3491, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.3491%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_mae_clipped_0001", 
        "value": 0.3491, 
        "severity": 0, 
        "severity_value": 0.17455, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.3491%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_mae_clipped_0001", 
        "value": 0.4196, 
        "severity": 0, 
        "severity_value": -0.4196, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.4196%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_mae_clipped_0001", 
        "value": 0.4196, 
        "severity": 0, 
        "severity_value": 0.2098, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.4196%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_rmse_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_rmse_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse_r\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_rmse_r", 
        "value": 0.3777, 
        "severity": 0, 
        "severity_value": -0.3777, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.3777%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_rmse_r", 
        "value": 0.3777, 
        "severity": 0, 
        "severity_value": 0.18885, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.3777%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_rmse_r", 
        "value": 0.3846, 
        "severity": 0, 
        "severity_value": -0.3846, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.3846%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_rmse_r", 
        "value": 0.3846, 
        "severity": 0, 
        "severity_value": 0.1923, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.3846%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_rmse_r", 
        "value": 0.3683, 
        "severity": 0, 
        "severity_value": -0.3683, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.3683%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_rmse_r", 
        "value": 0.3683, 
        "severity": 0, 
        "severity_value": 0.18415, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.3683%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_rmse_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_rmse_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_rmse_r", 
        "value": 0.3625, 
        "severity": 0, 
        "severity_value": -0.3625, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.3625%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_rmse_r", 
        "value": 0.3625, 
        "severity": 0, 
        "severity_value": 0.18125, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.3625%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_rowwise_rmse_r", 
        "value": 0.4993, 
        "severity": 0, 
        "severity_value": -0.4993, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.4993%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_rowwise_rmse_r", 
        "value": 0.4993, 
        "severity": 0, 
        "severity_value": 0.24965, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.4993%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_rmse_r", 
        "value": 0.5112, 
        "severity": 0, 
        "severity_value": -0.5112, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.5112%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_rmse_r", 
        "value": 0.5112, 
        "severity": 0, 
        "severity_value": 0.2556, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.5112%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_rmse_r", 
        "value": 0.4138, 
        "severity": 0, 
        "severity_value": -0.4138, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.4138%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_rmse_r", 
        "value": 0.4138, 
        "severity": 0, 
        "severity_value": 0.2069, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.4138%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_rmse_r", 
        "value": 0.5084, 
        "severity": 0, 
        "severity_value": -0.5084, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.5084%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_rmse_r", 
        "value": 0.5084, 
        "severity": 0, 
        "severity_value": 0.2542, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.5084%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_rmse_r", 
        "value": 0.3789, 
        "severity": 0, 
        "severity_value": -0.3789, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.3789%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_rmse_r", 
        "value": 0.3789, 
        "severity": 0, 
        "severity_value": 0.18945, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.3789%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_rmse_r", 
        "value": 0.466, 
        "severity": 0, 
        "severity_value": -0.466, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.466%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_rmse_r", 
        "value": 0.466, 
        "severity": 0, 
        "severity_value": 0.233, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.466%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_rmse_clipped_0001_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_rmse_clipped_0001_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.3421, 
        "severity": 0, 
        "severity_value": -0.3421, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.3421%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.3421, 
        "severity": 0, 
        "severity_value": 0.17105, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.3421%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.347, 
        "severity": 0, 
        "severity_value": -0.347, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.347%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.347, 
        "severity": 0, 
        "severity_value": 0.1735, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.347%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.3102, 
        "severity": 0, 
        "severity_value": -0.3102, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.3102%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.3102, 
        "severity": 0, 
        "severity_value": 0.1551, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.3102%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_rmse_clipped_0001_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_rmse_clipped_0001_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.3284, 
        "severity": 0, 
        "severity_value": -0.3284, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.3284%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.3284, 
        "severity": 0, 
        "severity_value": 0.1642, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.3284%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.424, 
        "severity": 0, 
        "severity_value": -0.424, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.424%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.424, 
        "severity": 0, 
        "severity_value": 0.212, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.424%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.4466, 
        "severity": 0, 
        "severity_value": -0.4466, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.4466%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.4466, 
        "severity": 0, 
        "severity_value": 0.2233, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.4466%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.3468, 
        "severity": 0, 
        "severity_value": -0.3468, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.3468%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.3468, 
        "severity": 0, 
        "severity_value": 0.1734, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.3468%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.4339, 
        "severity": 0, 
        "severity_value": -0.4339, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.4339%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.4339, 
        "severity": 0, 
        "severity_value": 0.21695, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.4339%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.3436, 
        "severity": 0, 
        "severity_value": -0.3436, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.3436%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.3436, 
        "severity": 0, 
        "severity_value": 0.1718, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.3436%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.4185, 
        "severity": 0, 
        "severity_value": -0.4185, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.4185%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.4185, 
        "severity": 0, 
        "severity_value": 0.20925, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.4185%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_mae_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae_r\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_mae_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae_r\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_mae_r", 
        "value": 0.3415, 
        "severity": 0, 
        "severity_value": -0.3415, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.3415%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_mae_r", 
        "value": 0.3415, 
        "severity": 0, 
        "severity_value": 0.17075, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.3415%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_mae_r", 
        "value": 0.3331, 
        "severity": 0, 
        "severity_value": -0.3331, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.3331%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_mae_r", 
        "value": 0.3331, 
        "severity": 0, 
        "severity_value": 0.16655, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.3331%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_mae_r", 
        "value": 0.277, 
        "severity": 0, 
        "severity_value": -0.277, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.277%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_mae_r", 
        "value": 0.277, 
        "severity": 0, 
        "severity_value": 0.1385, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.277%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_mae_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_mae_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae_r\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_mae_r", 
        "value": 0.342, 
        "severity": 0, 
        "severity_value": -0.342, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.342%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_mae_r", 
        "value": 0.342, 
        "severity": 0, 
        "severity_value": 0.171, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.342%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_rowwise_mae_r", 
        "value": 0.4097, 
        "severity": 0, 
        "severity_value": -0.4097, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.4097%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_rowwise_mae_r", 
        "value": 0.4097, 
        "severity": 0, 
        "severity_value": 0.20485, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.4097%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_mae_r", 
        "value": 0.4334, 
        "severity": 0, 
        "severity_value": -0.4334, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.4334%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_mae_r", 
        "value": 0.4334, 
        "severity": 0, 
        "severity_value": 0.2167, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.4334%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_mae_r", 
        "value": 0.3286, 
        "severity": 0, 
        "severity_value": -0.3286, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.3286%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_mae_r", 
        "value": 0.3286, 
        "severity": 0, 
        "severity_value": 0.1643, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.3286%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_mae_r", 
        "value": 0.4089, 
        "severity": 0, 
        "severity_value": -0.4089, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.4089%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_mae_r", 
        "value": 0.4089, 
        "severity": 0, 
        "severity_value": 0.20445, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.4089%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_mae_r", 
        "value": 0.3491, 
        "severity": 0, 
        "severity_value": -0.3491, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.3491%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_mae_r", 
        "value": 0.3491, 
        "severity": 0, 
        "severity_value": 0.17455, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.3491%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_mae_r", 
        "value": 0.4196, 
        "severity": 0, 
        "severity_value": -0.4196, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.4196%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_mae_r", 
        "value": 0.4196, 
        "severity": 0, 
        "severity_value": 0.2098, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.4196%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_mae_clipped_0001_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_mae_clipped_0001_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_mae_clipped_0001_r", 
        "value": 0.3415, 
        "severity": 0, 
        "severity_value": -0.3415, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.3415%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_mae_clipped_0001_r", 
        "value": 0.3415, 
        "severity": 0, 
        "severity_value": 0.17075, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.3415%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_mae_clipped_0001_r", 
        "value": 0.3331, 
        "severity": 0, 
        "severity_value": -0.3331, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.3331%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_mae_clipped_0001_r", 
        "value": 0.3331, 
        "severity": 0, 
        "severity_value": 0.16655, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.3331%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_mae_clipped_0001_r", 
        "value": 0.277, 
        "severity": 0, 
        "severity_value": -0.277, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.277%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_mae_clipped_0001_r", 
        "value": 0.277, 
        "severity": 0, 
        "severity_value": 0.1385, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.277%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_mae_clipped_0001_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_mae_clipped_0001_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_mae_clipped_0001_r", 
        "value": 0.342, 
        "severity": 0, 
        "severity_value": -0.342, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.342%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_mae_clipped_0001_r", 
        "value": 0.342, 
        "severity": 0, 
        "severity_value": 0.171, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.342%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_rowwise_mae_clipped_0001_r", 
        "value": 0.4093, 
        "severity": 0, 
        "severity_value": -0.4093, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.4093%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_rowwise_mae_clipped_0001_r", 
        "value": 0.4093, 
        "severity": 0, 
        "severity_value": 0.20465, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.4093%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_mae_clipped_0001_r", 
        "value": 0.4334, 
        "severity": 0, 
        "severity_value": -0.4334, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.4334%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_mae_clipped_0001_r", 
        "value": 0.4334, 
        "severity": 0, 
        "severity_value": 0.2167, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.4334%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_mae_clipped_0001_r", 
        "value": 0.3284, 
        "severity": 0, 
        "severity_value": -0.3284, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.3284%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_mae_clipped_0001_r", 
        "value": 0.3284, 
        "severity": 0, 
        "severity_value": 0.1642, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.3284%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_mae_clipped_0001_r", 
        "value": 0.4086, 
        "severity": 0, 
        "severity_value": -0.4086, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.4086%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_mae_clipped_0001_r", 
        "value": 0.4086, 
        "severity": 0, 
        "severity_value": 0.2043, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.4086%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_mae_clipped_0001_r", 
        "value": 0.3491, 
        "severity": 0, 
        "severity_value": -0.3491, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.3491%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_mae_clipped_0001_r", 
        "value": 0.3491, 
        "severity": 0, 
        "severity_value": 0.17455, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.3491%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_mae_clipped_0001_r", 
        "value": 0.4196, 
        "severity": 0, 
        "severity_value": -0.4196, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.4196%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_mae_clipped_0001_r", 
        "value": 0.4196, 
        "severity": 0, 
        "severity_value": 0.2098, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.4196%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_cosine_sim", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_cosine_sim", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_cosine_sim", 
        "value": 0.182, 
        "severity": 0, 
        "severity_value": -0.182, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim\n  Worst score: 0.182%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_cosine_sim", 
        "value": 0.182, 
        "severity": 0, 
        "severity_value": 0.091, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim\n  Best score: 0.182%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_cosine_sim", 
        "value": 0.2647, 
        "severity": 0, 
        "severity_value": -0.2647, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim\n  Worst score: 0.2647%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_cosine_sim", 
        "value": 0.2647, 
        "severity": 0, 
        "severity_value": 0.13235, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim\n  Best score: 0.2647%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_cosine_sim", 
        "value": 0.2297, 
        "severity": 0, 
        "severity_value": -0.2297, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim\n  Worst score: 0.2297%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_cosine_sim", 
        "value": 0.2297, 
        "severity": 0, 
        "severity_value": 0.11485, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim\n  Best score: 0.2297%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_cosine_sim", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_cosine_sim", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_cosine_sim", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_cosine_sim", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_cosine_sim", 
        "value": 0.4253, 
        "severity": 0, 
        "severity_value": -0.4253, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_cosine_sim\n  Worst score: 0.4253%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_cosine_sim", 
        "value": 0.4253, 
        "severity": 0, 
        "severity_value": 0.21265, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_cosine_sim\n  Best score: 0.4253%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_cosine_sim", 
        "value": 0.4716, 
        "severity": 0, 
        "severity_value": -0.4716, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim\n  Worst score: 0.4716%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_cosine_sim", 
        "value": 0.4716, 
        "severity": 0, 
        "severity_value": 0.2358, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim\n  Best score: 0.4716%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_cosine_sim", 
        "value": 0.3043, 
        "severity": 0, 
        "severity_value": -0.3043, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim\n  Worst score: 0.3043%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_cosine_sim", 
        "value": 0.3043, 
        "severity": 0, 
        "severity_value": 0.15215, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim\n  Best score: 0.3043%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_cosine_sim", 
        "value": 0.4529, 
        "severity": 0, 
        "severity_value": -0.4529, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim\n  Worst score: 0.4529%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_cosine_sim", 
        "value": 0.4529, 
        "severity": 0, 
        "severity_value": 0.22645, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim\n  Best score: 0.4529%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_cosine_sim", 
        "value": 0.1786, 
        "severity": 0, 
        "severity_value": -0.1786, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim\n  Worst score: 0.1786%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_cosine_sim", 
        "value": 0.1786, 
        "severity": 0, 
        "severity_value": 0.0893, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim\n  Best score: 0.1786%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_cosine_sim", 
        "value": 0.4402, 
        "severity": 0, 
        "severity_value": -0.4402, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim\n  Worst score: 0.4402%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_cosine_sim", 
        "value": 0.4402, 
        "severity": 0, 
        "severity_value": 0.2201, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim\n  Best score: 0.4402%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_cosine_sim_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_cosine_sim_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_cosine_sim_clipped_0001", 
        "value": 0.1844, 
        "severity": 0, 
        "severity_value": -0.1844, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.1844%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_cosine_sim_clipped_0001", 
        "value": 0.1844, 
        "severity": 0, 
        "severity_value": 0.0922, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.1844%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_cosine_sim_clipped_0001", 
        "value": 0.2638, 
        "severity": 0, 
        "severity_value": -0.2638, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.2638%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_cosine_sim_clipped_0001", 
        "value": 0.2638, 
        "severity": 0, 
        "severity_value": 0.1319, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.2638%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_cosine_sim_clipped_0001", 
        "value": 0.2228, 
        "severity": 0, 
        "severity_value": -0.2228, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.2228%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_cosine_sim_clipped_0001", 
        "value": 0.2228, 
        "severity": 0, 
        "severity_value": 0.1114, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.2228%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_cosine_sim_clipped_0001", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_cosine_sim_clipped_0001", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_cosine_sim_clipped_0001", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_cosine_sim_clipped_0001", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_cosine_sim_clipped_0001", 
        "value": 0.4236, 
        "severity": 0, 
        "severity_value": -0.4236, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.4236%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_cosine_sim_clipped_0001", 
        "value": 0.4236, 
        "severity": 0, 
        "severity_value": 0.2118, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.4236%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_cosine_sim_clipped_0001", 
        "value": 0.4656, 
        "severity": 0, 
        "severity_value": -0.4656, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.4656%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_cosine_sim_clipped_0001", 
        "value": 0.4656, 
        "severity": 0, 
        "severity_value": 0.2328, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.4656%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_cosine_sim_clipped_0001", 
        "value": 0.2924, 
        "severity": 0, 
        "severity_value": -0.2924, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.2924%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_cosine_sim_clipped_0001", 
        "value": 0.2924, 
        "severity": 0, 
        "severity_value": 0.1462, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.2924%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_cosine_sim_clipped_0001", 
        "value": 0.4473, 
        "severity": 0, 
        "severity_value": -0.4473, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.4473%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_cosine_sim_clipped_0001", 
        "value": 0.4473, 
        "severity": 0, 
        "severity_value": 0.22365, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.4473%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_cosine_sim_clipped_0001", 
        "value": 0.1839, 
        "severity": 0, 
        "severity_value": -0.1839, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.1839%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_cosine_sim_clipped_0001", 
        "value": 0.1839, 
        "severity": 0, 
        "severity_value": 0.09195, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.1839%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_cosine_sim_clipped_0001", 
        "value": 0.4357, 
        "severity": 0, 
        "severity_value": -0.4357, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.4357%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_cosine_sim_clipped_0001", 
        "value": 0.4357, 
        "severity": 0, 
        "severity_value": 0.21785, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.4357%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_cosine_sim_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim_r\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_cosine_sim_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim_r\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_cosine_sim_r", 
        "value": 0.2234, 
        "severity": 0, 
        "severity_value": -0.2234, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.2234%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_cosine_sim_r", 
        "value": 0.2234, 
        "severity": 0, 
        "severity_value": 0.1117, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim_r\n  Best score: 0.2234%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_cosine_sim_r", 
        "value": 0.3019, 
        "severity": 0, 
        "severity_value": -0.3019, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.3019%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_cosine_sim_r", 
        "value": 0.3019, 
        "severity": 0, 
        "severity_value": 0.15095, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim_r\n  Best score: 0.3019%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_cosine_sim_r", 
        "value": 0.2686, 
        "severity": 0, 
        "severity_value": -0.2686, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.2686%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_cosine_sim_r", 
        "value": 0.2686, 
        "severity": 0, 
        "severity_value": 0.1343, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim_r\n  Best score: 0.2686%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_cosine_sim_r", 
        "value": 0.0506, 
        "severity": 0, 
        "severity_value": -0.0506, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.0506%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_cosine_sim_r", 
        "value": 0.0506, 
        "severity": 0, 
        "severity_value": 0.0253, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim_r\n  Best score: 0.0506%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_cosine_sim_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim_r\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_cosine_sim_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim_r\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_cosine_sim_r", 
        "value": 0.4544, 
        "severity": 0, 
        "severity_value": -0.4544, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.4544%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_cosine_sim_r", 
        "value": 0.4544, 
        "severity": 0, 
        "severity_value": 0.2272, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_cosine_sim_r\n  Best score: 0.4544%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_cosine_sim_r", 
        "value": 0.4984, 
        "severity": 0, 
        "severity_value": -0.4984, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.4984%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_cosine_sim_r", 
        "value": 0.4984, 
        "severity": 0, 
        "severity_value": 0.2492, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim_r\n  Best score: 0.4984%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_cosine_sim_r", 
        "value": 0.3395, 
        "severity": 0, 
        "severity_value": -0.3395, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.3395%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_cosine_sim_r", 
        "value": 0.3395, 
        "severity": 0, 
        "severity_value": 0.16975, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim_r\n  Best score: 0.3395%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_cosine_sim_r", 
        "value": 0.4806, 
        "severity": 0, 
        "severity_value": -0.4806, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.4806%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_cosine_sim_r", 
        "value": 0.4806, 
        "severity": 0, 
        "severity_value": 0.2403, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim_r\n  Best score: 0.4806%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_cosine_sim_r", 
        "value": 0.2202, 
        "severity": 0, 
        "severity_value": -0.2202, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.2202%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_cosine_sim_r", 
        "value": 0.2202, 
        "severity": 0, 
        "severity_value": 0.1101, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim_r\n  Best score: 0.2202%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_cosine_sim_r", 
        "value": 0.4685, 
        "severity": 0, 
        "severity_value": -0.4685, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.4685%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_cosine_sim_r", 
        "value": 0.4685, 
        "severity": 0, 
        "severity_value": 0.23425, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim_r\n  Best score: 0.4685%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_cosine_sim_clipped_0001_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_cosine_sim_clipped_0001_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_cosine_sim_clipped_0001_r", 
        "value": 0.2264, 
        "severity": 0, 
        "severity_value": -0.2264, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.2264%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_cosine_sim_clipped_0001_r", 
        "value": 0.2264, 
        "severity": 0, 
        "severity_value": 0.1132, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.2264%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_cosine_sim_clipped_0001_r", 
        "value": 0.3017, 
        "severity": 0, 
        "severity_value": -0.3017, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.3017%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_cosine_sim_clipped_0001_r", 
        "value": 0.3017, 
        "severity": 0, 
        "severity_value": 0.15085, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.3017%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_cosine_sim_clipped_0001_r", 
        "value": 0.2628, 
        "severity": 0, 
        "severity_value": -0.2628, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.2628%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_cosine_sim_clipped_0001_r", 
        "value": 0.2628, 
        "severity": 0, 
        "severity_value": 0.1314, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.2628%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_cosine_sim_clipped_0001_r", 
        "value": 0.0515, 
        "severity": 0, 
        "severity_value": -0.0515, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.0515%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_cosine_sim_clipped_0001_r", 
        "value": 0.0515, 
        "severity": 0, 
        "severity_value": 0.02575, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.0515%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_cosine_sim_clipped_0001_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_cosine_sim_clipped_0001_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_cosine_sim_clipped_0001_r", 
        "value": 0.4533, 
        "severity": 0, 
        "severity_value": -0.4533, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.4533%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_cosine_sim_clipped_0001_r", 
        "value": 0.4533, 
        "severity": 0, 
        "severity_value": 0.22665, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.4533%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_cosine_sim_clipped_0001_r", 
        "value": 0.4931, 
        "severity": 0, 
        "severity_value": -0.4931, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.4931%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_cosine_sim_clipped_0001_r", 
        "value": 0.4931, 
        "severity": 0, 
        "severity_value": 0.24655, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.4931%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_cosine_sim_clipped_0001_r", 
        "value": 0.3289, 
        "severity": 0, 
        "severity_value": -0.3289, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.3289%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_cosine_sim_clipped_0001_r", 
        "value": 0.3289, 
        "severity": 0, 
        "severity_value": 0.16445, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.3289%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_cosine_sim_clipped_0001_r", 
        "value": 0.4758, 
        "severity": 0, 
        "severity_value": -0.4758, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.4758%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_cosine_sim_clipped_0001_r", 
        "value": 0.4758, 
        "severity": 0, 
        "severity_value": 0.2379, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.4758%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_cosine_sim_clipped_0001_r", 
        "value": 0.2259, 
        "severity": 0, 
        "severity_value": -0.2259, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.2259%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_cosine_sim_clipped_0001_r", 
        "value": 0.2259, 
        "severity": 0, 
        "severity_value": 0.11295, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.2259%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_cosine_sim_clipped_0001_r", 
        "value": 0.4648, 
        "severity": 0, 
        "severity_value": -0.4648, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.4648%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_cosine_sim_clipped_0001_r", 
        "value": 0.4648, 
        "severity": 0, 
        "severity_value": 0.2324, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.4648%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_pearson", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_pearson\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_pearson", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_pearson\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_pearson", 
        "value": 0.1758, 
        "severity": 0, 
        "severity_value": -0.1758, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_pearson\n  Worst score: 0.1758%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_pearson", 
        "value": 0.1758, 
        "severity": 0, 
        "severity_value": 0.0879, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_pearson\n  Best score: 0.1758%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_pearson", 
        "value": 0.261, 
        "severity": 0, 
        "severity_value": -0.261, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_pearson\n  Worst score: 0.261%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_pearson", 
        "value": 0.261, 
        "severity": 0, 
        "severity_value": 0.1305, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_pearson\n  Best score: 0.261%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_pearson", 
        "value": 0.2278, 
        "severity": 0, 
        "severity_value": -0.2278, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_pearson\n  Worst score: 0.2278%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_pearson", 
        "value": 0.2278, 
        "severity": 0, 
        "severity_value": 0.1139, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_pearson\n  Best score: 0.2278%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_pearson\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_pearson\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_pearson\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_pearson\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_pearson", 
        "value": 0.4223, 
        "severity": 0, 
        "severity_value": -0.4223, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_pearson\n  Worst score: 0.4223%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_pearson", 
        "value": 0.4223, 
        "severity": 0, 
        "severity_value": 0.21115, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_pearson\n  Best score: 0.4223%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_pearson", 
        "value": 0.4693, 
        "severity": 0, 
        "severity_value": -0.4693, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_pearson\n  Worst score: 0.4693%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_pearson", 
        "value": 0.4693, 
        "severity": 0, 
        "severity_value": 0.23465, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_pearson\n  Best score: 0.4693%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_pearson", 
        "value": 0.3037, 
        "severity": 0, 
        "severity_value": -0.3037, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_pearson\n  Worst score: 0.3037%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_pearson", 
        "value": 0.3037, 
        "severity": 0, 
        "severity_value": 0.15185, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_pearson\n  Best score: 0.3037%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_pearson", 
        "value": 0.4509, 
        "severity": 0, 
        "severity_value": -0.4509, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_pearson\n  Worst score: 0.4509%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_pearson", 
        "value": 0.4509, 
        "severity": 0, 
        "severity_value": 0.22545, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_pearson\n  Best score: 0.4509%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_pearson", 
        "value": 0.174, 
        "severity": 0, 
        "severity_value": -0.174, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_pearson\n  Worst score: 0.174%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_pearson", 
        "value": 0.174, 
        "severity": 0, 
        "severity_value": 0.087, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_pearson\n  Best score: 0.174%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_pearson", 
        "value": 0.4381, 
        "severity": 0, 
        "severity_value": -0.4381, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_pearson\n  Worst score: 0.4381%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_pearson", 
        "value": 0.4381, 
        "severity": 0, 
        "severity_value": 0.21905, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_pearson\n  Best score: 0.4381%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_spearman", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_spearman\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_spearman", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_spearman\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_spearman", 
        "value": 0.2183, 
        "severity": 0, 
        "severity_value": -0.2183, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_spearman\n  Worst score: 0.2183%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_spearman", 
        "value": 0.2183, 
        "severity": 0, 
        "severity_value": 0.10915, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_spearman\n  Best score: 0.2183%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_spearman", 
        "value": 0.2867, 
        "severity": 0, 
        "severity_value": -0.2867, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_spearman\n  Worst score: 0.2867%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_spearman", 
        "value": 0.2867, 
        "severity": 0, 
        "severity_value": 0.14335, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_spearman\n  Best score: 0.2867%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_spearman", 
        "value": 0.2489, 
        "severity": 0, 
        "severity_value": -0.2489, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_spearman\n  Worst score: 0.2489%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_spearman", 
        "value": 0.2489, 
        "severity": 0, 
        "severity_value": 0.12445, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_spearman\n  Best score: 0.2489%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_spearman", 
        "value": 0.0596, 
        "severity": 0, 
        "severity_value": -0.0596, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_spearman\n  Worst score: 0.0596%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_spearman", 
        "value": 0.0596, 
        "severity": 0, 
        "severity_value": 0.0298, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_spearman\n  Best score: 0.0596%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_spearman\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_spearman\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_spearman", 
        "value": 0.4283, 
        "severity": 0, 
        "severity_value": -0.4283, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_spearman\n  Worst score: 0.4283%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_spearman", 
        "value": 0.4283, 
        "severity": 0, 
        "severity_value": 0.21415, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_spearman\n  Best score: 0.4283%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_spearman", 
        "value": 0.4663, 
        "severity": 0, 
        "severity_value": -0.4663, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_spearman\n  Worst score: 0.4663%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_spearman", 
        "value": 0.4663, 
        "severity": 0, 
        "severity_value": 0.23315, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_spearman\n  Best score: 0.4663%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_spearman", 
        "value": 0.312, 
        "severity": 0, 
        "severity_value": -0.312, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_spearman\n  Worst score: 0.312%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_spearman", 
        "value": 0.312, 
        "severity": 0, 
        "severity_value": 0.156, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_spearman\n  Best score: 0.312%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_spearman", 
        "value": 0.4465, 
        "severity": 0, 
        "severity_value": -0.4465, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_spearman\n  Worst score: 0.4465%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_spearman", 
        "value": 0.4465, 
        "severity": 0, 
        "severity_value": 0.22325, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_spearman\n  Best score: 0.4465%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_spearman", 
        "value": 0.2222, 
        "severity": 0, 
        "severity_value": -0.2222, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_spearman\n  Worst score: 0.2222%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_spearman", 
        "value": 0.2222, 
        "severity": 0, 
        "severity_value": 0.1111, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_spearman\n  Best score: 0.2222%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_spearman", 
        "value": 0.4448, 
        "severity": 0, 
        "severity_value": -0.4448, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_spearman\n  Worst score: 0.4448%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_spearman", 
        "value": 0.4448, 
        "severity": 0, 
        "severity_value": 0.2224, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_spearman\n  Best score: 0.4448%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_pearson_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_pearson_r\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_pearson_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_pearson_r\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_pearson_r", 
        "value": 0.2153, 
        "severity": 0, 
        "severity_value": -0.2153, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_pearson_r\n  Worst score: 0.2153%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_pearson_r", 
        "value": 0.2153, 
        "severity": 0, 
        "severity_value": 0.10765, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_pearson_r\n  Best score: 0.2153%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_pearson_r", 
        "value": 0.2964, 
        "severity": 0, 
        "severity_value": -0.2964, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_pearson_r\n  Worst score: 0.2964%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_pearson_r", 
        "value": 0.2964, 
        "severity": 0, 
        "severity_value": 0.1482, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_pearson_r\n  Best score: 0.2964%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_pearson_r", 
        "value": 0.2648, 
        "severity": 0, 
        "severity_value": -0.2648, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_pearson_r\n  Worst score: 0.2648%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_pearson_r", 
        "value": 0.2648, 
        "severity": 0, 
        "severity_value": 0.1324, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_pearson_r\n  Best score: 0.2648%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_pearson_r", 
        "value": 0.0479, 
        "severity": 0, 
        "severity_value": -0.0479, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_pearson_r\n  Worst score: 0.0479%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_pearson_r", 
        "value": 0.0479, 
        "severity": 0, 
        "severity_value": 0.02395, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_pearson_r\n  Best score: 0.0479%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_pearson_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_pearson_r\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_pearson_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_pearson_r\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_pearson_r", 
        "value": 0.45, 
        "severity": 0, 
        "severity_value": -0.45, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_pearson_r\n  Worst score: 0.45%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_pearson_r", 
        "value": 0.45, 
        "severity": 0, 
        "severity_value": 0.225, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_pearson_r\n  Best score: 0.45%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_pearson_r", 
        "value": 0.4947, 
        "severity": 0, 
        "severity_value": -0.4947, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_pearson_r\n  Worst score: 0.4947%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_pearson_r", 
        "value": 0.4947, 
        "severity": 0, 
        "severity_value": 0.24735, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_pearson_r\n  Best score: 0.4947%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_pearson_r", 
        "value": 0.337, 
        "severity": 0, 
        "severity_value": -0.337, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_pearson_r\n  Worst score: 0.337%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_pearson_r", 
        "value": 0.337, 
        "severity": 0, 
        "severity_value": 0.1685, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_pearson_r\n  Best score: 0.337%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_pearson_r", 
        "value": 0.4773, 
        "severity": 0, 
        "severity_value": -0.4773, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_pearson_r\n  Worst score: 0.4773%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_pearson_r", 
        "value": 0.4773, 
        "severity": 0, 
        "severity_value": 0.23865, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_pearson_r\n  Best score: 0.4773%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_pearson_r", 
        "value": 0.2136, 
        "severity": 0, 
        "severity_value": -0.2136, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_pearson_r\n  Worst score: 0.2136%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_pearson_r", 
        "value": 0.2136, 
        "severity": 0, 
        "severity_value": 0.1068, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_pearson_r\n  Best score: 0.2136%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_pearson_r", 
        "value": 0.465, 
        "severity": 0, 
        "severity_value": -0.465, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_pearson_r\n  Worst score: 0.465%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_pearson_r", 
        "value": 0.465, 
        "severity": 0, 
        "severity_value": 0.2325, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_pearson_r\n  Best score: 0.465%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_spearman_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_spearman_r\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_spearman_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_spearman_r\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_spearman_r", 
        "value": 0.2118, 
        "severity": 0, 
        "severity_value": -0.2118, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_spearman_r\n  Worst score: 0.2118%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_spearman_r", 
        "value": 0.2118, 
        "severity": 0, 
        "severity_value": 0.1059, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_spearman_r\n  Best score: 0.2118%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_spearman_r", 
        "value": 0.2807, 
        "severity": 0, 
        "severity_value": -0.2807, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_spearman_r\n  Worst score: 0.2807%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_spearman_r", 
        "value": 0.2807, 
        "severity": 0, 
        "severity_value": 0.14035, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_spearman_r\n  Best score: 0.2807%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_spearman_r", 
        "value": 0.2426, 
        "severity": 0, 
        "severity_value": -0.2426, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_spearman_r\n  Worst score: 0.2426%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_spearman_r", 
        "value": 0.2426, 
        "severity": 0, 
        "severity_value": 0.1213, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_spearman_r\n  Best score: 0.2426%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_spearman_r", 
        "value": 0.0517, 
        "severity": 0, 
        "severity_value": -0.0517, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_spearman_r\n  Worst score: 0.0517%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_spearman_r", 
        "value": 0.0517, 
        "severity": 0, 
        "severity_value": 0.02585, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_spearman_r\n  Best score: 0.0517%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_spearman_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_spearman_r\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_spearman_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_spearman_r\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_spearman_r", 
        "value": 0.4235, 
        "severity": 0, 
        "severity_value": -0.4235, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_spearman_r\n  Worst score: 0.4235%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_spearman_r", 
        "value": 0.4235, 
        "severity": 0, 
        "severity_value": 0.21175, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_spearman_r\n  Best score: 0.4235%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_spearman_r", 
        "value": 0.4617, 
        "severity": 0, 
        "severity_value": -0.4617, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_spearman_r\n  Worst score: 0.4617%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_spearman_r", 
        "value": 0.4617, 
        "severity": 0, 
        "severity_value": 0.23085, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_spearman_r\n  Best score: 0.4617%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_spearman_r", 
        "value": 0.3062, 
        "severity": 0, 
        "severity_value": -0.3062, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_spearman_r\n  Worst score: 0.3062%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_spearman_r", 
        "value": 0.3062, 
        "severity": 0, 
        "severity_value": 0.1531, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_spearman_r\n  Best score: 0.3062%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_spearman_r", 
        "value": 0.4418, 
        "severity": 0, 
        "severity_value": -0.4418, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_spearman_r\n  Worst score: 0.4418%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_spearman_r", 
        "value": 0.4418, 
        "severity": 0, 
        "severity_value": 0.2209, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_spearman_r\n  Best score: 0.4418%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_spearman_r", 
        "value": 0.2157, 
        "severity": 0, 
        "severity_value": -0.2157, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_spearman_r\n  Worst score: 0.2157%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_spearman_r", 
        "value": 0.2157, 
        "severity": 0, 
        "severity_value": 0.10785, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_spearman_r\n  Best score: 0.2157%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_spearman_r", 
        "value": 0.4401, 
        "severity": 0, 
        "severity_value": -0.4401, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_spearman_r\n  Worst score: 0.4401%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_spearman_r", 
        "value": 0.4401, 
        "severity": 0, 
        "severity_value": 0.22005, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_spearman_r\n  Best score: 0.4401%\n"
    }
]