[
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Task info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Task info", 
        "name": "Pct 'task_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_name' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_name\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Task info", 
        "name": "Pct 'task_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_summary' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_summary\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Task info", 
        "name": "Pct 'task_description' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_description' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_description\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'task_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'commit_sha' should be defined\n  Task id: dge_perturbation_prediction\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'method_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: method_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'method_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_name' should be defined\n  Task id: dge_perturbation_prediction\n  Field: method_name\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'method_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_summary' should be defined\n  Task id: dge_perturbation_prediction\n  Field: method_summary\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 0.4166666666666667, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'paper_reference' should be defined\n  Task id: dge_perturbation_prediction\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Method info", 
        "name": "Pct 'is_baseline' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'is_baseline' should be defined\n  Task id: dge_perturbation_prediction\n  Field: is_baseline\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'task_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'commit_sha' should be defined\n  Task id: dge_perturbation_prediction\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'metric_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: metric_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'metric_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_name' should be defined\n  Task id: dge_perturbation_prediction\n  Field: metric_name\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'metric_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_summary' should be defined\n  Task id: dge_perturbation_prediction\n  Field: metric_summary\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 1.0, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'paper_reference' should be defined\n  Task id: dge_perturbation_prediction\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Metric info", 
        "name": "Pct 'maximize' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'maximize' should be defined\n  Task id: dge_perturbation_prediction\n  Field: maximize\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'task_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: task_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_id' should be defined\n  Task id: dge_perturbation_prediction\n  Field: dataset_id\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_name' should be defined\n  Task id: dge_perturbation_prediction\n  Field: dataset_name\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_summary' should be defined\n  Task id: dge_perturbation_prediction\n  Field: dataset_summary\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'data_reference' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_reference' should be defined\n  Task id: dge_perturbation_prediction\n  Field: data_reference\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Dataset info", 
        "name": "Pct 'data_url' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_url' should be defined\n  Task id: dge_perturbation_prediction\n  Field: data_url\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw data", 
        "name": "Number of results", 
        "value": 24, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "len(results) == len(method_info) * len(metric_info) * len(dataset_info)", 
        "message": "Number of results should be equal to #methods × #metrics × #datasets.\n  Task id: dge_perturbation_prediction\n  Number of results: 24\n  Number of methods: 12\n  Number of metrics: 16\n  Number of datasets: 2\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_rmse' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_rmse\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_rmse_clipped_0001' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_mae' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_mae\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_mae_clipped_0001' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_mae_clipped_0001\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_rmse_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_rmse_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_rmse_clipped_0001_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_mae_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_mae_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_rowwise_mae_clipped_0001_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_cosine_sim' %missing", 
        "value": 0.08333333333333337, 
        "severity": 0, 
        "severity_value": 0.8333333333333337, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_cosine_sim\n  Percentage missing: 8%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_cosine_sim_clipped_0001' %missing", 
        "value": 0.08333333333333337, 
        "severity": 0, 
        "severity_value": 0.8333333333333337, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_cosine_sim_clipped_0001\n  Percentage missing: 8%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_cosine_sim_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_cosine_sim_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_cosine_sim_clipped_0001_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_pearson' %missing", 
        "value": 0.08333333333333337, 
        "severity": 0, 
        "severity_value": 0.8333333333333337, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_pearson\n  Percentage missing: 8%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_spearman' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_spearman\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_pearson_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_pearson_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Metric 'mean_spearman_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  Metric id: mean_spearman_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'ground_truth' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: ground_truth\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'mean_outcome' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: mean_outcome\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'mean_across_celltypes' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: mean_across_celltypes\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'mean_across_compounds' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: mean_across_compounds\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'sample' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: sample\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'zeros' %missing", 
        "value": 0.1875, 
        "severity": 1, 
        "severity_value": 1.875, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: zeros\n  Percentage missing: 19%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'lgc_ensemble' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: lgc_ensemble\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'nn_retraining_with_pseudolabels' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: nn_retraining_with_pseudolabels\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'jn_ap_op2' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: jn_ap_op2\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'scape' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: scape\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'transformer_ensemble' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: transformer_ensemble\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Method 'pyboost' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  method id: pyboost\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Dataset 'neurips-2023-data' %missing", 
        "value": 0.015625, 
        "severity": 0, 
        "severity_value": 0.15625, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  dataset id: neurips-2023-data\n  Percentage missing: 2%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Raw results", 
        "name": "Dataset 'neurips-2023-kaggle' %missing", 
        "value": 0.015625, 
        "severity": 0, 
        "severity_value": 0.15625, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: dge_perturbation_prediction\n  dataset id: neurips-2023-kaggle\n  Percentage missing: 2%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_rmse", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_rmse", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_rmse", 
        "value": 0.4793, 
        "severity": 0, 
        "severity_value": -0.4793, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.4793%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_rmse", 
        "value": 0.5678, 
        "severity": 0, 
        "severity_value": 0.2839, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse\n  Best score: 0.5678%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_rmse", 
        "value": 0.1743, 
        "severity": 0, 
        "severity_value": -0.1743, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.1743%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_rmse", 
        "value": 0.538, 
        "severity": 0, 
        "severity_value": 0.269, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse\n  Best score: 0.538%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_rmse", 
        "value": 0.5149, 
        "severity": 0, 
        "severity_value": -0.5149, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.5149%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_rmse", 
        "value": 0.5824, 
        "severity": 0, 
        "severity_value": 0.2912, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse\n  Best score: 0.5824%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_rmse", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_rmse", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_rmse", 
        "value": 0.4811, 
        "severity": 0, 
        "severity_value": -0.4811, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.4811%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_rmse", 
        "value": 0.5746, 
        "severity": 0, 
        "severity_value": 0.2873, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse\n  Best score: 0.5746%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_rowwise_rmse", 
        "value": 0.552, 
        "severity": 0, 
        "severity_value": -0.552, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.552%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_rowwise_rmse", 
        "value": 0.6523, 
        "severity": 0, 
        "severity_value": 0.32615, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_rmse\n  Best score: 0.6523%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_rmse", 
        "value": 0.5731, 
        "severity": 0, 
        "severity_value": -0.5731, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.5731%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_rmse", 
        "value": 0.6546, 
        "severity": 0, 
        "severity_value": 0.3273, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse\n  Best score: 0.6546%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_rmse", 
        "value": 0.5575, 
        "severity": 0, 
        "severity_value": -0.5575, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.5575%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_rmse", 
        "value": 0.6043, 
        "severity": 0, 
        "severity_value": 0.30215, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse\n  Best score: 0.6043%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_rmse", 
        "value": 0.5676, 
        "severity": 0, 
        "severity_value": -0.5676, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.5676%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_rmse", 
        "value": 0.6538, 
        "severity": 0, 
        "severity_value": 0.3269, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse\n  Best score: 0.6538%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_rmse", 
        "value": 0.4889, 
        "severity": 0, 
        "severity_value": -0.4889, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.4889%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_rmse", 
        "value": 0.5802, 
        "severity": 0, 
        "severity_value": 0.2901, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse\n  Best score: 0.5802%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_rmse", 
        "value": 0.5637, 
        "severity": 0, 
        "severity_value": -0.5637, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse\n  Worst score: 0.5637%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_rmse", 
        "value": 0.6379, 
        "severity": 0, 
        "severity_value": 0.31895, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse\n  Best score: 0.6379%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_rmse_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_rmse_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_rmse_clipped_0001", 
        "value": 0.3047, 
        "severity": 0, 
        "severity_value": -0.3047, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.3047%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_rmse_clipped_0001", 
        "value": 0.4353, 
        "severity": 0, 
        "severity_value": 0.21765, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.4353%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_rmse_clipped_0001", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_rmse_clipped_0001", 
        "value": 0.2271, 
        "severity": 0, 
        "severity_value": 0.11355, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.2271%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_rmse_clipped_0001", 
        "value": 0.2981, 
        "severity": 0, 
        "severity_value": -0.2981, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.2981%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_rmse_clipped_0001", 
        "value": 0.4607, 
        "severity": 0, 
        "severity_value": 0.23035, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.4607%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_rmse_clipped_0001", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_rmse_clipped_0001", 
        "value": 0.1949, 
        "severity": 0, 
        "severity_value": 0.09745, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.1949%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_rmse_clipped_0001", 
        "value": 0.3265, 
        "severity": 0, 
        "severity_value": -0.3265, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.3265%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_rmse_clipped_0001", 
        "value": 0.44, 
        "severity": 0, 
        "severity_value": 0.22, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.44%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_rowwise_rmse_clipped_0001", 
        "value": 0.4227, 
        "severity": 0, 
        "severity_value": -0.4227, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.4227%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_rowwise_rmse_clipped_0001", 
        "value": 0.4846, 
        "severity": 0, 
        "severity_value": 0.2423, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.4846%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_rmse_clipped_0001", 
        "value": 0.4262, 
        "severity": 0, 
        "severity_value": -0.4262, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.4262%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_rmse_clipped_0001", 
        "value": 0.5289, 
        "severity": 0, 
        "severity_value": 0.26445, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.5289%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_rmse_clipped_0001", 
        "value": 0.3276, 
        "severity": 0, 
        "severity_value": -0.3276, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.3276%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_rmse_clipped_0001", 
        "value": 0.5055, 
        "severity": 0, 
        "severity_value": 0.25275, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.5055%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_rmse_clipped_0001", 
        "value": 0.4135, 
        "severity": 0, 
        "severity_value": -0.4135, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.4135%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_rmse_clipped_0001", 
        "value": 0.5145, 
        "severity": 0, 
        "severity_value": 0.25725, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.5145%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_rmse_clipped_0001", 
        "value": 0.3417, 
        "severity": 0, 
        "severity_value": -0.3417, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.3417%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_rmse_clipped_0001", 
        "value": 0.4537, 
        "severity": 0, 
        "severity_value": 0.22685, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.4537%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_rmse_clipped_0001", 
        "value": 0.4255, 
        "severity": 0, 
        "severity_value": -0.4255, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Worst score: 0.4255%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_rmse_clipped_0001", 
        "value": 0.5273, 
        "severity": 0, 
        "severity_value": 0.26365, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse_clipped_0001\n  Best score: 0.5273%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_mae", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_mae", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_mae", 
        "value": 0.3695, 
        "severity": 0, 
        "severity_value": -0.3695, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae\n  Worst score: 0.3695%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_mae", 
        "value": 0.4199, 
        "severity": 0, 
        "severity_value": 0.20995, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae\n  Best score: 0.4199%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_mae", 
        "value": 0.3081, 
        "severity": 0, 
        "severity_value": 0.15405, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae\n  Best score: 0.3081%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_mae", 
        "value": 0.3383, 
        "severity": 0, 
        "severity_value": -0.3383, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae\n  Worst score: 0.3383%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_mae", 
        "value": 0.4537, 
        "severity": 0, 
        "severity_value": 0.22685, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae\n  Best score: 0.4537%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_mae", 
        "value": 0.1597, 
        "severity": 0, 
        "severity_value": 0.07985, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae\n  Best score: 0.1597%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_mae", 
        "value": 0.4059, 
        "severity": 0, 
        "severity_value": -0.4059, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae\n  Worst score: 0.4059%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_mae", 
        "value": 0.4434, 
        "severity": 0, 
        "severity_value": 0.2217, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae\n  Best score: 0.4434%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_rowwise_mae", 
        "value": 0.4739, 
        "severity": 0, 
        "severity_value": -0.4739, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_mae\n  Worst score: 0.4739%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_rowwise_mae", 
        "value": 0.4843, 
        "severity": 0, 
        "severity_value": 0.24215, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_mae\n  Best score: 0.4843%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_mae", 
        "value": 0.4709, 
        "severity": 0, 
        "severity_value": -0.4709, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae\n  Worst score: 0.4709%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_mae", 
        "value": 0.5257, 
        "severity": 0, 
        "severity_value": 0.26285, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae\n  Best score: 0.5257%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_mae", 
        "value": 0.3782, 
        "severity": 0, 
        "severity_value": -0.3782, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae\n  Worst score: 0.3782%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_mae", 
        "value": 0.5046, 
        "severity": 0, 
        "severity_value": 0.2523, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae\n  Best score: 0.5046%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_mae", 
        "value": 0.4613, 
        "severity": 0, 
        "severity_value": -0.4613, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae\n  Worst score: 0.4613%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_mae", 
        "value": 0.5134, 
        "severity": 0, 
        "severity_value": 0.2567, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae\n  Best score: 0.5134%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_mae", 
        "value": 0.4107, 
        "severity": 0, 
        "severity_value": -0.4107, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae\n  Worst score: 0.4107%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_mae", 
        "value": 0.4515, 
        "severity": 0, 
        "severity_value": 0.22575, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae\n  Best score: 0.4515%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_mae", 
        "value": 0.4772, 
        "severity": 0, 
        "severity_value": -0.4772, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae\n  Worst score: 0.4772%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_mae", 
        "value": 0.5247, 
        "severity": 0, 
        "severity_value": 0.26235, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae\n  Best score: 0.5247%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_mae_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_mae_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_mae_clipped_0001", 
        "value": 0.2945, 
        "severity": 0, 
        "severity_value": -0.2945, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.2945%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_mae_clipped_0001", 
        "value": 0.4464, 
        "severity": 0, 
        "severity_value": 0.2232, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.4464%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_mae_clipped_0001", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_mae_clipped_0001", 
        "value": 0.22, 
        "severity": 0, 
        "severity_value": 0.11, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.22%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_mae_clipped_0001", 
        "value": 0.2685, 
        "severity": 0, 
        "severity_value": -0.2685, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.2685%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_mae_clipped_0001", 
        "value": 0.4837, 
        "severity": 0, 
        "severity_value": 0.24185, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.4837%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_mae_clipped_0001", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_mae_clipped_0001", 
        "value": 0.2475, 
        "severity": 0, 
        "severity_value": 0.12375, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.2475%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_mae_clipped_0001", 
        "value": 0.3404, 
        "severity": 0, 
        "severity_value": -0.3404, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.3404%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_mae_clipped_0001", 
        "value": 0.4754, 
        "severity": 0, 
        "severity_value": 0.2377, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.4754%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_rowwise_mae_clipped_0001", 
        "value": 0.4188, 
        "severity": 0, 
        "severity_value": -0.4188, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.4188%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_rowwise_mae_clipped_0001", 
        "value": 0.5075, 
        "severity": 0, 
        "severity_value": 0.25375, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.5075%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_mae_clipped_0001", 
        "value": 0.4189, 
        "severity": 0, 
        "severity_value": -0.4189, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.4189%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_mae_clipped_0001", 
        "value": 0.5564, 
        "severity": 0, 
        "severity_value": 0.2782, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.5564%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_mae_clipped_0001", 
        "value": 0.3123, 
        "severity": 0, 
        "severity_value": -0.3123, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.3123%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_mae_clipped_0001", 
        "value": 0.5315, 
        "severity": 0, 
        "severity_value": 0.26575, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.5315%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_mae_clipped_0001", 
        "value": 0.4034, 
        "severity": 0, 
        "severity_value": -0.4034, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.4034%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_mae_clipped_0001", 
        "value": 0.539, 
        "severity": 0, 
        "severity_value": 0.2695, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.539%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_mae_clipped_0001", 
        "value": 0.3465, 
        "severity": 0, 
        "severity_value": -0.3465, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.3465%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_mae_clipped_0001", 
        "value": 0.4854, 
        "severity": 0, 
        "severity_value": 0.2427, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.4854%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_mae_clipped_0001", 
        "value": 0.4246, 
        "severity": 0, 
        "severity_value": -0.4246, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae_clipped_0001\n  Worst score: 0.4246%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_mae_clipped_0001", 
        "value": 0.5581, 
        "severity": 0, 
        "severity_value": 0.27905, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae_clipped_0001\n  Best score: 0.5581%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_rmse_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_rmse_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse_r\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_rmse_r", 
        "value": 0.4793, 
        "severity": 0, 
        "severity_value": -0.4793, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.4793%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_rmse_r", 
        "value": 0.5678, 
        "severity": 0, 
        "severity_value": 0.2839, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.5678%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_rmse_r", 
        "value": 0.1743, 
        "severity": 0, 
        "severity_value": -0.1743, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.1743%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_rmse_r", 
        "value": 0.538, 
        "severity": 0, 
        "severity_value": 0.269, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.538%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_rmse_r", 
        "value": 0.5149, 
        "severity": 0, 
        "severity_value": -0.5149, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.5149%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_rmse_r", 
        "value": 0.5824, 
        "severity": 0, 
        "severity_value": 0.2912, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.5824%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_rmse_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_rmse_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_rmse_r", 
        "value": 0.4811, 
        "severity": 0, 
        "severity_value": -0.4811, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.4811%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_rmse_r", 
        "value": 0.5746, 
        "severity": 0, 
        "severity_value": 0.2873, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.5746%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_rowwise_rmse_r", 
        "value": 0.552, 
        "severity": 0, 
        "severity_value": -0.552, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.552%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_rowwise_rmse_r", 
        "value": 0.6523, 
        "severity": 0, 
        "severity_value": 0.32615, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.6523%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_rmse_r", 
        "value": 0.5731, 
        "severity": 0, 
        "severity_value": -0.5731, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.5731%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_rmse_r", 
        "value": 0.6546, 
        "severity": 0, 
        "severity_value": 0.3273, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.6546%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_rmse_r", 
        "value": 0.5575, 
        "severity": 0, 
        "severity_value": -0.5575, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.5575%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_rmse_r", 
        "value": 0.6043, 
        "severity": 0, 
        "severity_value": 0.30215, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.6043%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_rmse_r", 
        "value": 0.5676, 
        "severity": 0, 
        "severity_value": -0.5676, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.5676%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_rmse_r", 
        "value": 0.6538, 
        "severity": 0, 
        "severity_value": 0.3269, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.6538%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_rmse_r", 
        "value": 0.4889, 
        "severity": 0, 
        "severity_value": -0.4889, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.4889%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_rmse_r", 
        "value": 0.5802, 
        "severity": 0, 
        "severity_value": 0.2901, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.5802%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_rmse_r", 
        "value": 0.5637, 
        "severity": 0, 
        "severity_value": -0.5637, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse_r\n  Worst score: 0.5637%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_rmse_r", 
        "value": 0.6379, 
        "severity": 0, 
        "severity_value": 0.31895, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse_r\n  Best score: 0.6379%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_rmse_clipped_0001_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_rmse_clipped_0001_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.3047, 
        "severity": 0, 
        "severity_value": -0.3047, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.3047%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.4353, 
        "severity": 0, 
        "severity_value": 0.21765, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.4353%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.2271, 
        "severity": 0, 
        "severity_value": 0.11355, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.2271%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.2981, 
        "severity": 0, 
        "severity_value": -0.2981, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.2981%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.4607, 
        "severity": 0, 
        "severity_value": 0.23035, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.4607%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.1949, 
        "severity": 0, 
        "severity_value": 0.09745, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.1949%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.3265, 
        "severity": 0, 
        "severity_value": -0.3265, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.3265%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.44, 
        "severity": 0, 
        "severity_value": 0.22, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.44%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.4227, 
        "severity": 0, 
        "severity_value": -0.4227, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.4227%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.4846, 
        "severity": 0, 
        "severity_value": 0.2423, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.4846%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.4262, 
        "severity": 0, 
        "severity_value": -0.4262, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.4262%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.5289, 
        "severity": 0, 
        "severity_value": 0.26445, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.5289%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.3276, 
        "severity": 0, 
        "severity_value": -0.3276, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.3276%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.5055, 
        "severity": 0, 
        "severity_value": 0.25275, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.5055%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.4135, 
        "severity": 0, 
        "severity_value": -0.4135, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.4135%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.5145, 
        "severity": 0, 
        "severity_value": 0.25725, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.5145%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.3417, 
        "severity": 0, 
        "severity_value": -0.3417, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.3417%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.4537, 
        "severity": 0, 
        "severity_value": 0.22685, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.4537%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.4255, 
        "severity": 0, 
        "severity_value": -0.4255, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Worst score: 0.4255%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_rmse_clipped_0001_r", 
        "value": 0.5273, 
        "severity": 0, 
        "severity_value": 0.26365, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_rmse_clipped_0001_r\n  Best score: 0.5273%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_mae_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae_r\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_mae_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae_r\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_mae_r", 
        "value": 0.3695, 
        "severity": 0, 
        "severity_value": -0.3695, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.3695%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_mae_r", 
        "value": 0.4199, 
        "severity": 0, 
        "severity_value": 0.20995, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.4199%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_mae_r", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_mae_r", 
        "value": 0.3081, 
        "severity": 0, 
        "severity_value": 0.15405, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.3081%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_mae_r", 
        "value": 0.3383, 
        "severity": 0, 
        "severity_value": -0.3383, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.3383%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_mae_r", 
        "value": 0.4537, 
        "severity": 0, 
        "severity_value": 0.22685, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.4537%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_mae_r", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_mae_r", 
        "value": 0.1597, 
        "severity": 0, 
        "severity_value": 0.07985, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.1597%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_mae_r", 
        "value": 0.4059, 
        "severity": 0, 
        "severity_value": -0.4059, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.4059%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_mae_r", 
        "value": 0.4434, 
        "severity": 0, 
        "severity_value": 0.2217, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.4434%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_rowwise_mae_r", 
        "value": 0.4739, 
        "severity": 0, 
        "severity_value": -0.4739, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.4739%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_rowwise_mae_r", 
        "value": 0.4843, 
        "severity": 0, 
        "severity_value": 0.24215, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.4843%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_mae_r", 
        "value": 0.4709, 
        "severity": 0, 
        "severity_value": -0.4709, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.4709%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_mae_r", 
        "value": 0.5257, 
        "severity": 0, 
        "severity_value": 0.26285, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.5257%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_mae_r", 
        "value": 0.3782, 
        "severity": 0, 
        "severity_value": -0.3782, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.3782%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_mae_r", 
        "value": 0.5046, 
        "severity": 0, 
        "severity_value": 0.2523, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.5046%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_mae_r", 
        "value": 0.4613, 
        "severity": 0, 
        "severity_value": -0.4613, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.4613%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_mae_r", 
        "value": 0.5134, 
        "severity": 0, 
        "severity_value": 0.2567, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.5134%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_mae_r", 
        "value": 0.4107, 
        "severity": 0, 
        "severity_value": -0.4107, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.4107%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_mae_r", 
        "value": 0.4515, 
        "severity": 0, 
        "severity_value": 0.22575, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.4515%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_mae_r", 
        "value": 0.4772, 
        "severity": 0, 
        "severity_value": -0.4772, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae_r\n  Worst score: 0.4772%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_mae_r", 
        "value": 0.5247, 
        "severity": 0, 
        "severity_value": 0.26235, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae_r\n  Best score: 0.5247%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_rowwise_mae_clipped_0001_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_rowwise_mae_clipped_0001_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_rowwise_mae_clipped_0001_r", 
        "value": 0.2945, 
        "severity": 0, 
        "severity_value": -0.2945, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.2945%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_rowwise_mae_clipped_0001_r", 
        "value": 0.4464, 
        "severity": 0, 
        "severity_value": 0.2232, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.4464%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_rowwise_mae_clipped_0001_r", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_rowwise_mae_clipped_0001_r", 
        "value": 0.22, 
        "severity": 0, 
        "severity_value": 0.11, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.22%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_rowwise_mae_clipped_0001_r", 
        "value": 0.2685, 
        "severity": 0, 
        "severity_value": -0.2685, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.2685%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_rowwise_mae_clipped_0001_r", 
        "value": 0.4837, 
        "severity": 0, 
        "severity_value": 0.24185, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.4837%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_rowwise_mae_clipped_0001_r", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_rowwise_mae_clipped_0001_r", 
        "value": 0.2475, 
        "severity": 0, 
        "severity_value": 0.12375, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.2475%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_rowwise_mae_clipped_0001_r", 
        "value": 0.3404, 
        "severity": 0, 
        "severity_value": -0.3404, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.3404%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_rowwise_mae_clipped_0001_r", 
        "value": 0.4754, 
        "severity": 0, 
        "severity_value": 0.2377, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.4754%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_rowwise_mae_clipped_0001_r", 
        "value": 0.4188, 
        "severity": 0, 
        "severity_value": -0.4188, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.4188%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_rowwise_mae_clipped_0001_r", 
        "value": 0.5075, 
        "severity": 0, 
        "severity_value": 0.25375, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.5075%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_rowwise_mae_clipped_0001_r", 
        "value": 0.4189, 
        "severity": 0, 
        "severity_value": -0.4189, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.4189%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_rowwise_mae_clipped_0001_r", 
        "value": 0.5564, 
        "severity": 0, 
        "severity_value": 0.2782, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.5564%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_rowwise_mae_clipped_0001_r", 
        "value": 0.3123, 
        "severity": 0, 
        "severity_value": -0.3123, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.3123%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_rowwise_mae_clipped_0001_r", 
        "value": 0.5315, 
        "severity": 0, 
        "severity_value": 0.26575, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.5315%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_rowwise_mae_clipped_0001_r", 
        "value": 0.4034, 
        "severity": 0, 
        "severity_value": -0.4034, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.4034%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_rowwise_mae_clipped_0001_r", 
        "value": 0.539, 
        "severity": 0, 
        "severity_value": 0.2695, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.539%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_rowwise_mae_clipped_0001_r", 
        "value": 0.3465, 
        "severity": 0, 
        "severity_value": -0.3465, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.3465%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_rowwise_mae_clipped_0001_r", 
        "value": 0.4854, 
        "severity": 0, 
        "severity_value": 0.2427, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.4854%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_rowwise_mae_clipped_0001_r", 
        "value": 0.4246, 
        "severity": 0, 
        "severity_value": -0.4246, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Worst score: 0.4246%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_rowwise_mae_clipped_0001_r", 
        "value": 0.5581, 
        "severity": 0, 
        "severity_value": 0.27905, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_rowwise_mae_clipped_0001_r\n  Best score: 0.5581%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_cosine_sim", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_cosine_sim", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_cosine_sim", 
        "value": 0.1602, 
        "severity": 0, 
        "severity_value": -0.1602, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim\n  Worst score: 0.1602%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_cosine_sim", 
        "value": 0.2076, 
        "severity": 0, 
        "severity_value": 0.1038, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim\n  Best score: 0.2076%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_cosine_sim", 
        "value": 0.2161, 
        "severity": 0, 
        "severity_value": -0.2161, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim\n  Worst score: 0.2161%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_cosine_sim", 
        "value": 0.2742, 
        "severity": 0, 
        "severity_value": 0.1371, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim\n  Best score: 0.2742%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_cosine_sim", 
        "value": 0.2206, 
        "severity": 0, 
        "severity_value": -0.2206, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim\n  Worst score: 0.2206%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_cosine_sim", 
        "value": 0.2701, 
        "severity": 0, 
        "severity_value": 0.13505, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim\n  Best score: 0.2701%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_cosine_sim", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_cosine_sim", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_cosine_sim", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_cosine_sim", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_cosine_sim", 
        "value": 0.3697, 
        "severity": 0, 
        "severity_value": -0.3697, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_cosine_sim\n  Worst score: 0.3697%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_cosine_sim", 
        "value": 0.4435, 
        "severity": 0, 
        "severity_value": 0.22175, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_cosine_sim\n  Best score: 0.4435%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_cosine_sim", 
        "value": 0.382, 
        "severity": 0, 
        "severity_value": -0.382, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim\n  Worst score: 0.382%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_cosine_sim", 
        "value": 0.471, 
        "severity": 0, 
        "severity_value": 0.2355, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim\n  Best score: 0.471%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_cosine_sim", 
        "value": 0.328, 
        "severity": 0, 
        "severity_value": -0.328, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim\n  Worst score: 0.328%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_cosine_sim", 
        "value": 0.336, 
        "severity": 0, 
        "severity_value": 0.168, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim\n  Best score: 0.336%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_cosine_sim", 
        "value": 0.3565, 
        "severity": 0, 
        "severity_value": -0.3565, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim\n  Worst score: 0.3565%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_cosine_sim", 
        "value": 0.4425, 
        "severity": 0, 
        "severity_value": 0.22125, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim\n  Best score: 0.4425%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_cosine_sim", 
        "value": 0.1811, 
        "severity": 0, 
        "severity_value": -0.1811, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim\n  Worst score: 0.1811%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_cosine_sim", 
        "value": 0.1814, 
        "severity": 0, 
        "severity_value": 0.0907, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim\n  Best score: 0.1814%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_cosine_sim", 
        "value": 0.3617, 
        "severity": 0, 
        "severity_value": -0.3617, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim\n  Worst score: 0.3617%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_cosine_sim", 
        "value": 0.4508, 
        "severity": 0, 
        "severity_value": 0.2254, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim\n  Best score: 0.4508%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_cosine_sim_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_cosine_sim_clipped_0001", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_cosine_sim_clipped_0001", 
        "value": 0.144, 
        "severity": 0, 
        "severity_value": -0.144, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.144%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_cosine_sim_clipped_0001", 
        "value": 0.2063, 
        "severity": 0, 
        "severity_value": 0.10315, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.2063%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_cosine_sim_clipped_0001", 
        "value": 0.2025, 
        "severity": 0, 
        "severity_value": -0.2025, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.2025%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_cosine_sim_clipped_0001", 
        "value": 0.2681, 
        "severity": 0, 
        "severity_value": 0.13405, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.2681%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_cosine_sim_clipped_0001", 
        "value": 0.2013, 
        "severity": 0, 
        "severity_value": -0.2013, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.2013%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_cosine_sim_clipped_0001", 
        "value": 0.2211, 
        "severity": 0, 
        "severity_value": 0.11055, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.2211%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_cosine_sim_clipped_0001", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_cosine_sim_clipped_0001", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_cosine_sim_clipped_0001", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_cosine_sim_clipped_0001", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_cosine_sim_clipped_0001", 
        "value": 0.3599, 
        "severity": 0, 
        "severity_value": -0.3599, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.3599%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_cosine_sim_clipped_0001", 
        "value": 0.4083, 
        "severity": 0, 
        "severity_value": 0.20415, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.4083%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_cosine_sim_clipped_0001", 
        "value": 0.3682, 
        "severity": 0, 
        "severity_value": -0.3682, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.3682%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_cosine_sim_clipped_0001", 
        "value": 0.4379, 
        "severity": 0, 
        "severity_value": 0.21895, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.4379%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_cosine_sim_clipped_0001", 
        "value": 0.2773, 
        "severity": 0, 
        "severity_value": -0.2773, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.2773%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_cosine_sim_clipped_0001", 
        "value": 0.3165, 
        "severity": 0, 
        "severity_value": 0.15825, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.3165%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_cosine_sim_clipped_0001", 
        "value": 0.3421, 
        "severity": 0, 
        "severity_value": -0.3421, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.3421%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_cosine_sim_clipped_0001", 
        "value": 0.404, 
        "severity": 0, 
        "severity_value": 0.202, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.404%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_cosine_sim_clipped_0001", 
        "value": 0.1823, 
        "severity": 0, 
        "severity_value": -0.1823, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.1823%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_cosine_sim_clipped_0001", 
        "value": 0.1863, 
        "severity": 0, 
        "severity_value": 0.09315, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.1863%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_cosine_sim_clipped_0001", 
        "value": 0.3527, 
        "severity": 0, 
        "severity_value": -0.3527, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim_clipped_0001\n  Worst score: 0.3527%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_cosine_sim_clipped_0001", 
        "value": 0.4306, 
        "severity": 0, 
        "severity_value": 0.2153, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim_clipped_0001\n  Best score: 0.4306%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_cosine_sim_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim_r\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_cosine_sim_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim_r\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_cosine_sim_r", 
        "value": 0.1845, 
        "severity": 0, 
        "severity_value": -0.1845, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.1845%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_cosine_sim_r", 
        "value": 0.2508, 
        "severity": 0, 
        "severity_value": 0.1254, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim_r\n  Best score: 0.2508%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_cosine_sim_r", 
        "value": 0.2388, 
        "severity": 0, 
        "severity_value": -0.2388, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.2388%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_cosine_sim_r", 
        "value": 0.3137, 
        "severity": 0, 
        "severity_value": 0.15685, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim_r\n  Best score: 0.3137%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_cosine_sim_r", 
        "value": 0.2631, 
        "severity": 0, 
        "severity_value": -0.2631, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.2631%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_cosine_sim_r", 
        "value": 0.2912, 
        "severity": 0, 
        "severity_value": 0.1456, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim_r\n  Best score: 0.2912%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_cosine_sim_r", 
        "value": 0.0289, 
        "severity": 0, 
        "severity_value": -0.0289, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.0289%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_cosine_sim_r", 
        "value": 0.0545, 
        "severity": 0, 
        "severity_value": 0.02725, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim_r\n  Best score: 0.0545%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_cosine_sim_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim_r\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_cosine_sim_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim_r\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_cosine_sim_r", 
        "value": 0.4041, 
        "severity": 0, 
        "severity_value": -0.4041, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.4041%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_cosine_sim_r", 
        "value": 0.4596, 
        "severity": 0, 
        "severity_value": 0.2298, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_cosine_sim_r\n  Best score: 0.4596%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_cosine_sim_r", 
        "value": 0.4157, 
        "severity": 0, 
        "severity_value": -0.4157, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.4157%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_cosine_sim_r", 
        "value": 0.4863, 
        "severity": 0, 
        "severity_value": 0.24315, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim_r\n  Best score: 0.4863%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_cosine_sim_r", 
        "value": 0.3475, 
        "severity": 0, 
        "severity_value": -0.3475, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.3475%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_cosine_sim_r", 
        "value": 0.3722, 
        "severity": 0, 
        "severity_value": 0.1861, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim_r\n  Best score: 0.3722%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_cosine_sim_r", 
        "value": 0.3916, 
        "severity": 0, 
        "severity_value": -0.3916, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.3916%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_cosine_sim_r", 
        "value": 0.4587, 
        "severity": 0, 
        "severity_value": 0.22935, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim_r\n  Best score: 0.4587%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_cosine_sim_r", 
        "value": 0.2048, 
        "severity": 0, 
        "severity_value": -0.2048, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.2048%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_cosine_sim_r", 
        "value": 0.226, 
        "severity": 0, 
        "severity_value": 0.113, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim_r\n  Best score: 0.226%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_cosine_sim_r", 
        "value": 0.3965, 
        "severity": 0, 
        "severity_value": -0.3965, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim_r\n  Worst score: 0.3965%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_cosine_sim_r", 
        "value": 0.4667, 
        "severity": 0, 
        "severity_value": 0.23335, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim_r\n  Best score: 0.4667%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_cosine_sim_clipped_0001_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_cosine_sim_clipped_0001_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_cosine_sim_clipped_0001_r", 
        "value": 0.1904, 
        "severity": 0, 
        "severity_value": -0.1904, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.1904%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_cosine_sim_clipped_0001_r", 
        "value": 0.2601, 
        "severity": 0, 
        "severity_value": 0.13005, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.2601%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_cosine_sim_clipped_0001_r", 
        "value": 0.2458, 
        "severity": 0, 
        "severity_value": -0.2458, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.2458%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_cosine_sim_clipped_0001_r", 
        "value": 0.3176, 
        "severity": 0, 
        "severity_value": 0.1588, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.3176%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_cosine_sim_clipped_0001_r", 
        "value": 0.2554, 
        "severity": 0, 
        "severity_value": -0.2554, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.2554%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_cosine_sim_clipped_0001_r", 
        "value": 0.2634, 
        "severity": 0, 
        "severity_value": 0.1317, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.2634%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_cosine_sim_clipped_0001_r", 
        "value": 0.0543, 
        "severity": 0, 
        "severity_value": -0.0543, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.0543%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_cosine_sim_clipped_0001_r", 
        "value": 0.0677, 
        "severity": 0, 
        "severity_value": 0.03385, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.0677%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_cosine_sim_clipped_0001_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_cosine_sim_clipped_0001_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_cosine_sim_clipped_0001_r", 
        "value": 0.4033, 
        "severity": 0, 
        "severity_value": -0.4033, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.4033%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_cosine_sim_clipped_0001_r", 
        "value": 0.4404, 
        "severity": 0, 
        "severity_value": 0.2202, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.4404%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_cosine_sim_clipped_0001_r", 
        "value": 0.411, 
        "severity": 0, 
        "severity_value": -0.411, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.411%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_cosine_sim_clipped_0001_r", 
        "value": 0.4684, 
        "severity": 0, 
        "severity_value": 0.2342, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.4684%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_cosine_sim_clipped_0001_r", 
        "value": 0.3166, 
        "severity": 0, 
        "severity_value": -0.3166, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.3166%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_cosine_sim_clipped_0001_r", 
        "value": 0.3627, 
        "severity": 0, 
        "severity_value": 0.18135, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.3627%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_cosine_sim_clipped_0001_r", 
        "value": 0.3867, 
        "severity": 0, 
        "severity_value": -0.3867, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.3867%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_cosine_sim_clipped_0001_r", 
        "value": 0.4364, 
        "severity": 0, 
        "severity_value": 0.2182, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.4364%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_cosine_sim_clipped_0001_r", 
        "value": 0.2267, 
        "severity": 0, 
        "severity_value": -0.2267, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.2267%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_cosine_sim_clipped_0001_r", 
        "value": 0.2414, 
        "severity": 0, 
        "severity_value": 0.1207, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.2414%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_cosine_sim_clipped_0001_r", 
        "value": 0.3965, 
        "severity": 0, 
        "severity_value": -0.3965, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Worst score: 0.3965%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_cosine_sim_clipped_0001_r", 
        "value": 0.4615, 
        "severity": 0, 
        "severity_value": 0.23075, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_cosine_sim_clipped_0001_r\n  Best score: 0.4615%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_pearson", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_pearson\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_pearson", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_pearson\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_pearson", 
        "value": 0.1532, 
        "severity": 0, 
        "severity_value": -0.1532, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_pearson\n  Worst score: 0.1532%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_pearson", 
        "value": 0.1883, 
        "severity": 0, 
        "severity_value": 0.09415, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_pearson\n  Best score: 0.1883%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_pearson", 
        "value": 0.2118, 
        "severity": 0, 
        "severity_value": -0.2118, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_pearson\n  Worst score: 0.2118%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_pearson", 
        "value": 0.2684, 
        "severity": 0, 
        "severity_value": 0.1342, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_pearson\n  Best score: 0.2684%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_pearson", 
        "value": 0.2111, 
        "severity": 0, 
        "severity_value": -0.2111, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_pearson\n  Worst score: 0.2111%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_pearson", 
        "value": 0.2679, 
        "severity": 0, 
        "severity_value": 0.13395, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_pearson\n  Best score: 0.2679%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_pearson\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_pearson\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_pearson\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_pearson\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_pearson", 
        "value": 0.3641, 
        "severity": 0, 
        "severity_value": -0.3641, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_pearson\n  Worst score: 0.3641%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_pearson", 
        "value": 0.4405, 
        "severity": 0, 
        "severity_value": 0.22025, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_pearson\n  Best score: 0.4405%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_pearson", 
        "value": 0.376, 
        "severity": 0, 
        "severity_value": -0.376, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_pearson\n  Worst score: 0.376%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_pearson", 
        "value": 0.4687, 
        "severity": 0, 
        "severity_value": 0.23435, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_pearson\n  Best score: 0.4687%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_pearson", 
        "value": 0.3268, 
        "severity": 0, 
        "severity_value": -0.3268, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_pearson\n  Worst score: 0.3268%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_pearson", 
        "value": 0.3345, 
        "severity": 0, 
        "severity_value": 0.16725, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_pearson\n  Best score: 0.3345%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_pearson", 
        "value": 0.3529, 
        "severity": 0, 
        "severity_value": -0.3529, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_pearson\n  Worst score: 0.3529%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_pearson", 
        "value": 0.4401, 
        "severity": 0, 
        "severity_value": 0.22005, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_pearson\n  Best score: 0.4401%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_pearson", 
        "value": 0.1524, 
        "severity": 0, 
        "severity_value": -0.1524, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_pearson\n  Worst score: 0.1524%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_pearson", 
        "value": 0.1762, 
        "severity": 0, 
        "severity_value": 0.0881, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_pearson\n  Best score: 0.1762%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_pearson", 
        "value": 0.3572, 
        "severity": 0, 
        "severity_value": -0.3572, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_pearson\n  Worst score: 0.3572%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_pearson", 
        "value": 0.4485, 
        "severity": 0, 
        "severity_value": 0.22425, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_pearson\n  Best score: 0.4485%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_spearman", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_spearman\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_spearman", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_spearman\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_spearman", 
        "value": 0.1903, 
        "severity": 0, 
        "severity_value": -0.1903, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_spearman\n  Worst score: 0.1903%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_spearman", 
        "value": 0.2222, 
        "severity": 0, 
        "severity_value": 0.1111, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_spearman\n  Best score: 0.2222%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_spearman", 
        "value": 0.2487, 
        "severity": 0, 
        "severity_value": -0.2487, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_spearman\n  Worst score: 0.2487%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_spearman", 
        "value": 0.2908, 
        "severity": 0, 
        "severity_value": 0.1454, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_spearman\n  Best score: 0.2908%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_spearman", 
        "value": 0.2126, 
        "severity": 0, 
        "severity_value": -0.2126, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_spearman\n  Worst score: 0.2126%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_spearman", 
        "value": 0.2489, 
        "severity": 0, 
        "severity_value": 0.12445, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_spearman\n  Best score: 0.2489%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_spearman", 
        "value": 0.0301, 
        "severity": 0, 
        "severity_value": -0.0301, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_spearman\n  Worst score: 0.0301%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_spearman", 
        "value": 0.0642, 
        "severity": 0, 
        "severity_value": 0.0321, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_spearman\n  Best score: 0.0642%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_spearman\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_spearman\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_spearman", 
        "value": 0.3678, 
        "severity": 0, 
        "severity_value": -0.3678, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_spearman\n  Worst score: 0.3678%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_spearman", 
        "value": 0.4191, 
        "severity": 0, 
        "severity_value": 0.20955, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_spearman\n  Best score: 0.4191%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_spearman", 
        "value": 0.3712, 
        "severity": 0, 
        "severity_value": -0.3712, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_spearman\n  Worst score: 0.3712%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_spearman", 
        "value": 0.4443, 
        "severity": 0, 
        "severity_value": 0.22215, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_spearman\n  Best score: 0.4443%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_spearman", 
        "value": 0.2965, 
        "severity": 0, 
        "severity_value": -0.2965, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_spearman\n  Worst score: 0.2965%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_spearman", 
        "value": 0.3276, 
        "severity": 0, 
        "severity_value": 0.1638, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_spearman\n  Best score: 0.3276%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_spearman", 
        "value": 0.3526, 
        "severity": 0, 
        "severity_value": -0.3526, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_spearman\n  Worst score: 0.3526%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_spearman", 
        "value": 0.4171, 
        "severity": 0, 
        "severity_value": 0.20855, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_spearman\n  Best score: 0.4171%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_spearman", 
        "value": 0.1991, 
        "severity": 0, 
        "severity_value": -0.1991, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_spearman\n  Worst score: 0.1991%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_spearman", 
        "value": 0.223, 
        "severity": 0, 
        "severity_value": 0.1115, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_spearman\n  Best score: 0.223%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_spearman", 
        "value": 0.3644, 
        "severity": 0, 
        "severity_value": -0.3644, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_spearman\n  Worst score: 0.3644%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_spearman", 
        "value": 0.4428, 
        "severity": 0, 
        "severity_value": 0.2214, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_spearman\n  Best score: 0.4428%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_pearson_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_pearson_r\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_pearson_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_pearson_r\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_pearson_r", 
        "value": 0.1762, 
        "severity": 0, 
        "severity_value": -0.1762, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_pearson_r\n  Worst score: 0.1762%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_pearson_r", 
        "value": 0.2186, 
        "severity": 0, 
        "severity_value": 0.1093, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_pearson_r\n  Best score: 0.2186%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_pearson_r", 
        "value": 0.2332, 
        "severity": 0, 
        "severity_value": -0.2332, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_pearson_r\n  Worst score: 0.2332%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_pearson_r", 
        "value": 0.2957, 
        "severity": 0, 
        "severity_value": 0.14785, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_pearson_r\n  Best score: 0.2957%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_pearson_r", 
        "value": 0.2406, 
        "severity": 0, 
        "severity_value": -0.2406, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_pearson_r\n  Worst score: 0.2406%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_pearson_r", 
        "value": 0.2877, 
        "severity": 0, 
        "severity_value": 0.14385, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_pearson_r\n  Best score: 0.2877%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_pearson_r", 
        "value": 0.0271, 
        "severity": 0, 
        "severity_value": -0.0271, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_pearson_r\n  Worst score: 0.0271%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_pearson_r", 
        "value": 0.0374, 
        "severity": 0, 
        "severity_value": 0.0187, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_pearson_r\n  Best score: 0.0374%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_pearson_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_pearson_r\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_pearson_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_pearson_r\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_pearson_r", 
        "value": 0.3878, 
        "severity": 0, 
        "severity_value": -0.3878, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_pearson_r\n  Worst score: 0.3878%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_pearson_r", 
        "value": 0.4557, 
        "severity": 0, 
        "severity_value": 0.22785, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_pearson_r\n  Best score: 0.4557%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_pearson_r", 
        "value": 0.3993, 
        "severity": 0, 
        "severity_value": -0.3993, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_pearson_r\n  Worst score: 0.3993%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_pearson_r", 
        "value": 0.4831, 
        "severity": 0, 
        "severity_value": 0.24155, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_pearson_r\n  Best score: 0.4831%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_pearson_r", 
        "value": 0.345, 
        "severity": 0, 
        "severity_value": -0.345, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_pearson_r\n  Worst score: 0.345%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_pearson_r", 
        "value": 0.3593, 
        "severity": 0, 
        "severity_value": 0.17965, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_pearson_r\n  Best score: 0.3593%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_pearson_r", 
        "value": 0.3771, 
        "severity": 0, 
        "severity_value": -0.3771, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_pearson_r\n  Worst score: 0.3771%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_pearson_r", 
        "value": 0.4553, 
        "severity": 0, 
        "severity_value": 0.22765, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_pearson_r\n  Best score: 0.4553%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_pearson_r", 
        "value": 0.1841, 
        "severity": 0, 
        "severity_value": -0.1841, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_pearson_r\n  Worst score: 0.1841%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_pearson_r", 
        "value": 0.1986, 
        "severity": 0, 
        "severity_value": 0.0993, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_pearson_r\n  Best score: 0.1986%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_pearson_r", 
        "value": 0.3812, 
        "severity": 0, 
        "severity_value": -0.3812, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_pearson_r\n  Worst score: 0.3812%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_pearson_r", 
        "value": 0.4635, 
        "severity": 0, 
        "severity_value": 0.23175, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_pearson_r\n  Best score: 0.4635%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score ground_truth mean_spearman_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method ground_truth performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_spearman_r\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score ground_truth mean_spearman_r", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method ground_truth performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: ground_truth\n  Metric id: mean_spearman_r\n  Best score: 1%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_outcome mean_spearman_r", 
        "value": 0.1834, 
        "severity": 0, 
        "severity_value": -0.1834, 
        "code": "worst_score >= -1", 
        "message": "Method mean_outcome performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_spearman_r\n  Worst score: 0.1834%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_outcome mean_spearman_r", 
        "value": 0.2313, 
        "severity": 0, 
        "severity_value": 0.11565, 
        "code": "best_score <= 2", 
        "message": "Method mean_outcome performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_outcome\n  Metric id: mean_spearman_r\n  Best score: 0.2313%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_celltypes mean_spearman_r", 
        "value": 0.2424, 
        "severity": 0, 
        "severity_value": -0.2424, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_celltypes performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_spearman_r\n  Worst score: 0.2424%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_celltypes mean_spearman_r", 
        "value": 0.2991, 
        "severity": 0, 
        "severity_value": 0.14955, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_celltypes performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_celltypes\n  Metric id: mean_spearman_r\n  Best score: 0.2991%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score mean_across_compounds mean_spearman_r", 
        "value": 0.2218, 
        "severity": 0, 
        "severity_value": -0.2218, 
        "code": "worst_score >= -1", 
        "message": "Method mean_across_compounds performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_spearman_r\n  Worst score: 0.2218%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score mean_across_compounds mean_spearman_r", 
        "value": 0.2426, 
        "severity": 0, 
        "severity_value": 0.1213, 
        "code": "best_score <= 2", 
        "message": "Method mean_across_compounds performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: mean_across_compounds\n  Metric id: mean_spearman_r\n  Best score: 0.2426%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score sample mean_spearman_r", 
        "value": 0.0414, 
        "severity": 0, 
        "severity_value": -0.0414, 
        "code": "worst_score >= -1", 
        "message": "Method sample performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_spearman_r\n  Worst score: 0.0414%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score sample mean_spearman_r", 
        "value": 0.0563, 
        "severity": 0, 
        "severity_value": 0.02815, 
        "code": "best_score <= 2", 
        "message": "Method sample performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: sample\n  Metric id: mean_spearman_r\n  Best score: 0.0563%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_spearman_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_spearman_r\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score zeros mean_spearman_r", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: zeros\n  Metric id: mean_spearman_r\n  Best score: 0%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score lgc_ensemble mean_spearman_r", 
        "value": 0.3752, 
        "severity": 0, 
        "severity_value": -0.3752, 
        "code": "worst_score >= -1", 
        "message": "Method lgc_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_spearman_r\n  Worst score: 0.3752%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score lgc_ensemble mean_spearman_r", 
        "value": 0.4142, 
        "severity": 0, 
        "severity_value": 0.2071, 
        "code": "best_score <= 2", 
        "message": "Method lgc_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: lgc_ensemble\n  Metric id: mean_spearman_r\n  Best score: 0.4142%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score nn_retraining_with_pseudolabels mean_spearman_r", 
        "value": 0.3786, 
        "severity": 0, 
        "severity_value": -0.3786, 
        "code": "worst_score >= -1", 
        "message": "Method nn_retraining_with_pseudolabels performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_spearman_r\n  Worst score: 0.3786%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score nn_retraining_with_pseudolabels mean_spearman_r", 
        "value": 0.4396, 
        "severity": 0, 
        "severity_value": 0.2198, 
        "code": "best_score <= 2", 
        "message": "Method nn_retraining_with_pseudolabels performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: nn_retraining_with_pseudolabels\n  Metric id: mean_spearman_r\n  Best score: 0.4396%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score jn_ap_op2 mean_spearman_r", 
        "value": 0.2906, 
        "severity": 0, 
        "severity_value": -0.2906, 
        "code": "worst_score >= -1", 
        "message": "Method jn_ap_op2 performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_spearman_r\n  Worst score: 0.2906%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score jn_ap_op2 mean_spearman_r", 
        "value": 0.3355, 
        "severity": 0, 
        "severity_value": 0.16775, 
        "code": "best_score <= 2", 
        "message": "Method jn_ap_op2 performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: jn_ap_op2\n  Metric id: mean_spearman_r\n  Best score: 0.3355%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score scape mean_spearman_r", 
        "value": 0.3602, 
        "severity": 0, 
        "severity_value": -0.3602, 
        "code": "worst_score >= -1", 
        "message": "Method scape performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_spearman_r\n  Worst score: 0.3602%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score scape mean_spearman_r", 
        "value": 0.4122, 
        "severity": 0, 
        "severity_value": 0.2061, 
        "code": "best_score <= 2", 
        "message": "Method scape performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: scape\n  Metric id: mean_spearman_r\n  Best score: 0.4122%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score transformer_ensemble mean_spearman_r", 
        "value": 0.2085, 
        "severity": 0, 
        "severity_value": -0.2085, 
        "code": "worst_score >= -1", 
        "message": "Method transformer_ensemble performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_spearman_r\n  Worst score: 0.2085%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score transformer_ensemble mean_spearman_r", 
        "value": 0.2164, 
        "severity": 0, 
        "severity_value": 0.1082, 
        "code": "best_score <= 2", 
        "message": "Method transformer_ensemble performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: transformer_ensemble\n  Metric id: mean_spearman_r\n  Best score: 0.2164%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Worst score pyboost mean_spearman_r", 
        "value": 0.3718, 
        "severity": 0, 
        "severity_value": -0.3718, 
        "code": "worst_score >= -1", 
        "message": "Method pyboost performs much worse than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_spearman_r\n  Worst score: 0.3718%\n"
    }, 
    {
        "task_id": "dge_perturbation_prediction", 
        "category": "Scaling", 
        "name": "Best score pyboost mean_spearman_r", 
        "value": 0.4381, 
        "severity": 0, 
        "severity_value": 0.21905, 
        "code": "best_score <= 2", 
        "message": "Method pyboost performs a lot better than baselines.\n  Task id: dge_perturbation_prediction\n  Method id: pyboost\n  Metric id: mean_spearman_r\n  Best score: 0.4381%\n"
    }
]