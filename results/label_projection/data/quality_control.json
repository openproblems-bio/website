[
    {
        "task_id": "task_label_projection", 
        "category": "Task info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_id' should be defined\n  Task id: task_label_projection\n  Field: task_id\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Task info", 
        "name": "Pct 'task_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_name' should be defined\n  Task id: task_label_projection\n  Field: task_name\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Task info", 
        "name": "Pct 'task_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_summary' should be defined\n  Task id: task_label_projection\n  Field: task_summary\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Task info", 
        "name": "Pct 'task_description' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_description' should be defined\n  Task id: task_label_projection\n  Field: task_description\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Method info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'task_id' should be defined\n  Task id: task_label_projection\n  Field: task_id\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Method info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'commit_sha' should be defined\n  Task id: task_label_projection\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Method info", 
        "name": "Pct 'method_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_id' should be defined\n  Task id: task_label_projection\n  Field: method_id\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Method info", 
        "name": "Pct 'method_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_name' should be defined\n  Task id: task_label_projection\n  Field: method_name\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Method info", 
        "name": "Pct 'method_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_summary' should be defined\n  Task id: task_label_projection\n  Field: method_summary\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Method info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 0.8421052631578947, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'paper_reference' should be defined\n  Task id: task_label_projection\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Method info", 
        "name": "Pct 'is_baseline' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'is_baseline' should be defined\n  Task id: task_label_projection\n  Field: is_baseline\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Metric info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'task_id' should be defined\n  Task id: task_label_projection\n  Field: task_id\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Metric info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'commit_sha' should be defined\n  Task id: task_label_projection\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Metric info", 
        "name": "Pct 'metric_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_id' should be defined\n  Task id: task_label_projection\n  Field: metric_id\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Metric info", 
        "name": "Pct 'metric_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_name' should be defined\n  Task id: task_label_projection\n  Field: metric_name\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Metric info", 
        "name": "Pct 'metric_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_summary' should be defined\n  Task id: task_label_projection\n  Field: metric_summary\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Metric info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 1.0, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'paper_reference' should be defined\n  Task id: task_label_projection\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Metric info", 
        "name": "Pct 'maximize' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'maximize' should be defined\n  Task id: task_label_projection\n  Field: maximize\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Dataset info", 
        "name": "Pct 'task_id' missing", 
        "value": 1.0, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'task_id' should be defined\n  Task id: task_label_projection\n  Field: task_id\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_id' should be defined\n  Task id: task_label_projection\n  Field: dataset_id\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_name' should be defined\n  Task id: task_label_projection\n  Field: dataset_name\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_summary' should be defined\n  Task id: task_label_projection\n  Field: dataset_summary\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Dataset info", 
        "name": "Pct 'data_reference' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_reference' should be defined\n  Task id: task_label_projection\n  Field: data_reference\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Dataset info", 
        "name": "Pct 'data_url' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_url' should be defined\n  Task id: task_label_projection\n  Field: data_url\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw data", 
        "name": "Number of results", 
        "value": 133, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "len(results) == len(method_info) * len(metric_info) * len(dataset_info)", 
        "message": "Number of results should be equal to #methods × #metrics × #datasets.\n  Task id: task_label_projection\n  Number of results: 133\n  Number of methods: 19\n  Number of metrics: 4\n  Number of datasets: 7\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Metric 'accuracy' %missing", 
        "value": 0.33834586466165417, 
        "severity": 3, 
        "severity_value": 3.3834586466165417, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  Metric id: accuracy\n  Percentage missing: 34%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Metric 'f1_weighted' %missing", 
        "value": 0.33834586466165417, 
        "severity": 3, 
        "severity_value": 3.3834586466165417, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  Metric id: f1_weighted\n  Percentage missing: 34%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Metric 'f1_macro' %missing", 
        "value": 0.33834586466165417, 
        "severity": 3, 
        "severity_value": 3.3834586466165417, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  Metric id: f1_macro\n  Percentage missing: 34%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Metric 'f1_micro' %missing", 
        "value": 0.330827067669173, 
        "severity": 3, 
        "severity_value": 3.30827067669173, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  Metric id: f1_micro\n  Percentage missing: 33%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'majority_vote' %missing", 
        "value": 0.1428571428571429, 
        "severity": 1, 
        "severity_value": 1.428571428571429, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: majority_vote\n  Percentage missing: 14%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'random_labels' %missing", 
        "value": 0.1428571428571429, 
        "severity": 1, 
        "severity_value": 1.428571428571429, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: random_labels\n  Percentage missing: 14%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'true_labels' %missing", 
        "value": 0.1071428571428571, 
        "severity": 1, 
        "severity_value": 1.071428571428571, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: true_labels\n  Percentage missing: 11%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'geneformer' %missing", 
        "value": 1.0, 
        "severity": 3, 
        "severity_value": 10.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: geneformer\n  Percentage missing: 100%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'knn' %missing", 
        "value": 0.1428571428571429, 
        "severity": 1, 
        "severity_value": 1.428571428571429, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: knn\n  Percentage missing: 14%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'logistic_regression' %missing", 
        "value": 0.1428571428571429, 
        "severity": 1, 
        "severity_value": 1.428571428571429, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: logistic_regression\n  Percentage missing: 14%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'mlp' %missing", 
        "value": 0.1428571428571429, 
        "severity": 1, 
        "severity_value": 1.428571428571429, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: mlp\n  Percentage missing: 14%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'naive_bayes' %missing", 
        "value": 0.1428571428571429, 
        "severity": 1, 
        "severity_value": 1.428571428571429, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: naive_bayes\n  Percentage missing: 14%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'scanvi' %missing", 
        "value": 0.1428571428571429, 
        "severity": 1, 
        "severity_value": 1.428571428571429, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: scanvi\n  Percentage missing: 14%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'scanvi_scarches' %missing", 
        "value": 0.1428571428571429, 
        "severity": 1, 
        "severity_value": 1.428571428571429, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: scanvi_scarches\n  Percentage missing: 14%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'scgpt_finetuned' %missing", 
        "value": 1.0, 
        "severity": 3, 
        "severity_value": 10.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: scgpt_finetuned\n  Percentage missing: 100%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'scgpt_zeroshot' %missing", 
        "value": 0.4285714285714286, 
        "severity": 3, 
        "severity_value": 4.285714285714286, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: scgpt_zeroshot\n  Percentage missing: 43%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'scimilarity' %missing", 
        "value": 0.4285714285714286, 
        "severity": 3, 
        "severity_value": 4.285714285714286, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: scimilarity\n  Percentage missing: 43%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'scimilarity_knn' %missing", 
        "value": 0.4285714285714286, 
        "severity": 3, 
        "severity_value": 4.285714285714286, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: scimilarity_knn\n  Percentage missing: 43%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'scprint' %missing", 
        "value": 1.0, 
        "severity": 3, 
        "severity_value": 10.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: scprint\n  Percentage missing: 100%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'seurat_transferdata' %missing", 
        "value": 0.1428571428571429, 
        "severity": 1, 
        "severity_value": 1.428571428571429, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: seurat_transferdata\n  Percentage missing: 14%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'singler' %missing", 
        "value": 0.4285714285714286, 
        "severity": 3, 
        "severity_value": 4.285714285714286, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: singler\n  Percentage missing: 43%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'uce' %missing", 
        "value": 0.1428571428571429, 
        "severity": 1, 
        "severity_value": 1.428571428571429, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: uce\n  Percentage missing: 14%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Method 'xgboost' %missing", 
        "value": 0.1428571428571429, 
        "severity": 1, 
        "severity_value": 1.428571428571429, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  method id: xgboost\n  Percentage missing: 14%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'cellxgene_census/gtex_v9' %missing", 
        "value": 0.1578947368421053, 
        "severity": 1, 
        "severity_value": 1.578947368421053, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  dataset id: cellxgene_census/gtex_v9\n  Percentage missing: 16%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'cellxgene_census/tabula_sapiens' %missing", 
        "value": 0.1578947368421053, 
        "severity": 1, 
        "severity_value": 1.578947368421053, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  dataset id: cellxgene_census/tabula_sapiens\n  Percentage missing: 16%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'cellxgene_census/mouse_pancreas_atlas' %missing", 
        "value": 0.368421052631579, 
        "severity": 3, 
        "severity_value": 3.68421052631579, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  dataset id: cellxgene_census/mouse_pancreas_atlas\n  Percentage missing: 37%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'cellxgene_census/hypomap' %missing", 
        "value": 0.3157894736842105, 
        "severity": 3, 
        "severity_value": 3.157894736842105, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  dataset id: cellxgene_census/hypomap\n  Percentage missing: 32%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'cellxgene_census/immune_cell_atlas' %missing", 
        "value": 0.21052631578947367, 
        "severity": 2, 
        "severity_value": 2.1052631578947367, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  dataset id: cellxgene_census/immune_cell_atlas\n  Percentage missing: 21%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'cellxgene_census/dkd' %missing", 
        "value": 0.1578947368421053, 
        "severity": 1, 
        "severity_value": 1.578947368421053, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  dataset id: cellxgene_census/dkd\n  Percentage missing: 16%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'allen_brain_cell_atlas/2023_yao_mouse_brain_scrnaseq_10xv2' %missing", 
        "value": 0.9868421052631579, 
        "severity": 3, 
        "severity_value": 9.868421052631579, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_label_projection\n  dataset id: allen_brain_cell_atlas/2023_yao_mouse_brain_scrnaseq_10xv2\n  Percentage missing: 99%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score majority_vote accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method majority_vote performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: majority_vote\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score majority_vote accuracy", 
        "value": 0.1987, 
        "severity": 0, 
        "severity_value": 0.09935, 
        "code": "best_score <= 2", 
        "message": "Method majority_vote performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: majority_vote\n  Metric id: accuracy\n  Best score: 0.1987%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score random_labels accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_labels performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: random_labels\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score random_labels accuracy", 
        "value": 0.0426, 
        "severity": 0, 
        "severity_value": 0.0213, 
        "code": "best_score <= 2", 
        "message": "Method random_labels performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: random_labels\n  Metric id: accuracy\n  Best score: 0.0426%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score true_labels accuracy", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method true_labels performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: true_labels\n  Metric id: accuracy\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score true_labels accuracy", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method true_labels performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: true_labels\n  Metric id: accuracy\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score geneformer accuracy", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method geneformer performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: geneformer\n  Metric id: accuracy\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score geneformer accuracy", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method geneformer performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: geneformer\n  Metric id: accuracy\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score knn accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knn performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: knn\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score knn accuracy", 
        "value": 0.9933, 
        "severity": 0, 
        "severity_value": 0.49665, 
        "code": "best_score <= 2", 
        "message": "Method knn performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: knn\n  Metric id: accuracy\n  Best score: 0.9933%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score logistic_regression accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method logistic_regression performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: logistic_regression\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score logistic_regression accuracy", 
        "value": 0.9947, 
        "severity": 0, 
        "severity_value": 0.49735, 
        "code": "best_score <= 2", 
        "message": "Method logistic_regression performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: logistic_regression\n  Metric id: accuracy\n  Best score: 0.9947%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score mlp accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mlp performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: mlp\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score mlp accuracy", 
        "value": 0.996, 
        "severity": 0, 
        "severity_value": 0.498, 
        "code": "best_score <= 2", 
        "message": "Method mlp performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: mlp\n  Metric id: accuracy\n  Best score: 0.996%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score naive_bayes accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method naive_bayes performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: naive_bayes\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score naive_bayes accuracy", 
        "value": 0.992, 
        "severity": 0, 
        "severity_value": 0.496, 
        "code": "best_score <= 2", 
        "message": "Method naive_bayes performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: naive_bayes\n  Metric id: accuracy\n  Best score: 0.992%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scanvi accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scanvi performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scanvi\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scanvi accuracy", 
        "value": 0.996, 
        "severity": 0, 
        "severity_value": 0.498, 
        "code": "best_score <= 2", 
        "message": "Method scanvi performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scanvi\n  Metric id: accuracy\n  Best score: 0.996%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scanvi_scarches accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scanvi_scarches performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scanvi_scarches\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scanvi_scarches accuracy", 
        "value": 0.9947, 
        "severity": 0, 
        "severity_value": 0.49735, 
        "code": "best_score <= 2", 
        "message": "Method scanvi_scarches performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scanvi_scarches\n  Metric id: accuracy\n  Best score: 0.9947%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scgpt_finetuned accuracy", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scgpt_finetuned performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scgpt_finetuned\n  Metric id: accuracy\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scgpt_finetuned accuracy", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method scgpt_finetuned performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scgpt_finetuned\n  Metric id: accuracy\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scgpt_zeroshot accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scgpt_zeroshot performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scgpt_zeroshot\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scgpt_zeroshot accuracy", 
        "value": 0.8152, 
        "severity": 0, 
        "severity_value": 0.4076, 
        "code": "best_score <= 2", 
        "message": "Method scgpt_zeroshot performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scgpt_zeroshot\n  Metric id: accuracy\n  Best score: 0.8152%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scimilarity accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scimilarity performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scimilarity\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scimilarity accuracy", 
        "value": 0.8619, 
        "severity": 0, 
        "severity_value": 0.43095, 
        "code": "best_score <= 2", 
        "message": "Method scimilarity performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scimilarity\n  Metric id: accuracy\n  Best score: 0.8619%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scimilarity_knn accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scimilarity_knn performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scimilarity_knn\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scimilarity_knn accuracy", 
        "value": 0.9454, 
        "severity": 0, 
        "severity_value": 0.4727, 
        "code": "best_score <= 2", 
        "message": "Method scimilarity_knn performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scimilarity_knn\n  Metric id: accuracy\n  Best score: 0.9454%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scprint accuracy", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scprint performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scprint\n  Metric id: accuracy\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scprint accuracy", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method scprint performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scprint\n  Metric id: accuracy\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score seurat_transferdata accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method seurat_transferdata performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: seurat_transferdata\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score seurat_transferdata accuracy", 
        "value": 0.9947, 
        "severity": 0, 
        "severity_value": 0.49735, 
        "code": "best_score <= 2", 
        "message": "Method seurat_transferdata performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: seurat_transferdata\n  Metric id: accuracy\n  Best score: 0.9947%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score singler accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method singler performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: singler\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score singler accuracy", 
        "value": 0.9893, 
        "severity": 0, 
        "severity_value": 0.49465, 
        "code": "best_score <= 2", 
        "message": "Method singler performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: singler\n  Metric id: accuracy\n  Best score: 0.9893%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score uce accuracy", 
        "value": -0.0279, 
        "severity": 0, 
        "severity_value": 0.0279, 
        "code": "worst_score >= -1", 
        "message": "Method uce performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: uce\n  Metric id: accuracy\n  Worst score: -0.0279%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score uce accuracy", 
        "value": 0.1, 
        "severity": 0, 
        "severity_value": 0.05, 
        "code": "best_score <= 2", 
        "message": "Method uce performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: uce\n  Metric id: accuracy\n  Best score: 0.1%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score xgboost accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method xgboost performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: xgboost\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score xgboost accuracy", 
        "value": 0.996, 
        "severity": 0, 
        "severity_value": 0.498, 
        "code": "best_score <= 2", 
        "message": "Method xgboost performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: xgboost\n  Metric id: accuracy\n  Best score: 0.996%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score majority_vote f1_weighted", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method majority_vote performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: majority_vote\n  Metric id: f1_weighted\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score majority_vote f1_weighted", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method majority_vote performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: majority_vote\n  Metric id: f1_weighted\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score random_labels f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_labels performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: random_labels\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score random_labels f1_weighted", 
        "value": 0.0567, 
        "severity": 0, 
        "severity_value": 0.02835, 
        "code": "best_score <= 2", 
        "message": "Method random_labels performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: random_labels\n  Metric id: f1_weighted\n  Best score: 0.0567%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score true_labels f1_weighted", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method true_labels performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: true_labels\n  Metric id: f1_weighted\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score true_labels f1_weighted", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method true_labels performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: true_labels\n  Metric id: f1_weighted\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score geneformer f1_weighted", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method geneformer performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: geneformer\n  Metric id: f1_weighted\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score geneformer f1_weighted", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method geneformer performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: geneformer\n  Metric id: f1_weighted\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score knn f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knn performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: knn\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score knn f1_weighted", 
        "value": 0.9936, 
        "severity": 0, 
        "severity_value": 0.4968, 
        "code": "best_score <= 2", 
        "message": "Method knn performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: knn\n  Metric id: f1_weighted\n  Best score: 0.9936%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score logistic_regression f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method logistic_regression performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: logistic_regression\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score logistic_regression f1_weighted", 
        "value": 0.9949, 
        "severity": 0, 
        "severity_value": 0.49745, 
        "code": "best_score <= 2", 
        "message": "Method logistic_regression performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: logistic_regression\n  Metric id: f1_weighted\n  Best score: 0.9949%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score mlp f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mlp performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: mlp\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score mlp f1_weighted", 
        "value": 0.9962, 
        "severity": 0, 
        "severity_value": 0.4981, 
        "code": "best_score <= 2", 
        "message": "Method mlp performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: mlp\n  Metric id: f1_weighted\n  Best score: 0.9962%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score naive_bayes f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method naive_bayes performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: naive_bayes\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score naive_bayes f1_weighted", 
        "value": 0.9924, 
        "severity": 0, 
        "severity_value": 0.4962, 
        "code": "best_score <= 2", 
        "message": "Method naive_bayes performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: naive_bayes\n  Metric id: f1_weighted\n  Best score: 0.9924%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scanvi f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scanvi performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scanvi\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scanvi f1_weighted", 
        "value": 0.9961, 
        "severity": 0, 
        "severity_value": 0.49805, 
        "code": "best_score <= 2", 
        "message": "Method scanvi performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scanvi\n  Metric id: f1_weighted\n  Best score: 0.9961%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scanvi_scarches f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scanvi_scarches performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scanvi_scarches\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scanvi_scarches f1_weighted", 
        "value": 0.9949, 
        "severity": 0, 
        "severity_value": 0.49745, 
        "code": "best_score <= 2", 
        "message": "Method scanvi_scarches performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scanvi_scarches\n  Metric id: f1_weighted\n  Best score: 0.9949%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scgpt_finetuned f1_weighted", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scgpt_finetuned performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scgpt_finetuned\n  Metric id: f1_weighted\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scgpt_finetuned f1_weighted", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method scgpt_finetuned performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scgpt_finetuned\n  Metric id: f1_weighted\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scgpt_zeroshot f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scgpt_zeroshot performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scgpt_zeroshot\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scgpt_zeroshot f1_weighted", 
        "value": 0.8081, 
        "severity": 0, 
        "severity_value": 0.40405, 
        "code": "best_score <= 2", 
        "message": "Method scgpt_zeroshot performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scgpt_zeroshot\n  Metric id: f1_weighted\n  Best score: 0.8081%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scimilarity f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scimilarity performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scimilarity\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scimilarity f1_weighted", 
        "value": 0.8455, 
        "severity": 0, 
        "severity_value": 0.42275, 
        "code": "best_score <= 2", 
        "message": "Method scimilarity performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scimilarity\n  Metric id: f1_weighted\n  Best score: 0.8455%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scimilarity_knn f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scimilarity_knn performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scimilarity_knn\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scimilarity_knn f1_weighted", 
        "value": 0.9487, 
        "severity": 0, 
        "severity_value": 0.47435, 
        "code": "best_score <= 2", 
        "message": "Method scimilarity_knn performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scimilarity_knn\n  Metric id: f1_weighted\n  Best score: 0.9487%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scprint f1_weighted", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scprint performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scprint\n  Metric id: f1_weighted\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scprint f1_weighted", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method scprint performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scprint\n  Metric id: f1_weighted\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score seurat_transferdata f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method seurat_transferdata performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: seurat_transferdata\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score seurat_transferdata f1_weighted", 
        "value": 0.9949, 
        "severity": 0, 
        "severity_value": 0.49745, 
        "code": "best_score <= 2", 
        "message": "Method seurat_transferdata performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: seurat_transferdata\n  Metric id: f1_weighted\n  Best score: 0.9949%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score singler f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method singler performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: singler\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score singler f1_weighted", 
        "value": 0.9898, 
        "severity": 0, 
        "severity_value": 0.4949, 
        "code": "best_score <= 2", 
        "message": "Method singler performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: singler\n  Metric id: f1_weighted\n  Best score: 0.9898%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score uce f1_weighted", 
        "value": -0.0037, 
        "severity": 0, 
        "severity_value": 0.0037, 
        "code": "worst_score >= -1", 
        "message": "Method uce performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: uce\n  Metric id: f1_weighted\n  Worst score: -0.0037%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score uce f1_weighted", 
        "value": 0.0816, 
        "severity": 0, 
        "severity_value": 0.0408, 
        "code": "best_score <= 2", 
        "message": "Method uce performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: uce\n  Metric id: f1_weighted\n  Best score: 0.0816%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score xgboost f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method xgboost performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: xgboost\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score xgboost f1_weighted", 
        "value": 0.9961, 
        "severity": 0, 
        "severity_value": 0.49805, 
        "code": "best_score <= 2", 
        "message": "Method xgboost performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: xgboost\n  Metric id: f1_weighted\n  Best score: 0.9961%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score majority_vote f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method majority_vote performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: majority_vote\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score majority_vote f1_macro", 
        "value": 0.0076, 
        "severity": 0, 
        "severity_value": 0.0038, 
        "code": "best_score <= 2", 
        "message": "Method majority_vote performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: majority_vote\n  Metric id: f1_macro\n  Best score: 0.0076%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score random_labels f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_labels performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: random_labels\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score random_labels f1_macro", 
        "value": 0.0438, 
        "severity": 0, 
        "severity_value": 0.0219, 
        "code": "best_score <= 2", 
        "message": "Method random_labels performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: random_labels\n  Metric id: f1_macro\n  Best score: 0.0438%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score true_labels f1_macro", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method true_labels performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: true_labels\n  Metric id: f1_macro\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score true_labels f1_macro", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method true_labels performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: true_labels\n  Metric id: f1_macro\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score geneformer f1_macro", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method geneformer performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: geneformer\n  Metric id: f1_macro\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score geneformer f1_macro", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method geneformer performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: geneformer\n  Metric id: f1_macro\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score knn f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knn performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: knn\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score knn f1_macro", 
        "value": 0.971, 
        "severity": 0, 
        "severity_value": 0.4855, 
        "code": "best_score <= 2", 
        "message": "Method knn performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: knn\n  Metric id: f1_macro\n  Best score: 0.971%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score logistic_regression f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method logistic_regression performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: logistic_regression\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score logistic_regression f1_macro", 
        "value": 0.9749, 
        "severity": 0, 
        "severity_value": 0.48745, 
        "code": "best_score <= 2", 
        "message": "Method logistic_regression performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: logistic_regression\n  Metric id: f1_macro\n  Best score: 0.9749%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score mlp f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mlp performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: mlp\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score mlp f1_macro", 
        "value": 0.9821, 
        "severity": 0, 
        "severity_value": 0.49105, 
        "code": "best_score <= 2", 
        "message": "Method mlp performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: mlp\n  Metric id: f1_macro\n  Best score: 0.9821%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score naive_bayes f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method naive_bayes performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: naive_bayes\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score naive_bayes f1_macro", 
        "value": 0.9597, 
        "severity": 0, 
        "severity_value": 0.47985, 
        "code": "best_score <= 2", 
        "message": "Method naive_bayes performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: naive_bayes\n  Metric id: f1_macro\n  Best score: 0.9597%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scanvi f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scanvi performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scanvi\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scanvi f1_macro", 
        "value": 0.992, 
        "severity": 0, 
        "severity_value": 0.496, 
        "code": "best_score <= 2", 
        "message": "Method scanvi performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scanvi\n  Metric id: f1_macro\n  Best score: 0.992%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scanvi_scarches f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scanvi_scarches performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scanvi_scarches\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scanvi_scarches f1_macro", 
        "value": 0.9766, 
        "severity": 0, 
        "severity_value": 0.4883, 
        "code": "best_score <= 2", 
        "message": "Method scanvi_scarches performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scanvi_scarches\n  Metric id: f1_macro\n  Best score: 0.9766%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scgpt_finetuned f1_macro", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scgpt_finetuned performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scgpt_finetuned\n  Metric id: f1_macro\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scgpt_finetuned f1_macro", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method scgpt_finetuned performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scgpt_finetuned\n  Metric id: f1_macro\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scgpt_zeroshot f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scgpt_zeroshot performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scgpt_zeroshot\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scgpt_zeroshot f1_macro", 
        "value": 0.5065, 
        "severity": 0, 
        "severity_value": 0.25325, 
        "code": "best_score <= 2", 
        "message": "Method scgpt_zeroshot performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scgpt_zeroshot\n  Metric id: f1_macro\n  Best score: 0.5065%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scimilarity f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scimilarity performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scimilarity\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scimilarity f1_macro", 
        "value": 0.6366, 
        "severity": 0, 
        "severity_value": 0.3183, 
        "code": "best_score <= 2", 
        "message": "Method scimilarity performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scimilarity\n  Metric id: f1_macro\n  Best score: 0.6366%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scimilarity_knn f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scimilarity_knn performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scimilarity_knn\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scimilarity_knn f1_macro", 
        "value": 0.9266, 
        "severity": 0, 
        "severity_value": 0.4633, 
        "code": "best_score <= 2", 
        "message": "Method scimilarity_knn performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scimilarity_knn\n  Metric id: f1_macro\n  Best score: 0.9266%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scprint f1_macro", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scprint performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scprint\n  Metric id: f1_macro\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scprint f1_macro", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method scprint performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scprint\n  Metric id: f1_macro\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score seurat_transferdata f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method seurat_transferdata performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: seurat_transferdata\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score seurat_transferdata f1_macro", 
        "value": 0.989, 
        "severity": 0, 
        "severity_value": 0.4945, 
        "code": "best_score <= 2", 
        "message": "Method seurat_transferdata performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: seurat_transferdata\n  Metric id: f1_macro\n  Best score: 0.989%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score singler f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method singler performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: singler\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score singler f1_macro", 
        "value": 0.9534, 
        "severity": 0, 
        "severity_value": 0.4767, 
        "code": "best_score <= 2", 
        "message": "Method singler performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: singler\n  Metric id: f1_macro\n  Best score: 0.9534%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score uce f1_macro", 
        "value": -0.0035, 
        "severity": 0, 
        "severity_value": 0.0035, 
        "code": "worst_score >= -1", 
        "message": "Method uce performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: uce\n  Metric id: f1_macro\n  Worst score: -0.0035%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score uce f1_macro", 
        "value": 0.0406, 
        "severity": 0, 
        "severity_value": 0.0203, 
        "code": "best_score <= 2", 
        "message": "Method uce performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: uce\n  Metric id: f1_macro\n  Best score: 0.0406%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score xgboost f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method xgboost performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: xgboost\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score xgboost f1_macro", 
        "value": 0.9801, 
        "severity": 0, 
        "severity_value": 0.49005, 
        "code": "best_score <= 2", 
        "message": "Method xgboost performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: xgboost\n  Metric id: f1_macro\n  Best score: 0.9801%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score majority_vote f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method majority_vote performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: majority_vote\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score majority_vote f1_micro", 
        "value": 0.1987, 
        "severity": 0, 
        "severity_value": 0.09935, 
        "code": "best_score <= 2", 
        "message": "Method majority_vote performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: majority_vote\n  Metric id: f1_micro\n  Best score: 0.1987%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score random_labels f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_labels performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: random_labels\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score random_labels f1_micro", 
        "value": 0.0426, 
        "severity": 0, 
        "severity_value": 0.0213, 
        "code": "best_score <= 2", 
        "message": "Method random_labels performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: random_labels\n  Metric id: f1_micro\n  Best score: 0.0426%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score true_labels f1_micro", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method true_labels performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: true_labels\n  Metric id: f1_micro\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score true_labels f1_micro", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method true_labels performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: true_labels\n  Metric id: f1_micro\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score geneformer f1_micro", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method geneformer performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: geneformer\n  Metric id: f1_micro\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score geneformer f1_micro", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method geneformer performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: geneformer\n  Metric id: f1_micro\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score knn f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knn performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: knn\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score knn f1_micro", 
        "value": 0.9933, 
        "severity": 0, 
        "severity_value": 0.49665, 
        "code": "best_score <= 2", 
        "message": "Method knn performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: knn\n  Metric id: f1_micro\n  Best score: 0.9933%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score logistic_regression f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method logistic_regression performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: logistic_regression\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score logistic_regression f1_micro", 
        "value": 0.9947, 
        "severity": 0, 
        "severity_value": 0.49735, 
        "code": "best_score <= 2", 
        "message": "Method logistic_regression performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: logistic_regression\n  Metric id: f1_micro\n  Best score: 0.9947%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score mlp f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mlp performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: mlp\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score mlp f1_micro", 
        "value": 0.996, 
        "severity": 0, 
        "severity_value": 0.498, 
        "code": "best_score <= 2", 
        "message": "Method mlp performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: mlp\n  Metric id: f1_micro\n  Best score: 0.996%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score naive_bayes f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method naive_bayes performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: naive_bayes\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score naive_bayes f1_micro", 
        "value": 0.992, 
        "severity": 0, 
        "severity_value": 0.496, 
        "code": "best_score <= 2", 
        "message": "Method naive_bayes performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: naive_bayes\n  Metric id: f1_micro\n  Best score: 0.992%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scanvi f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scanvi performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scanvi\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scanvi f1_micro", 
        "value": 0.996, 
        "severity": 0, 
        "severity_value": 0.498, 
        "code": "best_score <= 2", 
        "message": "Method scanvi performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scanvi\n  Metric id: f1_micro\n  Best score: 0.996%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scanvi_scarches f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scanvi_scarches performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scanvi_scarches\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scanvi_scarches f1_micro", 
        "value": 0.9947, 
        "severity": 0, 
        "severity_value": 0.49735, 
        "code": "best_score <= 2", 
        "message": "Method scanvi_scarches performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scanvi_scarches\n  Metric id: f1_micro\n  Best score: 0.9947%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scgpt_finetuned f1_micro", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scgpt_finetuned performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scgpt_finetuned\n  Metric id: f1_micro\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scgpt_finetuned f1_micro", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method scgpt_finetuned performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scgpt_finetuned\n  Metric id: f1_micro\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scgpt_zeroshot f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scgpt_zeroshot performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scgpt_zeroshot\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scgpt_zeroshot f1_micro", 
        "value": 0.8152, 
        "severity": 0, 
        "severity_value": 0.4076, 
        "code": "best_score <= 2", 
        "message": "Method scgpt_zeroshot performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scgpt_zeroshot\n  Metric id: f1_micro\n  Best score: 0.8152%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scimilarity f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scimilarity performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scimilarity\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scimilarity f1_micro", 
        "value": 0.8619, 
        "severity": 0, 
        "severity_value": 0.43095, 
        "code": "best_score <= 2", 
        "message": "Method scimilarity performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scimilarity\n  Metric id: f1_micro\n  Best score: 0.8619%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scimilarity_knn f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scimilarity_knn performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scimilarity_knn\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scimilarity_knn f1_micro", 
        "value": 0.9454, 
        "severity": 0, 
        "severity_value": 0.4727, 
        "code": "best_score <= 2", 
        "message": "Method scimilarity_knn performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scimilarity_knn\n  Metric id: f1_micro\n  Best score: 0.9454%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score scprint f1_micro", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scprint performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: scprint\n  Metric id: f1_micro\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score scprint f1_micro", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method scprint performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: scprint\n  Metric id: f1_micro\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score seurat_transferdata f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method seurat_transferdata performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: seurat_transferdata\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score seurat_transferdata f1_micro", 
        "value": 0.9947, 
        "severity": 0, 
        "severity_value": 0.49735, 
        "code": "best_score <= 2", 
        "message": "Method seurat_transferdata performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: seurat_transferdata\n  Metric id: f1_micro\n  Best score: 0.9947%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score singler f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method singler performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: singler\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score singler f1_micro", 
        "value": 0.9893, 
        "severity": 0, 
        "severity_value": 0.49465, 
        "code": "best_score <= 2", 
        "message": "Method singler performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: singler\n  Metric id: f1_micro\n  Best score: 0.9893%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score uce f1_micro", 
        "value": -0.0279, 
        "severity": 0, 
        "severity_value": 0.0279, 
        "code": "worst_score >= -1", 
        "message": "Method uce performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: uce\n  Metric id: f1_micro\n  Worst score: -0.0279%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score uce f1_micro", 
        "value": 0.1, 
        "severity": 0, 
        "severity_value": 0.05, 
        "code": "best_score <= 2", 
        "message": "Method uce performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: uce\n  Metric id: f1_micro\n  Best score: 0.1%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Worst score xgboost f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method xgboost performs much worse than baselines.\n  Task id: task_label_projection\n  Method id: xgboost\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_label_projection", 
        "category": "Scaling", 
        "name": "Best score xgboost f1_micro", 
        "value": 0.996, 
        "severity": 0, 
        "severity_value": 0.498, 
        "code": "best_score <= 2", 
        "message": "Method xgboost performs a lot better than baselines.\n  Task id: task_label_projection\n  Method id: xgboost\n  Metric id: f1_micro\n  Best score: 0.996%\n"
    }
]