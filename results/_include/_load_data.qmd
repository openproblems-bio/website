

```{r setup}
#| include: false
#| error: true
library(tidyverse)
library(kableExtra)

# touch library.bib in data dir
if (!file.exists("library.bib")) {
  file.create("library.bib")
}

# read task info
task_info <- jsonlite::read_json(paste0(params$data_dir, "/task_info.json"))

# add missing data
task_info$task_description <- task_info$task_description %||% NA_character_
task_info$task_motivation <- task_info$task_motivation %||% NA_character_

`%|%` <- function(x, y) {
  ifelse(is.na(x), y, x)
}

method_info <- jsonlite::read_json(paste0(params$data_dir, "/method_info.json"), simplifyVector = TRUE)
metric_info <- jsonlite::read_json(paste0(params$data_dir, "/metric_info.json"), simplifyVector = TRUE)
dataset_info <- jsonlite::read_json(paste0(params$data_dir, "/dataset_info.json"), simplifyVector = TRUE)
results <- jsonlite::read_json(paste0(params$data_dir, "/results.json"), simplifyVector = TRUE) %>% tibble()
qc <- if (file.exists(paste0(params$data_dir, "/quality_control.json"))) {
  jsonlite::read_json(paste0(params$data_dir, "/quality_control.json"), simplifyVector = TRUE)
} else {
  NULL
}

# add missing columns
for (col in c("method_summary", "method_description")) {
  method_info[[col]] <- method_info[[col]] %||% NA_character_
}
for (col in c("metric_summary", "metric_description")) {
  metric_info[[col]] <- metric_info[[col]] %||% NA_character_
}
for (col in c("dataset_summary", "dataset_description", "dataset_name")) {
  dataset_info[[col]] <- dataset_info[[col]] %||% NA_character_
}

# fill missing data
dataset_info$dataset_name <- dataset_info$dataset_name %|% dataset_info$dataset_id

split_cite_fun <- function(keys) {
  if (is.null(keys)) return("")

  keys <- keys[!is.na(keys)]
  if (length(keys) == 0) return("")

  refs <- unlist(stringr::str_split(keys, ", *"))
  # inner_str <- sapply(refs, function(ref) cite_fun(ref, format = format))
  # paste0("<sup>", paste(inner_str, collapse = ", "), "</sup>")
  # paste0("[", paste(inner_str, collapse = ", "), "]")
  paste0("[@", paste(refs, collapse = "; @"), "]")
}

convert_to_bibtex <- function(refs) {

  bibtexhandle <- curl::new_handle()
  curl::handle_setheaders(bibtexhandle, "accept" = "application/x-bibtex")

  bibs <- map(refs, function(ref) {
    if (grepl("^@", ref)) {
      # text is already a bibtex, update citation key
      ref
    } else {
      url <- paste0("https://doi.org/", ref)
      res <- curl::curl_fetch_memory(url, handle = bibtexhandle)
      if (res$status_code != 200) {
        cli::cli_alert_warning(paste0("Error processing doi '", ref, "'"))
        ""
      } else {
        rawToChar(res$content)
      }
    }
  })
  return(unlist(bibs))
}

get_bibtex_from_doi <- function(dois) {
  if (is.null(dois)) return("")

  dois <- dois[!is.na(dois)]
  if (length(dois) == 0) return("")

  bibtexhandle <- curl::new_handle()
  curl::handle_setheaders(bibtexhandle, "accept" = "application/x-bibtex")

  refs <- unlist(dois)
  bibs <- map (refs,function(ref) {
    url <- paste0("https://doi.org/", ref)
    res <- curl::curl_fetch_memory(url, handle = bibtexhandle)
    if (res$status_code != 200) {
      cli::cli_alert_warning(paste0("Error processing doi '", text, "'"))
      ""
    } else {
      rawToChar(res$content)
    }
  })

  return(unlist(bibs))
}

write_library <- function(library) {
  # Read existing entries from library.bib
  existing_bibs <- if (file.exists("library.bib")) {
    readLines("library.bib")
  } else {
    c()
  }

  # Filter out bibs that already exist in library.bib
  new_bibs <- library[!library %in% existing_bibs]

  # Write new entries to library.bib
  if (length(new_bibs) > 0) {
    write(new_bibs, "library.bib", append=TRUE)
  }
}

get_bibtex_entries <- function(bibs) {
  ref <-sapply(bibs, function(bib) {
    matches <- regmatches(bib, regexpr("@.*?\\{(.*?),", bib))
    if (length(matches) > 0) {
      sub("@.*?\\{(.*?),", "\\1", matches)
    } else {
      NA
    }
  })
  ref <- na.omit(ref)
  ref_string <- paste0("[@", ref, "]", collapse = " ")
  return(ref_string)
}

aggregate_scores <- function(scaled_score) {
  mean(pmin(1, pmax(0, scaled_score)) %|% 0)
}

strip_margin <- function(text, symbol = "\\|") {
  str_replace_all(text, paste0("(\n?)[ \t]*", symbol), "\\1")
}

ojs_define(
  task_info = jsonlite::read_json(paste0(params$data_dir, "/task_info.json")),
  dataset_info = jsonlite::read_json(paste0(params$data_dir, "/dataset_info.json")),
  method_info = jsonlite::read_json(paste0(params$data_dir, "/method_info.json")),
  metric_info = jsonlite::read_json(paste0(params$data_dir, "/metric_info.json")),
  results = jsonlite::read_json(paste0(params$data_dir, "/results.json"))
)
```

```{r overall_ranking}
#| echo: false
results_long <-
  inner_join(
    results %>%
      select(method_id, dataset_id, metric_values) %>%
      unnest(metric_values) %>%
      gather(metric_id, value, any_of(metric_info$metric_id)) %>%
      mutate(value = ifelse(is.na(value), NA_real_, value)),
    results %>%
      select(method_id, dataset_id, scaled_scores) %>%
      unnest(scaled_scores) %>%
      gather(metric_id, score, any_of(metric_info$metric_id)) %>%
      mutate(score = ifelse(is.na(score), NA_real_, score)),
    by = c("method_id", "dataset_id", "metric_id")
  ) %>%
  left_join(method_info %>% select(method_id, is_baseline), "method_id")

overall_ranking <- results_long %>%
  group_by(method_id) %>%
  summarise(mean_score = aggregate_scores(score)) %>%
  arrange(desc(mean_score))

# order by ranking
results_long$method_id <- factor(results_long$method_id, levels = rev(overall_ranking$method_id))
results$method_id <- factor(results$method_id, levels = rev(overall_ranking$method_id))
method_info$method_id <- factor(method_info$method_id, levels = rev(overall_ranking$method_id))
```
