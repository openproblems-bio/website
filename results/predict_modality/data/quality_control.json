[
    {
        "task_id": "task_predict_modality", 
        "category": "Task info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_id' should be defined\n  Task id: task_predict_modality\n  Field: task_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Task info", 
        "name": "Pct 'task_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_name' should be defined\n  Task id: task_predict_modality\n  Field: task_name\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Task info", 
        "name": "Pct 'task_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_summary' should be defined\n  Task id: task_predict_modality\n  Field: task_summary\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Task info", 
        "name": "Pct 'task_description' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_description' should be defined\n  Task id: task_predict_modality\n  Field: task_description\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'task_id' should be defined\n  Task id: task_predict_modality\n  Field: task_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'commit_sha' should be defined\n  Task id: task_predict_modality\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'method_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_id' should be defined\n  Task id: task_predict_modality\n  Field: method_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'method_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_name' should be defined\n  Task id: task_predict_modality\n  Field: method_name\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'method_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_summary' should be defined\n  Task id: task_predict_modality\n  Field: method_summary\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 0.5555555555555556, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'paper_reference' should be defined\n  Task id: task_predict_modality\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'is_baseline' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'is_baseline' should be defined\n  Task id: task_predict_modality\n  Field: is_baseline\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'task_id' should be defined\n  Task id: task_predict_modality\n  Field: task_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'commit_sha' should be defined\n  Task id: task_predict_modality\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'metric_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_id' should be defined\n  Task id: task_predict_modality\n  Field: metric_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'metric_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_name' should be defined\n  Task id: task_predict_modality\n  Field: metric_name\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'metric_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_summary' should be defined\n  Task id: task_predict_modality\n  Field: metric_summary\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'paper_reference' should be defined\n  Task id: task_predict_modality\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'maximize' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'maximize' should be defined\n  Task id: task_predict_modality\n  Field: maximize\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'task_id' missing", 
        "value": 1.0, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'task_id' should be defined\n  Task id: task_predict_modality\n  Field: task_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_id' should be defined\n  Task id: task_predict_modality\n  Field: dataset_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_name' should be defined\n  Task id: task_predict_modality\n  Field: dataset_name\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_summary' should be defined\n  Task id: task_predict_modality\n  Field: dataset_summary\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'data_reference' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_reference' should be defined\n  Task id: task_predict_modality\n  Field: data_reference\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'data_url' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_url' should be defined\n  Task id: task_predict_modality\n  Field: data_url\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw data", 
        "name": "Number of results", 
        "value": 72, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "len(results) == len(method_info) * len(metric_info) * len(dataset_info)", 
        "message": "Number of results should be equal to #methods × #metrics × #datasets.\n  Task id: task_predict_modality\n  Number of results: 72\n  Number of methods: 9\n  Number of metrics: 8\n  Number of datasets: 8\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'mean_pearson_per_cell' %missing", 
        "value": 0.05555555555555558, 
        "severity": 0, 
        "severity_value": 0.5555555555555558, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: mean_pearson_per_cell\n  Percentage missing: 6%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'mean_spearman_per_cell' %missing", 
        "value": 0.05555555555555558, 
        "severity": 0, 
        "severity_value": 0.5555555555555558, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: mean_spearman_per_cell\n  Percentage missing: 6%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'mean_pearson_per_gene' %missing", 
        "value": 0.05555555555555558, 
        "severity": 0, 
        "severity_value": 0.5555555555555558, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: mean_pearson_per_gene\n  Percentage missing: 6%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'mean_spearman_per_gene' %missing", 
        "value": 0.05555555555555558, 
        "severity": 0, 
        "severity_value": 0.5555555555555558, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: mean_spearman_per_gene\n  Percentage missing: 6%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'overall_pearson' %missing", 
        "value": 0.16666666666666663, 
        "severity": 1, 
        "severity_value": 1.6666666666666663, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: overall_pearson\n  Percentage missing: 17%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'overall_spearman' %missing", 
        "value": 0.16666666666666663, 
        "severity": 1, 
        "severity_value": 1.6666666666666663, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: overall_spearman\n  Percentage missing: 17%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'rmse' %missing", 
        "value": 0.05555555555555558, 
        "severity": 0, 
        "severity_value": 0.5555555555555558, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: rmse\n  Percentage missing: 6%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'mae' %missing", 
        "value": 0.05555555555555558, 
        "severity": 0, 
        "severity_value": 0.5555555555555558, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: mae\n  Percentage missing: 6%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'mean_per_gene' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: mean_per_gene\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'random_predict' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: random_predict\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'zeros' %missing", 
        "value": 0.25, 
        "severity": 2, 
        "severity_value": 2.5, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: zeros\n  Percentage missing: 25%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'solution' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: solution\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'knnr_py' %missing", 
        "value": 0.125, 
        "severity": 1, 
        "severity_value": 1.25, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: knnr_py\n  Percentage missing: 12%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'knnr_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: knnr_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'lm' %missing", 
        "value": 0.125, 
        "severity": 1, 
        "severity_value": 1.25, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: lm\n  Percentage missing: 12%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'lmds_irlba_rf' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: lmds_irlba_rf\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'guanlab_dengkw_pm' %missing", 
        "value": 0.25, 
        "severity": 2, 
        "severity_value": 2.5, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: guanlab_dengkw_pm\n  Percentage missing: 25%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2022/pbmc_multiome/swap' %missing", 
        "value": 0.36111111111111116, 
        "severity": 3, 
        "severity_value": 3.6111111111111116, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2022/pbmc_multiome/swap\n  Percentage missing: 36%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2021/bmmc_multiome/swap' %missing", 
        "value": 0.02777777777777779, 
        "severity": 0, 
        "severity_value": 0.2777777777777779, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2021/bmmc_multiome/swap\n  Percentage missing: 3%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2022/pbmc_cite/normal' %missing", 
        "value": 0.02777777777777779, 
        "severity": 0, 
        "severity_value": 0.2777777777777779, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2022/pbmc_cite/normal\n  Percentage missing: 3%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2021/bmmc_cite/normal' %missing", 
        "value": 0.02777777777777779, 
        "severity": 0, 
        "severity_value": 0.2777777777777779, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2021/bmmc_cite/normal\n  Percentage missing: 3%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2022/pbmc_cite/swap' %missing", 
        "value": 0.02777777777777779, 
        "severity": 0, 
        "severity_value": 0.2777777777777779, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2022/pbmc_cite/swap\n  Percentage missing: 3%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2021/bmmc_cite/swap' %missing", 
        "value": 0.02777777777777779, 
        "severity": 0, 
        "severity_value": 0.2777777777777779, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2021/bmmc_cite/swap\n  Percentage missing: 3%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2022/pbmc_multiome/normal' %missing", 
        "value": 0.13888888888888884, 
        "severity": 1, 
        "severity_value": 1.3888888888888884, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2022/pbmc_multiome/normal\n  Percentage missing: 14%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2021/bmmc_multiome/normal' %missing", 
        "value": 0.02777777777777779, 
        "severity": 0, 
        "severity_value": 0.2777777777777779, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2021/bmmc_multiome/normal\n  Percentage missing: 3%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene mean_pearson_per_cell", 
        "value": 0.1425, 
        "severity": 0, 
        "severity_value": -0.1425, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.1425%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene mean_pearson_per_cell", 
        "value": 0.849, 
        "severity": 0, 
        "severity_value": 0.4245, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_pearson_per_cell\n  Best score: 0.849%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict mean_pearson_per_cell", 
        "value": 0.0205, 
        "severity": 0, 
        "severity_value": -0.0205, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.0205%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict mean_pearson_per_cell", 
        "value": 0.7547, 
        "severity": 0, 
        "severity_value": 0.37735, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_pearson_per_cell\n  Best score: 0.7547%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_pearson_per_cell", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_pearson_per_cell\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros mean_pearson_per_cell", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_pearson_per_cell\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution mean_pearson_per_cell", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_pearson_per_cell\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution mean_pearson_per_cell", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_pearson_per_cell\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py mean_pearson_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py mean_pearson_per_cell", 
        "value": 0.8766, 
        "severity": 0, 
        "severity_value": 0.4383, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_pearson_per_cell\n  Best score: 0.8766%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r mean_pearson_per_cell", 
        "value": 0.1081, 
        "severity": 0, 
        "severity_value": -0.1081, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.1081%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r mean_pearson_per_cell", 
        "value": 0.8741, 
        "severity": 0, 
        "severity_value": 0.43705, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_pearson_per_cell\n  Best score: 0.8741%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm mean_pearson_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm mean_pearson_per_cell", 
        "value": 0.7042, 
        "severity": 0, 
        "severity_value": 0.3521, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_pearson_per_cell\n  Best score: 0.7042%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lmds_irlba_rf mean_pearson_per_cell", 
        "value": 0.0753, 
        "severity": 0, 
        "severity_value": -0.0753, 
        "code": "worst_score >= -1", 
        "message": "Method lmds_irlba_rf performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.0753%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lmds_irlba_rf mean_pearson_per_cell", 
        "value": 0.7112, 
        "severity": 0, 
        "severity_value": 0.3556, 
        "code": "best_score <= 2", 
        "message": "Method lmds_irlba_rf performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mean_pearson_per_cell\n  Best score: 0.7112%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm mean_pearson_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm mean_pearson_per_cell", 
        "value": 0.8843, 
        "severity": 0, 
        "severity_value": 0.44215, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_pearson_per_cell\n  Best score: 0.8843%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene mean_spearman_per_cell", 
        "value": 0.1574, 
        "severity": 0, 
        "severity_value": -0.1574, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.1574%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene mean_spearman_per_cell", 
        "value": 0.5996, 
        "severity": 0, 
        "severity_value": 0.2998, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_spearman_per_cell\n  Best score: 0.5996%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict mean_spearman_per_cell", 
        "value": 0.0853, 
        "severity": 0, 
        "severity_value": -0.0853, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.0853%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict mean_spearman_per_cell", 
        "value": 0.5182, 
        "severity": 0, 
        "severity_value": 0.2591, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_spearman_per_cell\n  Best score: 0.5182%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_spearman_per_cell", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_spearman_per_cell\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros mean_spearman_per_cell", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_spearman_per_cell\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution mean_spearman_per_cell", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_spearman_per_cell\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution mean_spearman_per_cell", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_spearman_per_cell\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py mean_spearman_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py mean_spearman_per_cell", 
        "value": 0.6912, 
        "severity": 0, 
        "severity_value": 0.3456, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_spearman_per_cell\n  Best score: 0.6912%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r mean_spearman_per_cell", 
        "value": 0.194, 
        "severity": 0, 
        "severity_value": -0.194, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.194%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r mean_spearman_per_cell", 
        "value": 0.6717, 
        "severity": 0, 
        "severity_value": 0.33585, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_spearman_per_cell\n  Best score: 0.6717%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm mean_spearman_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm mean_spearman_per_cell", 
        "value": 0.6085, 
        "severity": 0, 
        "severity_value": 0.30425, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_spearman_per_cell\n  Best score: 0.6085%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lmds_irlba_rf mean_spearman_per_cell", 
        "value": 0.0234, 
        "severity": 0, 
        "severity_value": -0.0234, 
        "code": "worst_score >= -1", 
        "message": "Method lmds_irlba_rf performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.0234%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lmds_irlba_rf mean_spearman_per_cell", 
        "value": 0.5932, 
        "severity": 0, 
        "severity_value": 0.2966, 
        "code": "best_score <= 2", 
        "message": "Method lmds_irlba_rf performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mean_spearman_per_cell\n  Best score: 0.5932%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm mean_spearman_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm mean_spearman_per_cell", 
        "value": 0.686, 
        "severity": 0, 
        "severity_value": 0.343, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_spearman_per_cell\n  Best score: 0.686%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene mean_pearson_per_gene", 
        "value": 2.2277e-06, 
        "severity": 0, 
        "severity_value": 1.11385e-06, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_pearson_per_gene\n  Best score: 2.2277e-06%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict mean_pearson_per_gene", 
        "value": 0.0117, 
        "severity": 0, 
        "severity_value": 0.00585, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_pearson_per_gene\n  Best score: 0.0117%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros mean_pearson_per_gene", 
        "value": 2.2277e-06, 
        "severity": 0, 
        "severity_value": 1.11385e-06, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_pearson_per_gene\n  Best score: 2.2277e-06%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution mean_pearson_per_gene", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_pearson_per_gene\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution mean_pearson_per_gene", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_pearson_per_gene\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py mean_pearson_per_gene", 
        "value": 0.5943, 
        "severity": 0, 
        "severity_value": 0.29715, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_pearson_per_gene\n  Best score: 0.5943%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r mean_pearson_per_gene", 
        "value": 0.0183, 
        "severity": 0, 
        "severity_value": -0.0183, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0183%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r mean_pearson_per_gene", 
        "value": 0.5437, 
        "severity": 0, 
        "severity_value": 0.27185, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_pearson_per_gene\n  Best score: 0.5437%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm mean_pearson_per_gene", 
        "value": 0.5152, 
        "severity": 0, 
        "severity_value": 0.2576, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_pearson_per_gene\n  Best score: 0.5152%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lmds_irlba_rf mean_pearson_per_gene", 
        "value": 0.0617, 
        "severity": 0, 
        "severity_value": -0.0617, 
        "code": "worst_score >= -1", 
        "message": "Method lmds_irlba_rf performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0617%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lmds_irlba_rf mean_pearson_per_gene", 
        "value": 0.551, 
        "severity": 0, 
        "severity_value": 0.2755, 
        "code": "best_score <= 2", 
        "message": "Method lmds_irlba_rf performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mean_pearson_per_gene\n  Best score: 0.551%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm mean_pearson_per_gene", 
        "value": 0.6394, 
        "severity": 0, 
        "severity_value": 0.3197, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_pearson_per_gene\n  Best score: 0.6394%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene mean_spearman_per_gene", 
        "value": 0.0001, 
        "severity": 0, 
        "severity_value": 5e-05, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_spearman_per_gene\n  Best score: 0.0001%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict mean_spearman_per_gene", 
        "value": 0.0048, 
        "severity": 0, 
        "severity_value": 0.0024, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_spearman_per_gene\n  Best score: 0.0048%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros mean_spearman_per_gene", 
        "value": 0.0001, 
        "severity": 0, 
        "severity_value": 5e-05, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_spearman_per_gene\n  Best score: 0.0001%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution mean_spearman_per_gene", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_spearman_per_gene\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution mean_spearman_per_gene", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_spearman_per_gene\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py mean_spearman_per_gene", 
        "value": 0.4881, 
        "severity": 0, 
        "severity_value": 0.24405, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_spearman_per_gene\n  Best score: 0.4881%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r mean_spearman_per_gene", 
        "value": 0.0187, 
        "severity": 0, 
        "severity_value": -0.0187, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0187%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r mean_spearman_per_gene", 
        "value": 0.4353, 
        "severity": 0, 
        "severity_value": 0.21765, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_spearman_per_gene\n  Best score: 0.4353%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm mean_spearman_per_gene", 
        "value": 0.4206, 
        "severity": 0, 
        "severity_value": 0.2103, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_spearman_per_gene\n  Best score: 0.4206%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lmds_irlba_rf mean_spearman_per_gene", 
        "value": 0.0629, 
        "severity": 0, 
        "severity_value": -0.0629, 
        "code": "worst_score >= -1", 
        "message": "Method lmds_irlba_rf performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0629%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lmds_irlba_rf mean_spearman_per_gene", 
        "value": 0.4502, 
        "severity": 0, 
        "severity_value": 0.2251, 
        "code": "best_score <= 2", 
        "message": "Method lmds_irlba_rf performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mean_spearman_per_gene\n  Best score: 0.4502%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm mean_spearman_per_gene", 
        "value": 0.5008, 
        "severity": 0, 
        "severity_value": 0.2504, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_spearman_per_gene\n  Best score: 0.5008%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene overall_pearson", 
        "value": 0.1141, 
        "severity": 0, 
        "severity_value": -0.1141, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: overall_pearson\n  Worst score: 0.1141%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene overall_pearson", 
        "value": 0.4139, 
        "severity": 0, 
        "severity_value": 0.20695, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: overall_pearson\n  Best score: 0.4139%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict overall_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: overall_pearson\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict overall_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: overall_pearson\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros overall_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: overall_pearson\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros overall_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: overall_pearson\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution overall_pearson", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: overall_pearson\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution overall_pearson", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: overall_pearson\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py overall_pearson", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: overall_pearson\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py overall_pearson", 
        "value": 0.7034, 
        "severity": 0, 
        "severity_value": 0.3517, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: overall_pearson\n  Best score: 0.7034%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r overall_pearson", 
        "value": 0.086, 
        "severity": 0, 
        "severity_value": -0.086, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: overall_pearson\n  Worst score: 0.086%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r overall_pearson", 
        "value": 0.6629, 
        "severity": 0, 
        "severity_value": 0.33145, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: overall_pearson\n  Best score: 0.6629%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm overall_pearson", 
        "value": -1.0596, 
        "severity": 1, 
        "severity_value": 1.0596, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: overall_pearson\n  Worst score: -1.0596%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm overall_pearson", 
        "value": 0.6412, 
        "severity": 0, 
        "severity_value": 0.3206, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: overall_pearson\n  Best score: 0.6412%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lmds_irlba_rf overall_pearson", 
        "value": -2.4094, 
        "severity": 2, 
        "severity_value": 2.4094, 
        "code": "worst_score >= -1", 
        "message": "Method lmds_irlba_rf performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: overall_pearson\n  Worst score: -2.4094%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lmds_irlba_rf overall_pearson", 
        "value": 0.6487, 
        "severity": 0, 
        "severity_value": 0.32435, 
        "code": "best_score <= 2", 
        "message": "Method lmds_irlba_rf performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: overall_pearson\n  Best score: 0.6487%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm overall_pearson", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: overall_pearson\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm overall_pearson", 
        "value": 0.7431, 
        "severity": 0, 
        "severity_value": 0.37155, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: overall_pearson\n  Best score: 0.7431%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene overall_spearman", 
        "value": 0.0678, 
        "severity": 0, 
        "severity_value": -0.0678, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: overall_spearman\n  Worst score: 0.0678%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene overall_spearman", 
        "value": 0.1834, 
        "severity": 0, 
        "severity_value": 0.0917, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: overall_spearman\n  Best score: 0.1834%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict overall_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: overall_spearman\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict overall_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: overall_spearman\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros overall_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: overall_spearman\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros overall_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: overall_spearman\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution overall_spearman", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: overall_spearman\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution overall_spearman", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: overall_spearman\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py overall_spearman", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: overall_spearman\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py overall_spearman", 
        "value": 0.5994, 
        "severity": 0, 
        "severity_value": 0.2997, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: overall_spearman\n  Best score: 0.5994%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r overall_spearman", 
        "value": 0.1053, 
        "severity": 0, 
        "severity_value": -0.1053, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: overall_spearman\n  Worst score: 0.1053%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r overall_spearman", 
        "value": 0.5595, 
        "severity": 0, 
        "severity_value": 0.27975, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: overall_spearman\n  Best score: 0.5595%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm overall_spearman", 
        "value": -0.3417, 
        "severity": 0, 
        "severity_value": 0.3417, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: overall_spearman\n  Worst score: -0.3417%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm overall_spearman", 
        "value": 0.5137, 
        "severity": 0, 
        "severity_value": 0.25685, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: overall_spearman\n  Best score: 0.5137%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lmds_irlba_rf overall_spearman", 
        "value": -0.988, 
        "severity": 0, 
        "severity_value": 0.988, 
        "code": "worst_score >= -1", 
        "message": "Method lmds_irlba_rf performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: overall_spearman\n  Worst score: -0.988%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lmds_irlba_rf overall_spearman", 
        "value": 0.5176, 
        "severity": 0, 
        "severity_value": 0.2588, 
        "code": "best_score <= 2", 
        "message": "Method lmds_irlba_rf performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: overall_spearman\n  Best score: 0.5176%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm overall_spearman", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: overall_spearman\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm overall_spearman", 
        "value": 0.6116, 
        "severity": 0, 
        "severity_value": 0.3058, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: overall_spearman\n  Best score: 0.6116%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene rmse", 
        "value": 0.1976, 
        "severity": 0, 
        "severity_value": -0.1976, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: rmse\n  Worst score: 0.1976%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene rmse", 
        "value": 0.5005, 
        "severity": 0, 
        "severity_value": 0.25025, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: rmse\n  Best score: 0.5005%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict rmse", 
        "value": 0.3395, 
        "severity": 0, 
        "severity_value": 0.16975, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: rmse\n  Best score: 0.3395%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros rmse", 
        "value": 0.3028, 
        "severity": 0, 
        "severity_value": 0.1514, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: rmse\n  Best score: 0.3028%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution rmse", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: rmse\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution rmse", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: rmse\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py rmse", 
        "value": 0.5468, 
        "severity": 0, 
        "severity_value": 0.2734, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: rmse\n  Best score: 0.5468%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r rmse", 
        "value": 0.1994, 
        "severity": 0, 
        "severity_value": -0.1994, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: rmse\n  Worst score: 0.1994%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r rmse", 
        "value": 0.5423, 
        "severity": 0, 
        "severity_value": 0.27115, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: rmse\n  Best score: 0.5423%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm rmse", 
        "value": 0.4619, 
        "severity": 0, 
        "severity_value": 0.23095, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: rmse\n  Best score: 0.4619%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lmds_irlba_rf rmse", 
        "value": 0.0083, 
        "severity": 0, 
        "severity_value": -0.0083, 
        "code": "worst_score >= -1", 
        "message": "Method lmds_irlba_rf performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: rmse\n  Worst score: 0.0083%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lmds_irlba_rf rmse", 
        "value": 0.303, 
        "severity": 0, 
        "severity_value": 0.1515, 
        "code": "best_score <= 2", 
        "message": "Method lmds_irlba_rf performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: rmse\n  Best score: 0.303%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm rmse", 
        "value": 0.561, 
        "severity": 0, 
        "severity_value": 0.2805, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: rmse\n  Best score: 0.561%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene mae", 
        "value": 0.0164, 
        "severity": 0, 
        "severity_value": -0.0164, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mae\n  Worst score: 0.0164%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene mae", 
        "value": 0.4307, 
        "severity": 0, 
        "severity_value": 0.21535, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mae\n  Best score: 0.4307%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict mae", 
        "value": 0.2697, 
        "severity": 0, 
        "severity_value": 0.13485, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mae\n  Best score: 0.2697%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros mae", 
        "value": 0.4618, 
        "severity": 0, 
        "severity_value": 0.2309, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mae\n  Best score: 0.4618%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution mae", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mae\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution mae", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mae\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py mae", 
        "value": 0.5267, 
        "severity": 0, 
        "severity_value": 0.26335, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mae\n  Best score: 0.5267%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r mae", 
        "value": 0.0231, 
        "severity": 0, 
        "severity_value": -0.0231, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mae\n  Worst score: 0.0231%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r mae", 
        "value": 0.5142, 
        "severity": 0, 
        "severity_value": 0.2571, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mae\n  Best score: 0.5142%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm mae", 
        "value": 0.4796, 
        "severity": 0, 
        "severity_value": 0.2398, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mae\n  Best score: 0.4796%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lmds_irlba_rf mae", 
        "value": -0.0608, 
        "severity": 0, 
        "severity_value": 0.0608, 
        "code": "worst_score >= -1", 
        "message": "Method lmds_irlba_rf performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mae\n  Worst score: -0.0608%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lmds_irlba_rf mae", 
        "value": 0.279, 
        "severity": 0, 
        "severity_value": 0.1395, 
        "code": "best_score <= 2", 
        "message": "Method lmds_irlba_rf performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mae\n  Best score: 0.279%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm mae", 
        "value": 0.5126, 
        "severity": 0, 
        "severity_value": 0.2563, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mae\n  Best score: 0.5126%\n"
    }
]