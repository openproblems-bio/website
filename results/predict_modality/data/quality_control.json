[
    {
        "task_id": "task_predict_modality", 
        "category": "Task info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_id' should be defined\n  Task id: task_predict_modality\n  Field: task_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Task info", 
        "name": "Pct 'task_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_name' should be defined\n  Task id: task_predict_modality\n  Field: task_name\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Task info", 
        "name": "Pct 'task_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_summary' should be defined\n  Task id: task_predict_modality\n  Field: task_summary\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Task info", 
        "name": "Pct 'task_description' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_description' should be defined\n  Task id: task_predict_modality\n  Field: task_description\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'task_id' should be defined\n  Task id: task_predict_modality\n  Field: task_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'commit_sha' should be defined\n  Task id: task_predict_modality\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'method_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_id' should be defined\n  Task id: task_predict_modality\n  Field: method_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'method_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_name' should be defined\n  Task id: task_predict_modality\n  Field: method_name\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'method_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_summary' should be defined\n  Task id: task_predict_modality\n  Field: method_summary\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 0.6, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'paper_reference' should be defined\n  Task id: task_predict_modality\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'is_baseline' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'is_baseline' should be defined\n  Task id: task_predict_modality\n  Field: is_baseline\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'task_id' should be defined\n  Task id: task_predict_modality\n  Field: task_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'commit_sha' should be defined\n  Task id: task_predict_modality\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'metric_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_id' should be defined\n  Task id: task_predict_modality\n  Field: metric_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'metric_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_name' should be defined\n  Task id: task_predict_modality\n  Field: metric_name\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'metric_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_summary' should be defined\n  Task id: task_predict_modality\n  Field: metric_summary\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 1.0, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'paper_reference' should be defined\n  Task id: task_predict_modality\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'maximize' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'maximize' should be defined\n  Task id: task_predict_modality\n  Field: maximize\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'task_id' missing", 
        "value": 1.0, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'task_id' should be defined\n  Task id: task_predict_modality\n  Field: task_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_id' should be defined\n  Task id: task_predict_modality\n  Field: dataset_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_name' should be defined\n  Task id: task_predict_modality\n  Field: dataset_name\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_summary' should be defined\n  Task id: task_predict_modality\n  Field: dataset_summary\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'data_reference' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_reference' should be defined\n  Task id: task_predict_modality\n  Field: data_reference\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'data_url' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_url' should be defined\n  Task id: task_predict_modality\n  Field: data_url\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw data", 
        "name": "Number of results", 
        "value": 80, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "len(results) == len(method_info) * len(metric_info) * len(dataset_info)", 
        "message": "Number of results should be equal to #methods × #metrics × #datasets.\n  Task id: task_predict_modality\n  Number of results: 80\n  Number of methods: 10\n  Number of metrics: 8\n  Number of datasets: 8\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'mean_pearson_per_cell' %missing", 
        "value": 0.22499999999999998, 
        "severity": 2, 
        "severity_value": 2.2499999999999996, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: mean_pearson_per_cell\n  Percentage missing: 22%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'mean_spearman_per_cell' %missing", 
        "value": 0.22499999999999998, 
        "severity": 2, 
        "severity_value": 2.2499999999999996, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: mean_spearman_per_cell\n  Percentage missing: 22%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'mean_pearson_per_gene' %missing", 
        "value": 0.22499999999999998, 
        "severity": 2, 
        "severity_value": 2.2499999999999996, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: mean_pearson_per_gene\n  Percentage missing: 22%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'mean_spearman_per_gene' %missing", 
        "value": 0.22499999999999998, 
        "severity": 2, 
        "severity_value": 2.2499999999999996, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: mean_spearman_per_gene\n  Percentage missing: 22%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'overall_pearson' %missing", 
        "value": 0.32499999999999996, 
        "severity": 3, 
        "severity_value": 3.2499999999999996, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: overall_pearson\n  Percentage missing: 32%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'overall_spearman' %missing", 
        "value": 0.32499999999999996, 
        "severity": 3, 
        "severity_value": 3.2499999999999996, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: overall_spearman\n  Percentage missing: 32%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'rmse' %missing", 
        "value": 0.21250000000000002, 
        "severity": 2, 
        "severity_value": 2.125, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: rmse\n  Percentage missing: 21%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'mae' %missing", 
        "value": 0.21250000000000002, 
        "severity": 2, 
        "severity_value": 2.125, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: mae\n  Percentage missing: 21%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'mean_per_gene' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: mean_per_gene\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'random_predict' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: random_predict\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'zeros' %missing", 
        "value": 0.25, 
        "severity": 2, 
        "severity_value": 2.5, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: zeros\n  Percentage missing: 25%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'solution' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: solution\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'knnr_py' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: knnr_py\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'knnr_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: knnr_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'lm' %missing", 
        "value": 0.21875, 
        "severity": 2, 
        "severity_value": 2.1875, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: lm\n  Percentage missing: 22%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'guanlab_dengkw_pm' %missing", 
        "value": 0.25, 
        "severity": 2, 
        "severity_value": 2.5, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: guanlab_dengkw_pm\n  Percentage missing: 25%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'novel' %missing", 
        "value": 0.75, 
        "severity": 3, 
        "severity_value": 7.5, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: novel\n  Percentage missing: 75%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'simple_mlp' %missing", 
        "value": 1.0, 
        "severity": 3, 
        "severity_value": 10.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: simple_mlp\n  Percentage missing: 100%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2022/pbmc_multiome/swap' %missing", 
        "value": 0.32499999999999996, 
        "severity": 3, 
        "severity_value": 3.2499999999999996, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2022/pbmc_multiome/swap\n  Percentage missing: 32%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2021/bmmc_multiome/swap' %missing", 
        "value": 0.22499999999999998, 
        "severity": 2, 
        "severity_value": 2.2499999999999996, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2021/bmmc_multiome/swap\n  Percentage missing: 22%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2021/bmmc_cite/normal' %missing", 
        "value": 0.125, 
        "severity": 1, 
        "severity_value": 1.25, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2021/bmmc_cite/normal\n  Percentage missing: 12%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2022/pbmc_cite/normal' %missing", 
        "value": 0.22499999999999998, 
        "severity": 2, 
        "severity_value": 2.2499999999999996, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2022/pbmc_cite/normal\n  Percentage missing: 22%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2022/pbmc_cite/swap' %missing", 
        "value": 0.32499999999999996, 
        "severity": 3, 
        "severity_value": 3.2499999999999996, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2022/pbmc_cite/swap\n  Percentage missing: 32%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2021/bmmc_cite/swap' %missing", 
        "value": 0.19999999999999996, 
        "severity": 1, 
        "severity_value": 1.9999999999999996, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2021/bmmc_cite/swap\n  Percentage missing: 20%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2022/pbmc_multiome/normal' %missing", 
        "value": 0.32499999999999996, 
        "severity": 3, 
        "severity_value": 3.2499999999999996, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2022/pbmc_multiome/normal\n  Percentage missing: 32%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2021/bmmc_multiome/normal' %missing", 
        "value": 0.22499999999999998, 
        "severity": 2, 
        "severity_value": 2.2499999999999996, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2021/bmmc_multiome/normal\n  Percentage missing: 22%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene mean_pearson_per_cell", 
        "value": 0.1425, 
        "severity": 0, 
        "severity_value": -0.1425, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.1425%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene mean_pearson_per_cell", 
        "value": 0.849, 
        "severity": 0, 
        "severity_value": 0.4245, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_pearson_per_cell\n  Best score: 0.849%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict mean_pearson_per_cell", 
        "value": 0.0211, 
        "severity": 0, 
        "severity_value": -0.0211, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.0211%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict mean_pearson_per_cell", 
        "value": 0.7542, 
        "severity": 0, 
        "severity_value": 0.3771, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_pearson_per_cell\n  Best score: 0.7542%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_pearson_per_cell", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_pearson_per_cell\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros mean_pearson_per_cell", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_pearson_per_cell\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution mean_pearson_per_cell", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_pearson_per_cell\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution mean_pearson_per_cell", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_pearson_per_cell\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py mean_pearson_per_cell", 
        "value": 0.161, 
        "severity": 0, 
        "severity_value": -0.161, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.161%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py mean_pearson_per_cell", 
        "value": 0.8766, 
        "severity": 0, 
        "severity_value": 0.4383, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_pearson_per_cell\n  Best score: 0.8766%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r mean_pearson_per_cell", 
        "value": 0.1076, 
        "severity": 0, 
        "severity_value": -0.1076, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.1076%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r mean_pearson_per_cell", 
        "value": 0.8736, 
        "severity": 0, 
        "severity_value": 0.4368, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_pearson_per_cell\n  Best score: 0.8736%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm mean_pearson_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm mean_pearson_per_cell", 
        "value": 0.7043, 
        "severity": 0, 
        "severity_value": 0.35215, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_pearson_per_cell\n  Best score: 0.7043%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm mean_pearson_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm mean_pearson_per_cell", 
        "value": 0.8844, 
        "severity": 0, 
        "severity_value": 0.4422, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_pearson_per_cell\n  Best score: 0.8844%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score novel mean_pearson_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method novel performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: novel\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score novel mean_pearson_per_cell", 
        "value": 0.7762, 
        "severity": 0, 
        "severity_value": 0.3881, 
        "code": "best_score <= 2", 
        "message": "Method novel performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: novel\n  Metric id: mean_pearson_per_cell\n  Best score: 0.7762%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score simple_mlp mean_pearson_per_cell", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method simple_mlp performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: simple_mlp\n  Metric id: mean_pearson_per_cell\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score simple_mlp mean_pearson_per_cell", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method simple_mlp performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: simple_mlp\n  Metric id: mean_pearson_per_cell\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene mean_spearman_per_cell", 
        "value": 0.1574, 
        "severity": 0, 
        "severity_value": -0.1574, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.1574%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene mean_spearman_per_cell", 
        "value": 0.5996, 
        "severity": 0, 
        "severity_value": 0.2998, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_spearman_per_cell\n  Best score: 0.5996%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict mean_spearman_per_cell", 
        "value": 0.0836, 
        "severity": 0, 
        "severity_value": -0.0836, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.0836%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict mean_spearman_per_cell", 
        "value": 0.5175, 
        "severity": 0, 
        "severity_value": 0.25875, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_spearman_per_cell\n  Best score: 0.5175%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_spearman_per_cell", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_spearman_per_cell\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros mean_spearman_per_cell", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_spearman_per_cell\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution mean_spearman_per_cell", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_spearman_per_cell\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution mean_spearman_per_cell", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_spearman_per_cell\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py mean_spearman_per_cell", 
        "value": 0.1966, 
        "severity": 0, 
        "severity_value": -0.1966, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.1966%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py mean_spearman_per_cell", 
        "value": 0.6917, 
        "severity": 0, 
        "severity_value": 0.34585, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_spearman_per_cell\n  Best score: 0.6917%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r mean_spearman_per_cell", 
        "value": 0.194, 
        "severity": 0, 
        "severity_value": -0.194, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.194%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r mean_spearman_per_cell", 
        "value": 0.6703, 
        "severity": 0, 
        "severity_value": 0.33515, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_spearman_per_cell\n  Best score: 0.6703%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm mean_spearman_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm mean_spearman_per_cell", 
        "value": 0.6062, 
        "severity": 0, 
        "severity_value": 0.3031, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_spearman_per_cell\n  Best score: 0.6062%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm mean_spearman_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm mean_spearman_per_cell", 
        "value": 0.6864, 
        "severity": 0, 
        "severity_value": 0.3432, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_spearman_per_cell\n  Best score: 0.6864%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score novel mean_spearman_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method novel performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: novel\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score novel mean_spearman_per_cell", 
        "value": 0.6897, 
        "severity": 0, 
        "severity_value": 0.34485, 
        "code": "best_score <= 2", 
        "message": "Method novel performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: novel\n  Metric id: mean_spearman_per_cell\n  Best score: 0.6897%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score simple_mlp mean_spearman_per_cell", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method simple_mlp performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: simple_mlp\n  Metric id: mean_spearman_per_cell\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score simple_mlp mean_spearman_per_cell", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method simple_mlp performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: simple_mlp\n  Metric id: mean_spearman_per_cell\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene mean_pearson_per_gene", 
        "value": 0.0021, 
        "severity": 0, 
        "severity_value": 0.00105, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_pearson_per_gene\n  Best score: 0.0021%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict mean_pearson_per_gene", 
        "value": 0.0015, 
        "severity": 0, 
        "severity_value": 0.00075, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_pearson_per_gene\n  Best score: 0.0015%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros mean_pearson_per_gene", 
        "value": 0.0021, 
        "severity": 0, 
        "severity_value": 0.00105, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_pearson_per_gene\n  Best score: 0.0021%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution mean_pearson_per_gene", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_pearson_per_gene\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution mean_pearson_per_gene", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_pearson_per_gene\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py mean_pearson_per_gene", 
        "value": 0.0399, 
        "severity": 0, 
        "severity_value": -0.0399, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0399%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py mean_pearson_per_gene", 
        "value": 0.5944, 
        "severity": 0, 
        "severity_value": 0.2972, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_pearson_per_gene\n  Best score: 0.5944%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r mean_pearson_per_gene", 
        "value": 0.0207, 
        "severity": 0, 
        "severity_value": -0.0207, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0207%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r mean_pearson_per_gene", 
        "value": 0.5336, 
        "severity": 0, 
        "severity_value": 0.2668, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_pearson_per_gene\n  Best score: 0.5336%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm mean_pearson_per_gene", 
        "value": 0.5291, 
        "severity": 0, 
        "severity_value": 0.26455, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_pearson_per_gene\n  Best score: 0.5291%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm mean_pearson_per_gene", 
        "value": 0.6415, 
        "severity": 0, 
        "severity_value": 0.32075, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_pearson_per_gene\n  Best score: 0.6415%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score novel mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method novel performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: novel\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score novel mean_pearson_per_gene", 
        "value": 0.4998, 
        "severity": 0, 
        "severity_value": 0.2499, 
        "code": "best_score <= 2", 
        "message": "Method novel performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: novel\n  Metric id: mean_pearson_per_gene\n  Best score: 0.4998%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score simple_mlp mean_pearson_per_gene", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method simple_mlp performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: simple_mlp\n  Metric id: mean_pearson_per_gene\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score simple_mlp mean_pearson_per_gene", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method simple_mlp performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: simple_mlp\n  Metric id: mean_pearson_per_gene\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene mean_spearman_per_gene", 
        "value": 0.0063, 
        "severity": 0, 
        "severity_value": 0.00315, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_spearman_per_gene\n  Best score: 0.0063%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict mean_spearman_per_gene", 
        "value": 0.0019, 
        "severity": 0, 
        "severity_value": 0.00095, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_spearman_per_gene\n  Best score: 0.0019%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros mean_spearman_per_gene", 
        "value": 0.0063, 
        "severity": 0, 
        "severity_value": 0.00315, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_spearman_per_gene\n  Best score: 0.0063%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution mean_spearman_per_gene", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_spearman_per_gene\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution mean_spearman_per_gene", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_spearman_per_gene\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py mean_spearman_per_gene", 
        "value": 0.0412, 
        "severity": 0, 
        "severity_value": -0.0412, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0412%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py mean_spearman_per_gene", 
        "value": 0.4887, 
        "severity": 0, 
        "severity_value": 0.24435, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_spearman_per_gene\n  Best score: 0.4887%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r mean_spearman_per_gene", 
        "value": 0.021, 
        "severity": 0, 
        "severity_value": -0.021, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.021%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r mean_spearman_per_gene", 
        "value": 0.4277, 
        "severity": 0, 
        "severity_value": 0.21385, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_spearman_per_gene\n  Best score: 0.4277%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm mean_spearman_per_gene", 
        "value": 0.4338, 
        "severity": 0, 
        "severity_value": 0.2169, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_spearman_per_gene\n  Best score: 0.4338%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm mean_spearman_per_gene", 
        "value": 0.5036, 
        "severity": 0, 
        "severity_value": 0.2518, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_spearman_per_gene\n  Best score: 0.5036%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score novel mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method novel performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: novel\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score novel mean_spearman_per_gene", 
        "value": 0.3719, 
        "severity": 0, 
        "severity_value": 0.18595, 
        "code": "best_score <= 2", 
        "message": "Method novel performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: novel\n  Metric id: mean_spearman_per_gene\n  Best score: 0.3719%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score simple_mlp mean_spearman_per_gene", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method simple_mlp performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: simple_mlp\n  Metric id: mean_spearman_per_gene\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score simple_mlp mean_spearman_per_gene", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method simple_mlp performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: simple_mlp\n  Metric id: mean_spearman_per_gene\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene overall_pearson", 
        "value": 0.1192, 
        "severity": 0, 
        "severity_value": -0.1192, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: overall_pearson\n  Worst score: 0.1192%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene overall_pearson", 
        "value": 0.4135, 
        "severity": 0, 
        "severity_value": 0.20675, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: overall_pearson\n  Best score: 0.4135%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict overall_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: overall_pearson\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict overall_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: overall_pearson\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros overall_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: overall_pearson\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros overall_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: overall_pearson\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution overall_pearson", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: overall_pearson\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution overall_pearson", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: overall_pearson\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py overall_pearson", 
        "value": 0.1393, 
        "severity": 0, 
        "severity_value": -0.1393, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: overall_pearson\n  Worst score: 0.1393%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py overall_pearson", 
        "value": 0.7075, 
        "severity": 0, 
        "severity_value": 0.35375, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: overall_pearson\n  Best score: 0.7075%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r overall_pearson", 
        "value": 0.0858, 
        "severity": 0, 
        "severity_value": -0.0858, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: overall_pearson\n  Worst score: 0.0858%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r overall_pearson", 
        "value": 0.6596, 
        "severity": 0, 
        "severity_value": 0.3298, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: overall_pearson\n  Best score: 0.6596%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm overall_pearson", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: overall_pearson\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm overall_pearson", 
        "value": 0.6593, 
        "severity": 0, 
        "severity_value": 0.32965, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: overall_pearson\n  Best score: 0.6593%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm overall_pearson", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: overall_pearson\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm overall_pearson", 
        "value": 0.7476, 
        "severity": 0, 
        "severity_value": 0.3738, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: overall_pearson\n  Best score: 0.7476%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score novel overall_pearson", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method novel performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: novel\n  Metric id: overall_pearson\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score novel overall_pearson", 
        "value": 0.6401, 
        "severity": 0, 
        "severity_value": 0.32005, 
        "code": "best_score <= 2", 
        "message": "Method novel performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: novel\n  Metric id: overall_pearson\n  Best score: 0.6401%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score simple_mlp overall_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method simple_mlp performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: simple_mlp\n  Metric id: overall_pearson\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score simple_mlp overall_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method simple_mlp performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: simple_mlp\n  Metric id: overall_pearson\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene overall_spearman", 
        "value": 0.0731, 
        "severity": 0, 
        "severity_value": -0.0731, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: overall_spearman\n  Worst score: 0.0731%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene overall_spearman", 
        "value": 0.1815, 
        "severity": 0, 
        "severity_value": 0.09075, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: overall_spearman\n  Best score: 0.1815%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict overall_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: overall_spearman\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict overall_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: overall_spearman\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros overall_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: overall_spearman\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros overall_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: overall_spearman\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution overall_spearman", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: overall_spearman\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution overall_spearman", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: overall_spearman\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py overall_spearman", 
        "value": 0.1098, 
        "severity": 0, 
        "severity_value": -0.1098, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: overall_spearman\n  Worst score: 0.1098%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py overall_spearman", 
        "value": 0.6025, 
        "severity": 0, 
        "severity_value": 0.30125, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: overall_spearman\n  Best score: 0.6025%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r overall_spearman", 
        "value": 0.1057, 
        "severity": 0, 
        "severity_value": -0.1057, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: overall_spearman\n  Worst score: 0.1057%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r overall_spearman", 
        "value": 0.5548, 
        "severity": 0, 
        "severity_value": 0.2774, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: overall_spearman\n  Best score: 0.5548%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm overall_spearman", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: overall_spearman\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm overall_spearman", 
        "value": 0.5312, 
        "severity": 0, 
        "severity_value": 0.2656, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: overall_spearman\n  Best score: 0.5312%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm overall_spearman", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: overall_spearman\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm overall_spearman", 
        "value": 0.6158, 
        "severity": 0, 
        "severity_value": 0.3079, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: overall_spearman\n  Best score: 0.6158%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score novel overall_spearman", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method novel performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: novel\n  Metric id: overall_spearman\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score novel overall_spearman", 
        "value": 0.5182, 
        "severity": 0, 
        "severity_value": 0.2591, 
        "code": "best_score <= 2", 
        "message": "Method novel performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: novel\n  Metric id: overall_spearman\n  Best score: 0.5182%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score simple_mlp overall_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method simple_mlp performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: simple_mlp\n  Metric id: overall_spearman\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score simple_mlp overall_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method simple_mlp performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: simple_mlp\n  Metric id: overall_spearman\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene rmse", 
        "value": 0.1982, 
        "severity": 0, 
        "severity_value": -0.1982, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: rmse\n  Worst score: 0.1982%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene rmse", 
        "value": 0.5005, 
        "severity": 0, 
        "severity_value": 0.25025, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: rmse\n  Best score: 0.5005%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict rmse", 
        "value": 0.3387, 
        "severity": 0, 
        "severity_value": 0.16935, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: rmse\n  Best score: 0.3387%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros rmse", 
        "value": 0.3057, 
        "severity": 0, 
        "severity_value": 0.15285, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: rmse\n  Best score: 0.3057%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution rmse", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: rmse\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution rmse", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: rmse\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py rmse", 
        "value": 0.2749, 
        "severity": 0, 
        "severity_value": -0.2749, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: rmse\n  Worst score: 0.2749%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py rmse", 
        "value": 0.5469, 
        "severity": 0, 
        "severity_value": 0.27345, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: rmse\n  Best score: 0.5469%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r rmse", 
        "value": 0.2035, 
        "severity": 0, 
        "severity_value": -0.2035, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: rmse\n  Worst score: 0.2035%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r rmse", 
        "value": 0.5415, 
        "severity": 0, 
        "severity_value": 0.27075, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: rmse\n  Best score: 0.5415%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm rmse", 
        "value": 0.4538, 
        "severity": 0, 
        "severity_value": 0.2269, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: rmse\n  Best score: 0.4538%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm rmse", 
        "value": 0.5611, 
        "severity": 0, 
        "severity_value": 0.28055, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: rmse\n  Best score: 0.5611%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score novel rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method novel performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: novel\n  Metric id: rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score novel rmse", 
        "value": 0.3883, 
        "severity": 0, 
        "severity_value": 0.19415, 
        "code": "best_score <= 2", 
        "message": "Method novel performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: novel\n  Metric id: rmse\n  Best score: 0.3883%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score simple_mlp rmse", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method simple_mlp performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: simple_mlp\n  Metric id: rmse\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score simple_mlp rmse", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method simple_mlp performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: simple_mlp\n  Metric id: rmse\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene mae", 
        "value": 0.023, 
        "severity": 0, 
        "severity_value": -0.023, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mae\n  Worst score: 0.023%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene mae", 
        "value": 0.4307, 
        "severity": 0, 
        "severity_value": 0.21535, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mae\n  Best score: 0.4307%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict mae", 
        "value": 0.2771, 
        "severity": 0, 
        "severity_value": 0.13855, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mae\n  Best score: 0.2771%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros mae", 
        "value": 0.4613, 
        "severity": 0, 
        "severity_value": 0.23065, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mae\n  Best score: 0.4613%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution mae", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mae\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution mae", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mae\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py mae", 
        "value": 0.0606, 
        "severity": 0, 
        "severity_value": -0.0606, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mae\n  Worst score: 0.0606%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py mae", 
        "value": 0.5267, 
        "severity": 0, 
        "severity_value": 0.26335, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mae\n  Best score: 0.5267%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r mae", 
        "value": 0.0329, 
        "severity": 0, 
        "severity_value": -0.0329, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mae\n  Worst score: 0.0329%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r mae", 
        "value": 0.5129, 
        "severity": 0, 
        "severity_value": 0.25645, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mae\n  Best score: 0.5129%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm mae", 
        "value": 0.4734, 
        "severity": 0, 
        "severity_value": 0.2367, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mae\n  Best score: 0.4734%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm mae", 
        "value": 0.5128, 
        "severity": 0, 
        "severity_value": 0.2564, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mae\n  Best score: 0.5128%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score novel mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method novel performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: novel\n  Metric id: mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score novel mae", 
        "value": 0.414, 
        "severity": 0, 
        "severity_value": 0.207, 
        "code": "best_score <= 2", 
        "message": "Method novel performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: novel\n  Metric id: mae\n  Best score: 0.414%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score simple_mlp mae", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method simple_mlp performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: simple_mlp\n  Metric id: mae\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score simple_mlp mae", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method simple_mlp performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: simple_mlp\n  Metric id: mae\n  Best score: 0%\n"
    }
]