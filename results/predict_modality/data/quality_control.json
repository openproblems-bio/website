[
    {
        "task_id": "task_predict_modality", 
        "category": "Task info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_id' should be defined\n  Task id: task_predict_modality\n  Field: task_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Task info", 
        "name": "Pct 'task_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_name' should be defined\n  Task id: task_predict_modality\n  Field: task_name\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Task info", 
        "name": "Pct 'task_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_summary' should be defined\n  Task id: task_predict_modality\n  Field: task_summary\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Task info", 
        "name": "Pct 'task_description' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_description' should be defined\n  Task id: task_predict_modality\n  Field: task_description\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'task_id' should be defined\n  Task id: task_predict_modality\n  Field: task_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'commit_sha' should be defined\n  Task id: task_predict_modality\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'method_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_id' should be defined\n  Task id: task_predict_modality\n  Field: method_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'method_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_name' should be defined\n  Task id: task_predict_modality\n  Field: method_name\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'method_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_summary' should be defined\n  Task id: task_predict_modality\n  Field: method_summary\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 0.5555555555555556, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'paper_reference' should be defined\n  Task id: task_predict_modality\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Method info", 
        "name": "Pct 'is_baseline' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'is_baseline' should be defined\n  Task id: task_predict_modality\n  Field: is_baseline\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'task_id' should be defined\n  Task id: task_predict_modality\n  Field: task_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'commit_sha' should be defined\n  Task id: task_predict_modality\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'metric_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_id' should be defined\n  Task id: task_predict_modality\n  Field: metric_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'metric_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_name' should be defined\n  Task id: task_predict_modality\n  Field: metric_name\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'metric_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_summary' should be defined\n  Task id: task_predict_modality\n  Field: metric_summary\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'paper_reference' should be defined\n  Task id: task_predict_modality\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Metric info", 
        "name": "Pct 'maximize' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'maximize' should be defined\n  Task id: task_predict_modality\n  Field: maximize\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'task_id' missing", 
        "value": 1.0, 
        "severity": 2, 
        "severity_value": 3.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'task_id' should be defined\n  Task id: task_predict_modality\n  Field: task_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_id' should be defined\n  Task id: task_predict_modality\n  Field: dataset_id\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_name' should be defined\n  Task id: task_predict_modality\n  Field: dataset_name\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_summary' should be defined\n  Task id: task_predict_modality\n  Field: dataset_summary\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'data_reference' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_reference' should be defined\n  Task id: task_predict_modality\n  Field: data_reference\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Dataset info", 
        "name": "Pct 'data_url' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_url' should be defined\n  Task id: task_predict_modality\n  Field: data_url\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw data", 
        "name": "Number of results", 
        "value": 72, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "len(results) == len(method_info) * len(metric_info) * len(dataset_info)", 
        "message": "Number of results should be equal to #methods × #metrics × #datasets.\n  Task id: task_predict_modality\n  Number of results: 72\n  Number of methods: 9\n  Number of metrics: 8\n  Number of datasets: 8\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'mean_pearson_per_cell' %missing", 
        "value": 0.05555555555555558, 
        "severity": 0, 
        "severity_value": 0.5555555555555558, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: mean_pearson_per_cell\n  Percentage missing: 6%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'mean_spearman_per_cell' %missing", 
        "value": 0.05555555555555558, 
        "severity": 0, 
        "severity_value": 0.5555555555555558, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: mean_spearman_per_cell\n  Percentage missing: 6%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'mean_pearson_per_gene' %missing", 
        "value": 0.05555555555555558, 
        "severity": 0, 
        "severity_value": 0.5555555555555558, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: mean_pearson_per_gene\n  Percentage missing: 6%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'mean_spearman_per_gene' %missing", 
        "value": 0.05555555555555558, 
        "severity": 0, 
        "severity_value": 0.5555555555555558, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: mean_spearman_per_gene\n  Percentage missing: 6%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'overall_pearson' %missing", 
        "value": 0.16666666666666663, 
        "severity": 1, 
        "severity_value": 1.6666666666666663, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: overall_pearson\n  Percentage missing: 17%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'overall_spearman' %missing", 
        "value": 0.16666666666666663, 
        "severity": 1, 
        "severity_value": 1.6666666666666663, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: overall_spearman\n  Percentage missing: 17%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'rmse' %missing", 
        "value": 0.05555555555555558, 
        "severity": 0, 
        "severity_value": 0.5555555555555558, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: rmse\n  Percentage missing: 6%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Metric 'mae' %missing", 
        "value": 0.05555555555555558, 
        "severity": 0, 
        "severity_value": 0.5555555555555558, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  Metric id: mae\n  Percentage missing: 6%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'mean_per_gene' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: mean_per_gene\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'random_predict' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: random_predict\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'zeros' %missing", 
        "value": 0.25, 
        "severity": 2, 
        "severity_value": 2.5, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: zeros\n  Percentage missing: 25%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'solution' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: solution\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'knnr_py' %missing", 
        "value": 0.125, 
        "severity": 1, 
        "severity_value": 1.25, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: knnr_py\n  Percentage missing: 12%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'knnr_r' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: knnr_r\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'lm' %missing", 
        "value": 0.125, 
        "severity": 1, 
        "severity_value": 1.25, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: lm\n  Percentage missing: 12%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'lmds_irlba_rf' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: lmds_irlba_rf\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Method 'guanlab_dengkw_pm' %missing", 
        "value": 0.25, 
        "severity": 2, 
        "severity_value": 2.5, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  method id: guanlab_dengkw_pm\n  Percentage missing: 25%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2021/bmmc_cite/normal' %missing", 
        "value": 0.02777777777777779, 
        "severity": 0, 
        "severity_value": 0.2777777777777779, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2021/bmmc_cite/normal\n  Percentage missing: 3%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2021/bmmc_multiome/normal' %missing", 
        "value": 0.02777777777777779, 
        "severity": 0, 
        "severity_value": 0.2777777777777779, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2021/bmmc_multiome/normal\n  Percentage missing: 3%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2022/pbmc_multiome/swap' %missing", 
        "value": 0.36111111111111116, 
        "severity": 3, 
        "severity_value": 3.6111111111111116, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2022/pbmc_multiome/swap\n  Percentage missing: 36%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2021/bmmc_multiome/swap' %missing", 
        "value": 0.02777777777777779, 
        "severity": 0, 
        "severity_value": 0.2777777777777779, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2021/bmmc_multiome/swap\n  Percentage missing: 3%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2022/pbmc_multiome/normal' %missing", 
        "value": 0.13888888888888884, 
        "severity": 1, 
        "severity_value": 1.3888888888888884, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2022/pbmc_multiome/normal\n  Percentage missing: 14%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2022/pbmc_cite/normal' %missing", 
        "value": 0.02777777777777779, 
        "severity": 0, 
        "severity_value": 0.2777777777777779, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2022/pbmc_cite/normal\n  Percentage missing: 3%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2022/pbmc_cite/swap' %missing", 
        "value": 0.02777777777777779, 
        "severity": 0, 
        "severity_value": 0.2777777777777779, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2022/pbmc_cite/swap\n  Percentage missing: 3%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_neurips2021/bmmc_cite/swap' %missing", 
        "value": 0.02777777777777779, 
        "severity": 0, 
        "severity_value": 0.2777777777777779, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: task_predict_modality\n  dataset id: openproblems_neurips2021/bmmc_cite/swap\n  Percentage missing: 3%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene mean_pearson_per_cell", 
        "value": 0.1425, 
        "severity": 0, 
        "severity_value": -0.1425, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.1425%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene mean_pearson_per_cell", 
        "value": 0.849, 
        "severity": 0, 
        "severity_value": 0.4245, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_pearson_per_cell\n  Best score: 0.849%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict mean_pearson_per_cell", 
        "value": 0.0202, 
        "severity": 0, 
        "severity_value": -0.0202, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.0202%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict mean_pearson_per_cell", 
        "value": 0.7556, 
        "severity": 0, 
        "severity_value": 0.3778, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_pearson_per_cell\n  Best score: 0.7556%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_pearson_per_cell", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_pearson_per_cell\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros mean_pearson_per_cell", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_pearson_per_cell\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution mean_pearson_per_cell", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_pearson_per_cell\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution mean_pearson_per_cell", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_pearson_per_cell\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py mean_pearson_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py mean_pearson_per_cell", 
        "value": 0.8764, 
        "severity": 0, 
        "severity_value": 0.4382, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_pearson_per_cell\n  Best score: 0.8764%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r mean_pearson_per_cell", 
        "value": 0.1076, 
        "severity": 0, 
        "severity_value": -0.1076, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.1076%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r mean_pearson_per_cell", 
        "value": 0.8737, 
        "severity": 0, 
        "severity_value": 0.43685, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_pearson_per_cell\n  Best score: 0.8737%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm mean_pearson_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm mean_pearson_per_cell", 
        "value": 0.7078, 
        "severity": 0, 
        "severity_value": 0.3539, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_pearson_per_cell\n  Best score: 0.7078%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lmds_irlba_rf mean_pearson_per_cell", 
        "value": 0.0729, 
        "severity": 0, 
        "severity_value": -0.0729, 
        "code": "worst_score >= -1", 
        "message": "Method lmds_irlba_rf performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.0729%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lmds_irlba_rf mean_pearson_per_cell", 
        "value": 0.7061, 
        "severity": 0, 
        "severity_value": 0.35305, 
        "code": "best_score <= 2", 
        "message": "Method lmds_irlba_rf performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mean_pearson_per_cell\n  Best score: 0.7061%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm mean_pearson_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_pearson_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm mean_pearson_per_cell", 
        "value": 0.8843, 
        "severity": 0, 
        "severity_value": 0.44215, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_pearson_per_cell\n  Best score: 0.8843%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene mean_spearman_per_cell", 
        "value": 0.1574, 
        "severity": 0, 
        "severity_value": -0.1574, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.1574%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene mean_spearman_per_cell", 
        "value": 0.5996, 
        "severity": 0, 
        "severity_value": 0.2998, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_spearman_per_cell\n  Best score: 0.5996%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict mean_spearman_per_cell", 
        "value": 0.0723, 
        "severity": 0, 
        "severity_value": -0.0723, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.0723%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict mean_spearman_per_cell", 
        "value": 0.5185, 
        "severity": 0, 
        "severity_value": 0.25925, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_spearman_per_cell\n  Best score: 0.5185%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_spearman_per_cell", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_spearman_per_cell\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros mean_spearman_per_cell", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_spearman_per_cell\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution mean_spearman_per_cell", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_spearman_per_cell\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution mean_spearman_per_cell", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_spearman_per_cell\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py mean_spearman_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py mean_spearman_per_cell", 
        "value": 0.6911, 
        "severity": 0, 
        "severity_value": 0.34555, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_spearman_per_cell\n  Best score: 0.6911%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r mean_spearman_per_cell", 
        "value": 0.1941, 
        "severity": 0, 
        "severity_value": -0.1941, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.1941%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r mean_spearman_per_cell", 
        "value": 0.6708, 
        "severity": 0, 
        "severity_value": 0.3354, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_spearman_per_cell\n  Best score: 0.6708%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm mean_spearman_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm mean_spearman_per_cell", 
        "value": 0.6098, 
        "severity": 0, 
        "severity_value": 0.3049, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_spearman_per_cell\n  Best score: 0.6098%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lmds_irlba_rf mean_spearman_per_cell", 
        "value": 0.0228, 
        "severity": 0, 
        "severity_value": -0.0228, 
        "code": "worst_score >= -1", 
        "message": "Method lmds_irlba_rf performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.0228%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lmds_irlba_rf mean_spearman_per_cell", 
        "value": 0.589, 
        "severity": 0, 
        "severity_value": 0.2945, 
        "code": "best_score <= 2", 
        "message": "Method lmds_irlba_rf performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mean_spearman_per_cell\n  Best score: 0.589%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm mean_spearman_per_cell", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_spearman_per_cell\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm mean_spearman_per_cell", 
        "value": 0.686, 
        "severity": 0, 
        "severity_value": 0.343, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_spearman_per_cell\n  Best score: 0.686%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene mean_pearson_per_gene", 
        "value": 0.0157, 
        "severity": 0, 
        "severity_value": 0.00785, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_pearson_per_gene\n  Best score: 0.0157%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict mean_pearson_per_gene", 
        "value": 0.0034, 
        "severity": 0, 
        "severity_value": 0.0017, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_pearson_per_gene\n  Best score: 0.0034%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros mean_pearson_per_gene", 
        "value": 0.0157, 
        "severity": 0, 
        "severity_value": 0.00785, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_pearson_per_gene\n  Best score: 0.0157%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution mean_pearson_per_gene", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_pearson_per_gene\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution mean_pearson_per_gene", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_pearson_per_gene\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py mean_pearson_per_gene", 
        "value": 0.601, 
        "severity": 0, 
        "severity_value": 0.3005, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_pearson_per_gene\n  Best score: 0.601%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r mean_pearson_per_gene", 
        "value": 0.0207, 
        "severity": 0, 
        "severity_value": -0.0207, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0207%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r mean_pearson_per_gene", 
        "value": 0.5439, 
        "severity": 0, 
        "severity_value": 0.27195, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_pearson_per_gene\n  Best score: 0.5439%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm mean_pearson_per_gene", 
        "value": 0.5264, 
        "severity": 0, 
        "severity_value": 0.2632, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_pearson_per_gene\n  Best score: 0.5264%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lmds_irlba_rf mean_pearson_per_gene", 
        "value": 0.0619, 
        "severity": 0, 
        "severity_value": -0.0619, 
        "code": "worst_score >= -1", 
        "message": "Method lmds_irlba_rf performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0619%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lmds_irlba_rf mean_pearson_per_gene", 
        "value": 0.5398, 
        "severity": 0, 
        "severity_value": 0.2699, 
        "code": "best_score <= 2", 
        "message": "Method lmds_irlba_rf performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mean_pearson_per_gene\n  Best score: 0.5398%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm mean_pearson_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_pearson_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm mean_pearson_per_gene", 
        "value": 0.6474, 
        "severity": 0, 
        "severity_value": 0.3237, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_pearson_per_gene\n  Best score: 0.6474%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene mean_spearman_per_gene", 
        "value": 0.0193, 
        "severity": 0, 
        "severity_value": 0.00965, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mean_spearman_per_gene\n  Best score: 0.0193%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict mean_spearman_per_gene", 
        "value": 0.0009, 
        "severity": 0, 
        "severity_value": 0.00045, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mean_spearman_per_gene\n  Best score: 0.0009%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros mean_spearman_per_gene", 
        "value": 0.0193, 
        "severity": 0, 
        "severity_value": 0.00965, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mean_spearman_per_gene\n  Best score: 0.0193%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution mean_spearman_per_gene", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_spearman_per_gene\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution mean_spearman_per_gene", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mean_spearman_per_gene\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py mean_spearman_per_gene", 
        "value": 0.499, 
        "severity": 0, 
        "severity_value": 0.2495, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mean_spearman_per_gene\n  Best score: 0.499%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r mean_spearman_per_gene", 
        "value": 0.0208, 
        "severity": 0, 
        "severity_value": -0.0208, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0208%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r mean_spearman_per_gene", 
        "value": 0.4419, 
        "severity": 0, 
        "severity_value": 0.22095, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mean_spearman_per_gene\n  Best score: 0.4419%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm mean_spearman_per_gene", 
        "value": 0.4398, 
        "severity": 0, 
        "severity_value": 0.2199, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mean_spearman_per_gene\n  Best score: 0.4398%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lmds_irlba_rf mean_spearman_per_gene", 
        "value": 0.0631, 
        "severity": 0, 
        "severity_value": -0.0631, 
        "code": "worst_score >= -1", 
        "message": "Method lmds_irlba_rf performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0631%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lmds_irlba_rf mean_spearman_per_gene", 
        "value": 0.4441, 
        "severity": 0, 
        "severity_value": 0.22205, 
        "code": "best_score <= 2", 
        "message": "Method lmds_irlba_rf performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mean_spearman_per_gene\n  Best score: 0.4441%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm mean_spearman_per_gene", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_spearman_per_gene\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm mean_spearman_per_gene", 
        "value": 0.5135, 
        "severity": 0, 
        "severity_value": 0.25675, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mean_spearman_per_gene\n  Best score: 0.5135%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene overall_pearson", 
        "value": 0.1203, 
        "severity": 0, 
        "severity_value": -0.1203, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: overall_pearson\n  Worst score: 0.1203%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene overall_pearson", 
        "value": 0.4197, 
        "severity": 0, 
        "severity_value": 0.20985, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: overall_pearson\n  Best score: 0.4197%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict overall_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: overall_pearson\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict overall_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: overall_pearson\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros overall_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: overall_pearson\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros overall_pearson", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: overall_pearson\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution overall_pearson", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: overall_pearson\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution overall_pearson", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: overall_pearson\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py overall_pearson", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: overall_pearson\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py overall_pearson", 
        "value": 0.7082, 
        "severity": 0, 
        "severity_value": 0.3541, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: overall_pearson\n  Best score: 0.7082%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r overall_pearson", 
        "value": 0.0864, 
        "severity": 0, 
        "severity_value": -0.0864, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: overall_pearson\n  Worst score: 0.0864%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r overall_pearson", 
        "value": 0.6654, 
        "severity": 0, 
        "severity_value": 0.3327, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: overall_pearson\n  Best score: 0.6654%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm overall_pearson", 
        "value": -0.6151, 
        "severity": 0, 
        "severity_value": 0.6151, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: overall_pearson\n  Worst score: -0.6151%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm overall_pearson", 
        "value": 0.6541, 
        "severity": 0, 
        "severity_value": 0.32705, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: overall_pearson\n  Best score: 0.6541%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lmds_irlba_rf overall_pearson", 
        "value": -2.4102, 
        "severity": 2, 
        "severity_value": 2.4102, 
        "code": "worst_score >= -1", 
        "message": "Method lmds_irlba_rf performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: overall_pearson\n  Worst score: -2.4102%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lmds_irlba_rf overall_pearson", 
        "value": 0.6371, 
        "severity": 0, 
        "severity_value": 0.31855, 
        "code": "best_score <= 2", 
        "message": "Method lmds_irlba_rf performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: overall_pearson\n  Best score: 0.6371%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm overall_pearson", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: overall_pearson\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm overall_pearson", 
        "value": 0.7483, 
        "severity": 0, 
        "severity_value": 0.37415, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: overall_pearson\n  Best score: 0.7483%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene overall_spearman", 
        "value": 0.0908, 
        "severity": 0, 
        "severity_value": -0.0908, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: overall_spearman\n  Worst score: 0.0908%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene overall_spearman", 
        "value": 0.1824, 
        "severity": 0, 
        "severity_value": 0.0912, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: overall_spearman\n  Best score: 0.1824%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict overall_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: overall_spearman\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict overall_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: overall_spearman\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros overall_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: overall_spearman\n  Worst score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros overall_spearman", 
        "value": 0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: overall_spearman\n  Best score: 0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution overall_spearman", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: overall_spearman\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution overall_spearman", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: overall_spearman\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py overall_spearman", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: overall_spearman\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py overall_spearman", 
        "value": 0.61, 
        "severity": 0, 
        "severity_value": 0.305, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: overall_spearman\n  Best score: 0.61%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r overall_spearman", 
        "value": 0.1103, 
        "severity": 0, 
        "severity_value": -0.1103, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: overall_spearman\n  Worst score: 0.1103%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r overall_spearman", 
        "value": 0.5663, 
        "severity": 0, 
        "severity_value": 0.28315, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: overall_spearman\n  Best score: 0.5663%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm overall_spearman", 
        "value": -0.2449, 
        "severity": 0, 
        "severity_value": 0.2449, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: overall_spearman\n  Worst score: -0.2449%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm overall_spearman", 
        "value": 0.5364, 
        "severity": 0, 
        "severity_value": 0.2682, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: overall_spearman\n  Best score: 0.5364%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lmds_irlba_rf overall_spearman", 
        "value": -0.9923, 
        "severity": 0, 
        "severity_value": 0.9923, 
        "code": "worst_score >= -1", 
        "message": "Method lmds_irlba_rf performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: overall_spearman\n  Worst score: -0.9923%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lmds_irlba_rf overall_spearman", 
        "value": 0.5143, 
        "severity": 0, 
        "severity_value": 0.25715, 
        "code": "best_score <= 2", 
        "message": "Method lmds_irlba_rf performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: overall_spearman\n  Best score: 0.5143%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm overall_spearman", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: overall_spearman\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm overall_spearman", 
        "value": 0.6234, 
        "severity": 0, 
        "severity_value": 0.3117, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: overall_spearman\n  Best score: 0.6234%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene rmse", 
        "value": 0.2007, 
        "severity": 0, 
        "severity_value": -0.2007, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: rmse\n  Worst score: 0.2007%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene rmse", 
        "value": 0.5005, 
        "severity": 0, 
        "severity_value": 0.25025, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: rmse\n  Best score: 0.5005%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict rmse", 
        "value": 0.3408, 
        "severity": 0, 
        "severity_value": 0.1704, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: rmse\n  Best score: 0.3408%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros rmse", 
        "value": 0.3061, 
        "severity": 0, 
        "severity_value": 0.15305, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: rmse\n  Best score: 0.3061%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution rmse", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: rmse\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution rmse", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: rmse\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py rmse", 
        "value": 0.5465, 
        "severity": 0, 
        "severity_value": 0.27325, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: rmse\n  Best score: 0.5465%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r rmse", 
        "value": 0.2044, 
        "severity": 0, 
        "severity_value": -0.2044, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: rmse\n  Worst score: 0.2044%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r rmse", 
        "value": 0.5417, 
        "severity": 0, 
        "severity_value": 0.27085, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: rmse\n  Best score: 0.5417%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm rmse", 
        "value": 0.4537, 
        "severity": 0, 
        "severity_value": 0.22685, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: rmse\n  Best score: 0.4537%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lmds_irlba_rf rmse", 
        "value": 0.0089, 
        "severity": 0, 
        "severity_value": -0.0089, 
        "code": "worst_score >= -1", 
        "message": "Method lmds_irlba_rf performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: rmse\n  Worst score: 0.0089%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lmds_irlba_rf rmse", 
        "value": 0.3061, 
        "severity": 0, 
        "severity_value": 0.15305, 
        "code": "best_score <= 2", 
        "message": "Method lmds_irlba_rf performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: rmse\n  Best score: 0.3061%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm rmse", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: rmse\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm rmse", 
        "value": 0.561, 
        "severity": 0, 
        "severity_value": 0.2805, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: rmse\n  Best score: 0.561%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score mean_per_gene mae", 
        "value": 0.0259, 
        "severity": 0, 
        "severity_value": -0.0259, 
        "code": "worst_score >= -1", 
        "message": "Method mean_per_gene performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mae\n  Worst score: 0.0259%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score mean_per_gene mae", 
        "value": 0.4307, 
        "severity": 0, 
        "severity_value": 0.21535, 
        "code": "best_score <= 2", 
        "message": "Method mean_per_gene performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: mean_per_gene\n  Metric id: mae\n  Best score: 0.4307%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score random_predict mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_predict performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score random_predict mae", 
        "value": 0.2591, 
        "severity": 0, 
        "severity_value": 0.12955, 
        "code": "best_score <= 2", 
        "message": "Method random_predict performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: random_predict\n  Metric id: mae\n  Best score: 0.2591%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score zeros mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method zeros performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score zeros mae", 
        "value": 0.46, 
        "severity": 0, 
        "severity_value": 0.23, 
        "code": "best_score <= 2", 
        "message": "Method zeros performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: zeros\n  Metric id: mae\n  Best score: 0.46%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score solution mae", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method solution performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mae\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score solution mae", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method solution performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: solution\n  Metric id: mae\n  Best score: 1%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_py mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_py performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_py mae", 
        "value": 0.5267, 
        "severity": 0, 
        "severity_value": 0.26335, 
        "code": "best_score <= 2", 
        "message": "Method knnr_py performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_py\n  Metric id: mae\n  Best score: 0.5267%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score knnr_r mae", 
        "value": 0.0167, 
        "severity": 0, 
        "severity_value": -0.0167, 
        "code": "worst_score >= -1", 
        "message": "Method knnr_r performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mae\n  Worst score: 0.0167%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score knnr_r mae", 
        "value": 0.5132, 
        "severity": 0, 
        "severity_value": 0.2566, 
        "code": "best_score <= 2", 
        "message": "Method knnr_r performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: knnr_r\n  Metric id: mae\n  Best score: 0.5132%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lm mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method lm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lm mae", 
        "value": 0.4771, 
        "severity": 0, 
        "severity_value": 0.23855, 
        "code": "best_score <= 2", 
        "message": "Method lm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lm\n  Metric id: mae\n  Best score: 0.4771%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score lmds_irlba_rf mae", 
        "value": -0.0588, 
        "severity": 0, 
        "severity_value": 0.0588, 
        "code": "worst_score >= -1", 
        "message": "Method lmds_irlba_rf performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mae\n  Worst score: -0.0588%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score lmds_irlba_rf mae", 
        "value": 0.278, 
        "severity": 0, 
        "severity_value": 0.139, 
        "code": "best_score <= 2", 
        "message": "Method lmds_irlba_rf performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: lmds_irlba_rf\n  Metric id: mae\n  Best score: 0.278%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Worst score guanlab_dengkw_pm mae", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method guanlab_dengkw_pm performs much worse than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mae\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "task_predict_modality", 
        "category": "Scaling", 
        "name": "Best score guanlab_dengkw_pm mae", 
        "value": 0.5124, 
        "severity": 0, 
        "severity_value": 0.2562, 
        "code": "best_score <= 2", 
        "message": "Method guanlab_dengkw_pm performs a lot better than baselines.\n  Task id: task_predict_modality\n  Method id: guanlab_dengkw_pm\n  Metric id: mae\n  Best score: 0.5124%\n"
    }
]