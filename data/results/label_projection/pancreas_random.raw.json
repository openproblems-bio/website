{
    "knn_classifier_log_cpm": {
        "submit": "2022-11-14 01:12:06.486", 
        "duration": "7m 20s", 
        "realtime": "1m 20s", 
        "%cpu": "297.4%", 
        "peak_rss": "2.2 GB", 
        "peak_vmem": "7.5 GB", 
        "rchar": "1.3 GB", 
        "wchar": "1.7 GB", 
        "metrics": {
            "f1": 0.926027368194697, 
            "accuracy": 0.927237354085603, 
            "f1_macro": 0.7640168314059024
        }, 
        "code_version": "1.1.3", 
        "metrics_raw": {
            "f1": 0.9415925828915669, 
            "accuracy": 0.9425675675675675, 
            "f1_macro": 0.7811660574162138
        }
    }, 
    "true_labels": {
        "submit": "2022-11-14 01:12:06.775", 
        "duration": "7m 50s", 
        "realtime": "25.7s", 
        "%cpu": "62.8%", 
        "peak_rss": "246 MB", 
        "peak_vmem": "5 GB", 
        "rchar": "1.3 GB", 
        "wchar": "1.2 GB", 
        "metrics": {
            "f1_macro": 1.0, 
            "accuracy": 1.0, 
            "f1": 1.0
        }, 
        "code_version": "0.6.0", 
        "metrics_raw": {
            "f1_macro": 1.0, 
            "accuracy": 1.0, 
            "f1": 1.0
        }
    }, 
    "logistic_regression_log_cpm": {
        "submit": "2022-11-14 01:12:06.400", 
        "duration": "8m 10s", 
        "realtime": "1m 22s", 
        "%cpu": "488.8%", 
        "peak_rss": "2.2 GB", 
        "peak_vmem": "7.5 GB", 
        "rchar": "1.3 GB", 
        "wchar": "1.7 GB", 
        "metrics": {
            "f1": 0.980068853221081, 
            "accuracy": 0.9801556420233464, 
            "f1_macro": 0.8845217480694209
        }, 
        "code_version": "1.1.3", 
        "metrics_raw": {
            "f1": 0.984262736434338, 
            "accuracy": 0.9843366093366094, 
            "f1_macro": 0.8929137137059172
        }
    }, 
    "mlp_log_cpm": {
        "submit": "2022-11-14 01:12:06.537", 
        "duration": "8m 19s", 
        "realtime": "1m 43s", 
        "%cpu": "800.4%", 
        "peak_rss": "2.2 GB", 
        "peak_vmem": "7.5 GB", 
        "rchar": "1.3 GB", 
        "wchar": "1.7 GB", 
        "metrics": {
            "f1": 0.9851789496236378, 
            "f1_macro": 0.9015956901031029, 
            "accuracy": 0.9852140077821012
        }, 
        "code_version": "1.1.3", 
        "metrics_raw": {
            "f1": 0.9882975737081288, 
            "f1_macro": 0.9087468685573311, 
            "accuracy": 0.9883292383292384
        }
    }, 
    "xgboost_log_cpm": {
        "submit": "2022-11-14 01:12:06.771", 
        "duration": "9m 29s", 
        "realtime": "1m 10s", 
        "%cpu": "3203.1%", 
        "peak_rss": "2.6 GB", 
        "peak_vmem": "11.5 GB", 
        "rchar": "1.3 GB", 
        "wchar": "1.7 GB", 
        "metrics": {
            "f1_macro": 0.8609750443524659, 
            "accuracy": 0.9712062256809338, 
            "f1": 0.970878679488411
        }, 
        "code_version": "1.6.2", 
        "metrics_raw": {
            "f1_macro": 0.8710781817909413, 
            "accuracy": 0.9772727272727273, 
            "f1": 0.9770063458287446
        }
    }, 
    "xgboost_scran": {
        "submit": "2022-11-14 01:12:06.752", 
        "duration": "17m 59s", 
        "realtime": "8m 54s", 
        "%cpu": "566.1%", 
        "peak_rss": "9 GB", 
        "peak_vmem": "16.4 GB", 
        "rchar": "1.3 GB", 
        "wchar": "2.1 GB", 
        "metrics": {
            "accuracy": 0.9638132295719845, 
            "f1_macro": 0.9509920939607429, 
            "f1": 0.9635199231641665
        }, 
        "code_version": "1.6.2", 
        "metrics_raw": {
            "accuracy": 0.9714373464373465, 
            "f1_macro": 0.9545535668486883, 
            "f1": 0.97119600841692
        }
    }, 
    "knn_classifier_scran": {
        "submit": "2022-11-14 01:12:06.526", 
        "duration": "18m 9s", 
        "realtime": "10m 2s", 
        "%cpu": "131.8%", 
        "peak_rss": "9.8 GB", 
        "peak_vmem": "14.9 GB", 
        "rchar": "1.3 GB", 
        "wchar": "2.1 GB", 
        "metrics": {
            "accuracy": 0.9470817120622569, 
            "f1_macro": 0.7943233958985448, 
            "f1": 0.9464640492238694
        }, 
        "code_version": "1.1.3", 
        "metrics_raw": {
            "accuracy": 0.9582309582309583, 
            "f1_macro": 0.8092702015956755, 
            "f1": 0.9577290069182879
        }
    }, 
    "seurat": {
        "submit": "2022-11-14 01:12:06.777", 
        "duration": "21m 59s", 
        "realtime": "13m 27s", 
        "%cpu": "119.5%", 
        "peak_rss": "402.8 GB", 
        "peak_vmem": "415.6 GB", 
        "rchar": "2.8 GB", 
        "wchar": "2.1 GB", 
        "metrics": {
            "f1": 0.9748912404207406, 
            "f1_macro": 0.8254165559369819, 
            "accuracy": 0.9754863813229573
        }, 
        "code_version": "4.1.1", 
        "metrics_raw": {
            "f1": 0.9801745894659917, 
            "f1_macro": 0.838103778325478, 
            "accuracy": 0.9806511056511057
        }
    }, 
    "mlp_scran": {
        "submit": "2022-11-14 01:13:28.081", 
        "duration": "31m 18s", 
        "realtime": "15m 41s", 
        "%cpu": "1071.0%", 
        "peak_rss": "9.8 GB", 
        "peak_vmem": "14.9 GB", 
        "rchar": "1.3 GB", 
        "wchar": "2.1 GB", 
        "metrics": {
            "accuracy": 0.9747081712062257, 
            "f1": 0.9744716594297168, 
            "f1_macro": 0.8707147438807031
        }, 
        "code_version": "1.1.3", 
        "metrics_raw": {
            "accuracy": 0.980036855036855, 
            "f1": 0.9798432961030897, 
            "f1_macro": 0.8801100837695595
        }
    }, 
    "majority_vote": {
        "submit": "2022-11-14 01:13:49.999", 
        "duration": "48m 36s", 
        "realtime": "16.9s", 
        "%cpu": "119.9%", 
        "peak_rss": "1.5 GB", 
        "peak_vmem": "5.8 GB", 
        "rchar": "1.3 GB", 
        "wchar": "1.2 GB", 
        "metrics": {
            "f1_macro": -0.03870274233608531, 
            "f1": -0.040359235366479965, 
            "accuracy": 0.17237354085603113
        }, 
        "code_version": "0.6.0", 
        "metrics_raw": {
            "f1_macro": 0.036781234728783196, 
            "f1": 0.17855165728597885, 
            "accuracy": 0.34674447174447176
        }
    }, 
    "random_labels": {
        "submit": "2022-11-14 01:13:50.292", 
        "duration": "49m 56s", 
        "realtime": "12.6s", 
        "%cpu": "119.5%", 
        "peak_rss": "1.5 GB", 
        "peak_vmem": "5.8 GB", 
        "rchar": "1.3 GB", 
        "wchar": "1.2 GB", 
        "metrics": {
            "f1": 0.0, 
            "accuracy": 0.0, 
            "f1_macro": 0.0
        }, 
        "code_version": "0.6.0", 
        "metrics_raw": {
            "f1": 0.21041856044594504, 
            "accuracy": 0.2106879606879607, 
            "f1_macro": 0.07267139479684238
        }
    }, 
    "logistic_regression_scran": {
        "submit": "2022-11-14 01:13:49.766", 
        "duration": "1h 1m 7s", 
        "realtime": "13m 53s", 
        "%cpu": "146.4%", 
        "peak_rss": "9.8 GB", 
        "peak_vmem": "14.9 GB", 
        "rchar": "1.3 GB", 
        "wchar": "2.1 GB", 
        "metrics": {
            "f1": 0.9290294325319287, 
            "f1_macro": 0.6406672432504178, 
            "accuracy": 0.9365758754863813
        }, 
        "code_version": "1.1.3", 
        "metrics_raw": {
            "f1": 0.943962957172592, 
            "f1_macro": 0.6667804558796044, 
            "accuracy": 0.9499385749385749
        }
    }, 
    "scarches_scanvi_hvg": {
        "submit": "2022-11-14 01:49:56.416", 
        "duration": "1h 3m 10s", 
        "realtime": "26m 48s", 
        "%cpu": "2324.9%", 
        "peak_rss": "5.7 GB", 
        "peak_vmem": "45.4 GB", 
        "rchar": "1.3 GB", 
        "wchar": "1.2 GB", 
        "metrics": {
            "accuracy": 0.9486381322957198, 
            "f1_macro": 0.4983330696003718, 
            "f1": 0.9375187822204816
        }, 
        "code_version": "0.19.0", 
        "metrics_raw": {
            "accuracy": 0.9594594594594594, 
            "f1_macro": 0.5347899051559633, 
            "f1": 0.9506659901205575
        }
    }, 
    "scarches_scanvi_all_genes": {
        "submit": "2022-11-14 01:50:06.348", 
        "duration": "1h 14m 20s", 
        "realtime": "35m 46s", 
        "%cpu": "2445.7%", 
        "peak_rss": "5.9 GB", 
        "peak_vmem": "45.6 GB", 
        "rchar": "1.3 GB", 
        "wchar": "1.2 GB", 
        "metrics": {
            "f1": 0.9337122546528168, 
            "accuracy": 0.9451361867704281, 
            "f1_macro": 0.4985069233525496
        }, 
        "code_version": "0.19.0", 
        "metrics_raw": {
            "f1": 0.9476604266039786, 
            "accuracy": 0.9566953316953317, 
            "f1_macro": 0.5349511247134796
        }
    }, 
    "scanvi_hvg": {
        "submit": "2022-11-14 01:48:56.590", 
        "duration": "1h 17m 19s", 
        "realtime": "44m 15s", 
        "%cpu": "2445.3%", 
        "peak_rss": "5.9 GB", 
        "peak_vmem": "45.2 GB", 
        "rchar": "1.3 GB", 
        "wchar": "1.2 GB", 
        "metrics": {
            "accuracy": 0.9700389105058366, 
            "f1": 0.9670354821740645, 
            "f1_macro": 0.6610286071097875
        }, 
        "code_version": "0.19.0", 
        "metrics_raw": {
            "accuracy": 0.9763513513513513, 
            "f1": 0.9739718285607926, 
            "f1_macro": 0.6856621310273477
        }
    }, 
    "scanvi_all_genes": {
        "submit": "2022-11-14 02:35:36.674", 
        "duration": "1h 54m 9s", 
        "realtime": "31m 19s", 
        "%cpu": "2769.8%", 
        "peak_rss": "4.5 GB", 
        "peak_vmem": "43.8 GB", 
        "rchar": "1.3 GB", 
        "wchar": "1.2 GB", 
        "metrics": {
            "f1": 0.955306149816049, 
            "f1_macro": 0.5848422723955045, 
            "accuracy": 0.9614785992217899
        }, 
        "code_version": "0.19.0", 
        "metrics_raw": {
            "f1": 0.9647105654325429, 
            "f1_macro": 0.6150123635212107, 
            "accuracy": 0.9695945945945946
        }
    }
}